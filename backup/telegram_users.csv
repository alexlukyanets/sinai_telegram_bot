url,title,posted_time,description,skills,location,hourly_budget_text,monthly_budget_text,weekly_budget_text,created_at,updated_at
https://www.upwork.com/jobs/Web-scraping-website_~0107ce923abeaec0ca/?referrer_url_path=/nx/search/jobs/,Web scraping website,2024-02-23 17:04:39,"Our project requires a skilled web scraping specialist who can help us collect data from various websites. The ideal candidate should have the ability to create custom web scraping scripts and tools that can extract data from websites and store it in a structured format.

Responsibilities:

Create custom web scraping scripts or tools to collect specific data from target websites
Verify that the data is extracted correctly and stored in a structured format such as CSV or Excel
Improve web scraping scripts for efficiency and performance
Collaborate with our team to comprehend project requirements and deliver data promptly
Requirements:

Demonstrated experience with web scraping methods and tools
Expertise in programming languages such as Python, Java, or similar
Knowledge of web technologies including HTML, CSS, and JavaScript
Excellent attention to detail and problem-solving skills
If you are interested and qualified for this project, please send us your proposal with details of your previous web scraping projects and relevant experience. We are looking for a talented and dependable freelancer who can produce high-quality results.","{'"Data Scraping'",Python,Scrapy,'"Data Mining'",'"Web Crawling'"}",United States,co,"","",2024-02-23 17:34:15.646973,2024-02-23 17:34:15.646973
https://www.upwork.com/jobs/Web-scraping-developer_~0161494e0d383c4ff5/?referrer_url_path=/nx/search/jobs/,Web scraping developer,2024-02-23 16:39:07,"Our project requires a skilled web scraping specialist who can help us collect data from various websites. The ideal candidate should have the ability to create custom web scraping scripts and tools to efficiently collect data from websites and store it in a structured format.

Responsibilities:

Create custom web scraping scripts or tools to collect specific data from target websites
Make sure data is collected correctly and stored in a structured format such as CSV or Excel
Improve web scraping scripts for efficiency and performance
Collaborate with our team to understand project requirements and deliver data on time
Requirements:

Demonstrated experience with web scraping methods and tools
Expertise in programming languages such as Python, Java, or similar
Knowledge of web technologies including HTML, CSS, and JavaScript
Excellent attention to detail and problem-solving skills
If you are interested and qualified for this project, please send us your proposal with details of your previous web scraping projects and relevant experience. We are looking for a talented and dependable freelancer who can produce high-quality results.","{'"Data Extraction'",ETL,'"Data Scraping'",Python,JavaScript,PHP,HTML,API,'"Data Mining'",Scrapy}",Singapore,co,"","",2024-02-23 17:34:15.669937,2024-02-23 17:34:15.669937
https://www.upwork.com/jobs/Python-developer-create-proof-concept-web-info-extraction-solution_~01d47a992527f17062/?referrer_url_path=/nx/search/jobs/,Python developer to create proof of concept web info extraction solution,2024-02-23 14:47:16,"Please read the following job description and submit an initial idea for a solution for this project. Payment is non-negotiable at $25 CAD, but there is a potential for future work upon successfully completing this job.

Objective: Our goal is to assess software documentation for accessibility compliance by analyzing content on official software websites, focusing on adherence to WCAG (Web Content Accessibility Guidelines) standards.

Project Description: We require a Python developer to automate evaluating software documentation for accessibility issues. The solution should encompass the following functionalities:

Automate Software Homepage Discovery: Use a search API, such as Google Custom Search API, to locate the homepage of specified software automatically, eliminating the need for manual input.

Scrape Accessibility Information: Upon locating the homepage, employ a web scraping framework like Scrapy to navigate to and extract content from the software''s accessibility page by searching for related keywords.

Analyze Documentation Against WCAG Standards: Utilize a Language Learning Model (LLM) to efficiently compare the scraped information with WCAG guidelines, employing a vector database for this analysis.

Develop a User Interface: Implement a simple UI that allows users to input software names and receive comprehensive reports on WCAG compliance. Streamlit is suggested for its simplicity and effectiveness.

Technical Requirements:
1. Familiarity with Python, especially with Scrapy and Google''s Custom Search API.
2. Experience with Natural Language Processing (NLP) and LLMs for content analysis (preferred).
Familiarity with WCAG guidelines and accessibility evaluation practices (preferred). (link: https://www.w3.org/TR/WCAG22/)

Code Snippets: Provided to illustrate expectations and offer a starting point, though modifications may be necessary based on the developer''s approach.

Application Instructions: Interested candidates should submit a proposal detailing their experience with web scraping and LLMs, including a brief plan of approach for this project. Highlight any specific technologies or frameworks you intend to utilize.


Note about the solution: There are no initial first steps. I have outlined one potential solution in this job description, but the final solution is for you to come up with.","{Python,Scrapy,'"LLM Prompt Engineering'"}",Canada,a,"","",2024-02-23 17:34:15.684866,2024-02-23 17:34:15.684866
https://www.upwork.com/jobs/TikTok-Web-API_~011ed6368d7fee2388/?referrer_url_path=/nx/search/jobs/,TikTok Web API,2024-02-23 14:34:15.69447,"Hello!

I am looking for someone who understands TikTok API, and signing URLS for web requests (not App). using _signature and others. So I can send follows, messages etc.

Is this something you understand?

Thanks

Chris E.","{'"Data Scraping'",'"Data Extraction'",Scrapy,Selenium,'"Web Crawling'",'"Bot Development'",Chatbot,'"Artificial Intelligence'",'"Data Collection'",Automation,'"Data Science'",'"Data Mining'",Zapier,'"API Integration'"}",United Kingdom,a,"","",2024-02-23 17:34:15.697272,2024-02-23 17:34:15.697272
https://www.upwork.com/jobs/Web-scraping-expert_~01ef5bf76108f1a013/?referrer_url_path=/nx/search/jobs/,Web scraping expert,2024-02-23 14:34:15.705887,"We are looking for a talented web scraping expert to help us extract data from various websites for a project we are working on. The ideal candidate should have experience with creating custom web scraping scripts and tools to efficiently extract data from websites and save it in a structured format.

Responsibilities:
- Develop custom web scraping scripts or tools to extract specific data from target websites
- Ensure data is extracted accurately and saved in a structured format such as CSV or Excel
- Optimize web scraping scripts for efficiency and performance
- Work closely with our team to understand project requirements and deliver data in a timely manner

Requirements:
- Proven experience with web scraping techniques and tools
- Proficiency in programming languages such as Python, Java, or similar
- Familiarity with web technologies including HTML, CSS, and JavaScript
- Strong attention to detail and problem-solving skills

If you have the skills and experience to help us with this project, please submit your proposal with details of your previous web scraping projects and relevant experience. We are looking to hire a talented and reliable freelancer who can deliver high-quality results.","{Scrapy,SQL,Python,'"Data Entry'",'"Data Scraping'",'"Data Mining'",'"Beautiful Soup'",Selenium,'"Lead Generation'",'"Web Crawling'",Django,'"Data Extraction'",Automation,'"Web Scraping'",JavaScript}",Georgia,a,"","",2024-02-23 17:34:15.708927,2024-02-23 17:34:15.708927
https://www.upwork.com/jobs/Web-Scraping-download-images-from-ever-project-page-with-high-resolution-and-save-them-into-folder_~013592af24343a7a78/?referrer_url_path=/nx/search/jobs/,"Web Scraping, download images from ever project page with high resolution and save them into folder",2024-02-23 13:37:23,We are seeking a talented and experienced web scraping expert to help us extract JSON data from various websites...,"{'"Data Scraping'",'"Data Extraction'",Python,Scrapy}",India,$3.00-$5.00,"","",2024-02-23 17:34:15.718345,2024-02-23 17:34:15.718345
https://www.upwork.com/jobs/Scraping-8500-Store-Locator-Websites_~011d4db667f43db4ad/?referrer_url_path=/nx/search/jobs/,Scraping 8500 Store Locator Websites ,2024-02-23 13:34:15.724808,"Scrape the store locator of 8500 retail websites. The stores will be provided. Output store locations to CSV. Format of Excel: Name, Address, State, City, Zip. Latitude and Longitude is bonus. ","{'"Data Scraping'",'"Online Research'",'"List Building'",'"Data Entry'",'"Data Mining'",Python,'"Microsoft Excel'",Scrapy,PHP}",United States,a,"","",2024-02-23 17:34:15.726798,2024-02-23 17:34:15.726798
https://www.upwork.com/jobs/Shopee-Data-Extraction-Scraping_~0101e64c8a659c9e79/?referrer_url_path=/nx/search/jobs/,Shopee Data Extraction/Scraping,2024-02-23 07:34:15.733844,"This is an updated post. 
We are looking for an engineer to develop a data scraping script (in Python) to extract product listings and product information from https://shopee.tw.

We want the ability to scrape the data based on keywords and categories. Please mention any relevant experience in proposals.
","{'"Web Application Development'",'"Web Crawling'",'"Data Scraping'",'"Data Extraction'",Scrapy,Selenium,API,'"API Development'",'"API Integration'",Python,'"Data Mining'"}",India,a,"","",2024-02-23 17:34:15.73612,2024-02-23 17:34:15.73612
https://www.upwork.com/jobs/Scrapping-information-from-list-URLs_~01e032c5f69216155e/?referrer_url_path=/nx/search/jobs/,Scrapping information from a list of URLs. ,2024-02-23 05:34:15.743141,"I have a list of URLs from which you have to extract specific information. I will provide you the URLs and exactly what you need to capture from each URL.  
Here is the example URLs. https://hackerone.com/reports/692116

You need to extract the following information: 
handle	 url	hacker	disclosed_date	severity	weakness	severity_score	times_spent	bounty	cve_id	cve_link	participants	report_date	visibility	asset	asset_category	spec-activity	more_info	report_text	summary_text	triage_date	triage_updated	first_reply	num_of_resolves	reslove_date	resolve_updates	informative_date	duplicate_date	n_a_date	spam_date	bounty_awarded_time

Apart from these on each page, you need to store the following information either on the same file or a different file:
 url	 activity	activity_person	 activity_time	 activity_text 

I can show you where each of these data points is present on the webpage. By the end of the project, I will require source files in Python with setup/running instructions. ","{'"Data Scraping'",Scrapy,Python}",United States,a,"","",2024-02-23 17:34:15.744838,2024-02-23 17:34:15.744838
https://www.upwork.com/jobs/Linkedin-Data-Scraper-Scrape-profiles-amp-email-addresses-based-Job-Title_~017ca7aae1ce2b169e/?referrer_url_path=/nx/search/jobs/,Linkedin Data Scraper / Scrape profiles &amp; email addresses based on Job Title,2024-02-22 17:34:15.752217,"I am looking for someone to scrape Linkedin based on job title and get me an excel list of names, title, email addresses....

I will provide you with the job title, and I''d like you to get me all of the info","{'"Data Scraping'",'"Data Mining'",'"Data Entry'",Scrapy,'"List Building'",'"Prospect List'",'"Lead Generation'",'"Microsoft Excel'"}",United States,a,"","",2024-02-23 17:34:15.754597,2024-02-23 17:34:15.754597
https://www.upwork.com/jobs/Web-scraping-news-articles_~0175bb35a10284477e/?referrer_url_path=/nx/search/jobs/,Web scraping news articles,2024-02-22 17:34:15.767888,"I need someone to help scrape all news articles related to key keywords &quot;belt road&quot; and &quot;south china sea&quot; on the People''s Daily website. The data should include the title, date, full content, and link to each relevant article. ","{'"Data Scraping'",'"Data Extraction'",Python,'"Data Mining'",Scrapy,'"Web Crawling'"}",Netherlands,bO,"","",2024-02-23 17:34:15.769865,2024-02-23 17:34:15.769865
https://www.upwork.com/jobs/Scrape-data-from-site_~018fb7098d3e078a8d/?referrer_url_path=/nx/search/jobs/,Scrape data from a site,2024-02-22 16:59:35,"Hi,  I need to scrape the customer data from a platform''s website that we use as I can''t manually export the data.  
We can look at the details on a quick call once I find the ideal candidate who can do this task. 

Thank you

","{'"Data Scraping'",'"Data Mining'",'"Data Extraction'",'"Data Entry'",Scrapy}",United States,cB,"","",2024-02-23 17:34:15.779238,2024-02-23 17:34:15.779238
https://www.upwork.com/jobs/need-Expert-Web-Scraper_~01c2091fcfe7d0eb68/?referrer_url_path=/nx/search/jobs/,I need an Expert Web Scraper,2024-02-22 17:34:15.787069,"Hi ,
I have a quick project and i need an expert web scraper to scrape the below website.

https://kenjoyretail.com/

I need the data as like the attached sample sheet.

Thanks","{'"Data Extraction'",'"Web Scraping'",pandas,'"Beautiful Soup'",'"Data Scraping'",'"Data Mining'",'"Data Entry'",Python,Scrapy}",Bangladesh,a,"","",2024-02-23 17:34:15.789776,2024-02-23 17:34:15.789776
https://www.upwork.com/jobs/need-python-scraper_~01197e27d0bf610260/?referrer_url_path=/nx/search/jobs/,I need python scraper ,2024-02-22 17:34:15.796652,"Hi there 
 i am interested in scraping the data from this wesbite.  I want to scarpe whole website data for example below link.

https://shawcross.co.uk

Please see the attached image whatever data i need i highlight by red and find attached the example file and i need the data as like the attached csv file.","{'"Data Extraction'",'"Web Scraping'",'"Beautiful Soup'",Scrapy,'"Data Scraping'",Python,'"Data Mining'",pandas,HTML}",Bangladesh,a,"","",2024-02-23 17:34:15.799052,2024-02-23 17:34:15.799052
https://www.upwork.com/jobs/Medical-Conference-Agenda-Scrapes_~015a7c9a6c713db327/?referrer_url_path=/nx/search/jobs/,Medical Conference Agenda Scrapes,2024-02-21 21:45:05,We have several medical conferences across many communities where we need agendas scraped. The scraping will include several line items necessary for us to do the work that i can explain more in detail.,"{'"Data Scraping'",'"Data Mining'",Scrapy,Selenium,'"Beautiful Soup'",'"Python Script'",'"Browser Automation'",'"Data Extraction'",'"Data Collection'",'"Web Crawling'",'"Task Automation'",'"Web Scraping'",'"Screen Scraping'",'"Web Scraping Software'"}",United States,a,"","",2024-02-23 17:34:15.80976,2024-02-23 17:34:15.80976
https://www.upwork.com/jobs/Web-scraping_~018cd4bbc9f9561433/?referrer_url_path=/nx/search/jobs/,Web scraping,2024-02-21 22:14:45,"escription: 
I''m working on a project to extract / scrape data on social media sites (TikTok, Instagram, YouTube) for public accounts.

To start, I want a script that does the following - 

takes in a list of TikTok usernames - 

tt_uns = [''taylerfit'', ''thedatingblindshow'', ''aditisp24'']

it goes to their pages (eg https://www.tiktok.com/@aditisp24) and returns the following - 

 - name (Aditi Patel), Following (22), Followers (40.6k), Likes (665K), Bio (&quot;22
Venmo/cashapp - aditisp24&quot;)

then, it loops through all the videos and gets - 

url - https://www.tiktok.com/@aditisp24/video/7285533891014823199
views - 21.2k
date - 2023-10-2
caption - 
likes - 2312
comments - 11
saves - 335

Additional work to follow.","{'"Data Scraping'",Python,'"Data Mining'",Scrapy,'"Data Extraction'"}",Israel,a,"","",2024-02-23 17:34:15.8197,2024-02-23 17:34:15.8197
https://www.upwork.com/jobs/Restaurant-Listing-Record-Extraction_~012961c316fdbbe5dd/?referrer_url_path=/nx/search/jobs/,Restaurant Listing Record Extraction,2024-02-21 18:54:15,"We are building an app reliant on restaurant listing data. We need clean data (less than a month old) to demo the functionality. We will ultimately need an ETL, but for now we need to scrape the following records for every open restaurant in the US, basically all the listings in yelp and uber eats:

- Restaurant Name
- Address
- Category (type of restaurant)
- Website URL
- Menus
- Photos","{'"Data Extraction'",'"Screen Scraping'",'"Web Scraping'",Scrapy,'"Beautiful Soup'",'"Web Scraping Framework'",Python-Goose,'"Data Mining'",'"Data Scraping'",'"Accuracy Verification'"}",United States,a,"","",2024-02-23 17:34:15.829679,2024-02-23 17:34:15.829679
https://www.upwork.com/jobs/File-Scraping-From-Website_~01248e89a45ea7a374/?referrer_url_path=/nx/search/jobs/,File Scraping From Website,2024-02-21 16:45:16,"Need to scrape all files in minutes folder on below website:

https://hendryfla.civicweb.net/filepro/documents/6759/

Would also like OCR run on all pdf files so can quickly search them.

All files should be individual, with a 2nd combined file for the year. For example, in 2023 all files should be separate, and an additional file created combining all files from 2023 into a single pdf","{'"Beautiful Soup'",'"Selenium WebDriver'",'"Data Scraping'",Python,'"Data Extraction'",Scrapy}",United States,co,"","",2024-02-23 17:34:15.839012,2024-02-23 17:34:15.839012
https://www.upwork.com/jobs/Data-Scraping-Expert-for-Gardening-Website_~01e71ab2856094b313/?referrer_url_path=/nx/search/jobs/,Data Scraping Expert for Gardening Website,2024-02-21 16:44:15,"Overview:
We are looking for a skilled Data Scraping Expert to help us compile a comprehensive list of vegetables, their varieties, and URLs for purchase options from a specific gardening website. This project requires precision and attention to detail to ensure all relevant data is accurately captured.

Responsibilities:
Navigate through the specified gardening website to identify all available vegetables.
Collect detailed information for each vegetable, including all available varieties.
Extract URLs for each variety that direct to the purchase options on the website.
Organize data collected into a structured format (e.g., Excel or Google Sheets) with clear headings: Vegetable, Variety, URL for Purchase Option 1, URL for Purchase Option 2, etc.
Ensure the accuracy and completeness of all data collected.
Communicate progress regularly and meet project deadlines.

Example Task:
Vegetable: Asparagus
Variety: Jersey Knight Asparagus
URLs for Purchase Options:
Price of each purchase option
Pictures of plant

I will give you the url to look at through chat. just message me","{'"Data Scraping'",'"Data Mining'",'"Data Entry'",Python,'"Microsoft Excel'",Scrapy,'"Data Extraction'"}",United States,a,"","",2024-02-23 17:34:15.850439,2024-02-23 17:34:15.850439
https://www.upwork.com/jobs/Scrape-website-for-OpenCart3-site_~01d90843c84e8f8436/?referrer_url_path=/nx/search/jobs/,Scrape website for my OpenCart3 site,2024-02-21 17:34:15.858775,"I want to be scraped one site in csv file for my OpenCart site
Csv must be suitable for OpenCart Import categories, manufactures, and products","{'"Data Scraping'",Python,Scrapy}",Bulgaria,$5.00-$20.00,"","",2024-02-23 17:34:15.861113,2024-02-23 17:34:15.861113
https://www.upwork.com/jobs/Scrapping-websites-and-automate-messages_~01acae6a92ac195375/?referrer_url_path=/nx/search/jobs/,Scrapping websites and automate messages.,2024-02-21 15:30:20,"I want someone who will help me to scrap websites (only websites with contact us fields), collect them, and send daily messages per amount I give (after we have the mega list) approximately between 500 to 1000 submissions a day. 

* If you know how to scrap websites by categories.
* If you know how to automate message sending via contact us fields.

I am offering a monthly work per hour.","{Python,'"Data Scraping'",Automation,Selenium,'"Data Mining'",'"Data Extraction'",'"Web Crawling'",Scripting,Scrapy}",Portugal,$5.00-$45.00,"","",2024-02-23 17:34:15.872626,2024-02-23 17:34:15.872626
https://www.upwork.com/jobs/Need-site-scraped_~0120630be815259c6a/?referrer_url_path=/nx/search/jobs/,Need site scraped,2024-02-21 17:34:15.880898,"We need to scrape this site you need to input a in search text field and click on search button https://citisenportal.com/Search/Sevier%20County%20Trustee/

Details are in the following link 
https://docs.google.com/document/d/1-3ijfHC-OqoqDkoFHVOTexWoCJiCvdCvR_3Bs4OR5Tk/edit?usp=drivesdk","{'"Data Extraction'",'"Screen Scraping'",'"Web Scraping'",'"Beautiful Soup'",Selenium,Python-Requests,Scrapy,'"Data Scraping'",Python,'"Web Crawling'"}",Pakistan,a,"","",2024-02-23 17:34:15.883313,2024-02-23 17:34:15.883313
https://www.upwork.com/jobs/Project-based-job-real-estate-agency_~011355bb164f8e435a/?referrer_url_path=/nx/search/jobs/,Project based job in real estate agency,2024-02-21 17:34:15.892835,"We have several tasks for our real estate agency, that may match your expertise can we discuss in chat?","{Selenium,'"Beautiful Soup'",Scrapy,'"Data Mining'",Python,'"Web Crawling'",'"Data Scraping'",'"Web Scraping'",'"Data Extraction'",'"Data Entry'",'"Microsoft Excel'",'"List Building'",'"Prospect List'",'"API Integration'",SQL}",Indonesia,a,"","",2024-02-23 17:34:15.894637,2024-02-23 17:34:15.894637
https://www.upwork.com/jobs/High-Scale-Website-Scraping-Tool_~0126d54cc7b7899c1a/?referrer_url_path=/nx/search/jobs/,High-Scale Website Scraping Tool,2024-02-21 10:36:54,"** No ChatGPT or templated responses to this project will be read. **

I need a high-scale website scraping tool that integrates with 3rd party enrichment APIs to assist with lead generation and link building prospecting.

The tool must be user friendly and ideally built with no-code integrations, although Pything frameworks etc are likely needed.

I have a full spec of everything it must do. Please share relevant work experience","{'"API Integration'",'"Data Extraction'",Scrapy,Selenium,StormCrawler,'"Data Mining'",Python,'"Data Scraping'",'"Web Crawling'",Automation}",United Kingdom,$20.00-$45.00,"","",2024-02-23 17:34:15.905743,2024-02-23 17:34:15.905743
https://www.upwork.com/jobs/Web-Scrapimg_~012daec9a7916be1e7/?referrer_url_path=/nx/search/jobs/,Web Scrapimg,2024-02-21 17:34:15.914524,"Web scraping of chat from website account .

We need small browser extension that will scrap all data of chat in Onlyfans .

The user will open the chat on him browser and activate the extension .
It will keep the data in our server first and after will provide the user copy of the data in txt file or excel .
","{Python,Selenium,'"Data Entry'",'"Data Scraping'",ETL,Scrapy,'"Data Mining'",'"Web Scraping'",'"Data Extraction'",'"Web Crawling'",'"Data Collection'",'"Web Scraping Software'",XPath,'"Web Crawler'",'"Browser Automation'"}",Bulgaria,a,"","",2024-02-23 17:34:15.917582,2024-02-23 17:34:15.917582
https://www.upwork.com/jobs/Web-Scraper_~01507634892f02a505/?referrer_url_path=/nx/search/jobs/,Web Scraper ,2024-02-21 17:34:15.924397,scrape data from sites using scrapy and requests. data needs to be imported in csv format. detailed format will be given later,"{Scrapy,Python,'"Web Crawling'",'"Data Scraping'",'"Data Mining'",CSV,Python-Requests}",India,a,"","",2024-02-23 17:34:15.926087,2024-02-23 17:34:15.926087
https://www.upwork.com/jobs/Lead-Generation-Finding-Cleaning-Companies-with-WEBSITE-New-York-and-Pennsylvania_~01207efa62a223e708/?referrer_url_path=/nx/search/jobs/,Lead Generation - Finding Cleaning Companies  with NO WEBSITE in New York and Pennsylvania,2024-02-20 17:34:15.933134,"Am needing to find 2,000 cleaning companies WITHOUT A WEBSITE in New York and Pennsylvania. 

What I need:
-Name of Manager/Decision Maker (if possible)
-Name Of Business
-Address Of Business
-Phone Number
-Email

*Has to be done in a DAY*

$5 for 2,000 leads

Can easily turn it to a FULLTIME job depending on how this goes.

Please apply with your experience and if you can get this done in a timely manner. ","{'"Lead Generation'",'"Data Scraping'",Python,Scrapy,'"Data Extraction'"}",United States,a,"","",2024-02-23 17:34:15.934889,2024-02-23 17:34:15.934889
https://www.upwork.com/jobs/Help-write-crawler-for-local-event-listings_~01eb71759f3ce0bdfb/?referrer_url_path=/nx/search/jobs/,Help write a crawler for local event listings,2024-02-20 17:34:15.94225,"Looking for help building a web crawler that runs every week,  to do a scrape of a few pages and extract live music events. 

Ideally, I''m looking for the data to be delivered in a PostgresSQL database that''s updated every time new results are found.  

Any experience working with ChatGPT and scraped data is highly preferred. if you have experience working with apify that''s a bonus too. 

Thank you 
Ritesh","{'"Data Extraction'",Scrapy,'"Beautiful Soup'",Selenium,'"Selenium WebDriver'",'"Data Scraping'",Python}",United States,bO,"","",2024-02-23 17:34:15.944742,2024-02-23 17:34:15.944742
https://www.upwork.com/jobs/Crawler_~0152e7dd88687629a2/?referrer_url_path=/nx/search/jobs/,Crawler,2024-02-19 04:49:54,"I need a crawler
I think we need a cloud flare detour","{'"Microsoft Excel'",'"Data Visualization'",Python,'"Microsoft Power BI'",'"Data Entry'",Automation,'"Data Analytics'",'"Data Extraction'",'"Web Scraping'",Scrapy,'"Data Collection'",'"Beautiful Soup'",Selenium,'"Data Scraping'",'"Web Crawling'"}",South Korea,a,"","",2024-02-23 17:34:18.17305,2024-02-23 17:34:18.17305
https://www.upwork.com/jobs/Data-Scrape-Hotel-Information_~0117338ac8d797c824/?referrer_url_path=/nx/search/jobs/,Data Scrape of Hotel Information,2024-02-20 21:39:57,"Hello, thanks for looking at this job.  We have periodic need for someone to help us scrape hotel data (example attached) for different locations around the world.  

We have typically scraped this data from hotels.com, but it can be from anywhere, as long as you can get all the information (most important are the latitude/longitude values) in this spreadsheet.  

We would like to hire someone immediately to help us scrape a location in Bangladesh and extract this info from all the hotels available there, and for the right candidate will have followup work.  ","{'"Data Scraping'",'"Data Mining'",Python,Scrapy,'"Data Extraction'"}",South Korea,a,"","",2024-02-23 17:34:15.952537,2024-02-23 17:34:15.952537
https://www.upwork.com/jobs/Web-Scraping-Specialist_~0163b2f2bce1bec6f5/?referrer_url_path=/nx/search/jobs/,Web Scraping Specialist,2024-02-20 18:55:58,We are looking for a skilled web scraping specialist who can extract data from websites. The job involves using web scraping tools and techniques to extract data from various websites. The data should be accurate and in a format that can be easily processed and analyzed. The specialist should have experience with web scraping techniques and be able to handle complex websites. The ability to write custom code to extract data is a plus.,"{'"Data Scraping'",'"Data Mining'",Python,Scrapy}",India,bO,"","",2024-02-23 17:34:15.960256,2024-02-23 17:34:15.960256
https://www.upwork.com/jobs/Data-scraping-from-Google-Maps_~01f46b556d180f9a0f/?referrer_url_path=/nx/search/jobs/,Data scraping from Google Maps,2024-02-20 17:59:25,"I need to extract information on all existing commercial establishments in Brazil from Google Maps within four categories (food retail, pharmacy, green shop, body shop) and export this information to an Excel file. The data should include the name of the establishment, category, city, state, and geographical coordinates.
I don''t need a map, just the Excel file with the name and details of these commercial establishments.

For the food retail category, we estimate there are approximately 500,000 establishments in Brazil.
For the pharmacies category, we estimate between 90,000 and 100,000 establishments.
For the green shop and body shop categories, we don''t know the exact quantity, but the research should be exhaustive to identify all establishments in these categories.

Attached is an Excel file with a sample sheet of the output we would like to receive (an Excel file with a long list of commercial establishments containing the name of the store, category information, city, state, and geographical coordinates). Please note that the final output is expected to contain more than 600,000 rows.
In the other sheets, you will find variations of the names of the categories to be researched (one sheet with category names in English and another sheet in Portuguese","{'"Screen Scraping'",'"Web Crawling'",'"Web Scraping'",'"Beautiful Soup'",Python-Requests,'"Data Scraping'",Python,'"Data Extraction'",'"Google Maps API'",Scrapy}",Pakistan,a,"","",2024-02-23 17:34:15.969361,2024-02-23 17:34:15.969361
https://www.upwork.com/jobs/Data-mining-lead-generation_~019256995e751c42d6/?referrer_url_path=/nx/search/jobs/,"Data mining, lead generation",2024-02-20 17:34:15.975412,"Hello,

I have 2 stages of the job. 

1.	I need the names of all private schools with Brazilian curriculum and private English language schools in Brazil. 
2.	I will need contact details (phone and verified email) of specific roles at those schools. Some role examples are school principal, their assistant, administrative director. 

Since lots of info in unavailable in English, we need a Portuguese speaker located anywhere in the world. 

Shall we connect on the phone for a 15 min conversation about the job?

Best,
Andrey
","{'"Data Entry'",'"Data Scraping'",Python,'"Lead Generation'",'"Data Mining'",Scrapy,'"Data Extraction'",API,Scripting,'"Social Media Marketing'",'"Instagram API'",'"Web Crawling'"}",United Arab Emirates,a,"","",2024-02-23 17:34:15.977441,2024-02-23 17:34:15.977441
https://www.upwork.com/jobs/Web-Scraping-Expert-Data-Match-Source-Contact-and-Merge_~01ba0c92da54188b50/?referrer_url_path=/nx/search/jobs/,"Web Scraping Expert to Data Match, Source Contact and Merge",2024-02-20 16:05:49,"Looking for a proficient virtual assistant to spearhead a dynamic web scraping and list-building project. The ideal candidate will leverage tools such as LinkedIn, Apollo, and other recommended scraping tools to curate a comprehensive database of potential prospects. Responsibilities include thorough research, accurate data extraction, and seamless integration of gathered information into a meticulously organized prospect list, ensuring quality and relevance for future outreach initiatives","{'"Beautiful Soup'",Selenium,'"Apache Mahout'",KNIME,'"Data Scraping'",'"Microsoft Excel'",'"Data Mining'",'"Lead Generation'",Scrapy,Python}",United States,cB,"","",2024-02-23 17:34:15.985516,2024-02-23 17:34:15.985516
https://www.upwork.com/jobs/Data-mining-and-extraction-expert_~01e2e656f7bdaa1450/?referrer_url_path=/nx/search/jobs/,Data mining and extraction expert ,2024-02-20 15:05:19,"We are seeking a skilled and detail-oriented Data Mining Specialist to help us gather essential information from a spreadsheet containing a list of UK medical practices. The task involves iterating over the spreadsheet, extracting key details such as:
- practice website link
- the digital health platform being used by the practice
 - FootFall, Askmygp, Accurx, EMIS, Private Hospital, SystmOnline, Patchs AI, eConsult, Engage Consult
- and gathering reviews with corresponding star ratings

Responsibilities:
- Iterate over a provided spreadsheet containing practice names and addresses of UK medical practices.
- Use the Google Maps API to retrieve the following:
 - Research and identify the official website for each practice.
 - Determine the specific digital platform utilized by each practice (e.g., Accurx).
 - Retrieve and compile reviews along with their respective star ratings for each practice","{Scrapy,'"Beautiful Soup'",RapidMiner,Selenium,pandas,'"Lead Generation'",'"Data Mining'",'"Data Extraction'",'"Data Scraping'",Python}",Pakistan,a,"","",2024-02-23 17:34:15.994277,2024-02-23 17:34:15.994277
https://www.upwork.com/jobs/Web-scraping-find-specific-results_~01662127e7def0a43a/?referrer_url_path=/nx/search/jobs/,Web scraping to find specific results,2024-02-20 13:45:28,"I want someone to provide me with a script that I can use to web scrape google search results for specific key word, for example I want to find sellers on etsy, and I want to results shown to me.
","{'"Data Scraping'",'"Data Mining'",Python,'"Data Entry'",Scrapy}",United Kingdom,a,"","",2024-02-23 17:34:16.003315,2024-02-23 17:34:16.003315
https://www.upwork.com/jobs/Commerce_~018c2adddf7655917b/?referrer_url_path=/nx/search/jobs/,Commerce,2024-02-20 11:33:00,"Greetings,
would you be able to support me and my partners in creating a stock asset management? 
My collaborators and I are working on an artificial intelligence algorithm. We have numerous contacts with potential investors and are seeking experienced professionals with additional connections to join us in this project. Could you support us in this? 
Thank you and good work.

Luca Dainesi","{'"List Building'",'"Lead Generation'",Python,'"Data Mining'",'"Data Scraping'",Selenium,Scrapy,Automation,'"Python Script'",Scripting,'"Web Crawling'",'"Data Extraction'",'"Prospect List'",'"Web Scraping'",'"Email List'"}",Italy,a,"","",2024-02-23 17:34:16.013514,2024-02-23 17:34:16.013514
https://www.upwork.com/jobs/Create-schedule-based-server-for-python-script_~0154a22de23848070a/?referrer_url_path=/nx/search/jobs/,Create a schedule based server for python script,2024-02-18 17:34:18.179963,I have 2 python scripts written to scrape data I need to create  schedule based server to run them daily,"{'"Data Extraction'",'"Data Mining'",'"Web Crawling'",Scrapy,'"Beautiful Soup'",Python,Automation,'"Data Scraping'",'"Python Script'",API}",Pakistan,a,"","",2024-02-23 17:34:18.18244,2024-02-23 17:34:18.18244
https://www.upwork.com/jobs/Data-Scraper-and-Lead-Generation-Specialist_~01a97fe5f3ea4e2c76/?referrer_url_path=/nx/search/jobs/,Data Scraper and Lead Generation Specialist,2024-02-20 17:34:16.020542,"Hello, I am looking for a good data scraper able to generate leads for us as well.
We are a consulting firm based in Lebanon, and we have a presence and clients in Saudi Arabia and UAE.
We need to generate leads from these 

Primary markets:
1- KSA
2- UAE

Secondary markets:
1- Lebanon
2- Qatar
3- Kuwait
4- Bahrain
5- Egypt

The requirements are (but not limited to):

1- Develop and implement effective data scraping techniques to extract relevant information from websites, social media platforms, directories, and other online sources.

2- Utilize a variety of data scraping tools and software, ensuring compliance with legal and ethical standards.

3- Generate outbound leads by identifying potential clients or customers through targeted data collection and analysis.

4- Conduct thorough research to verify and enrich profile information, ensuring high levels of accuracy and completeness.

5- Collaborate with the sales and marketing teams to align data scraping and lead generation efforts with overall business strategies.

6- Maintain up-to-date knowledge of industry trends, tools, and best practices in data scraping and lead generation.

7- Develop and maintain databases to store and organize collected data, ensuring easy access and retrieval for future use.

8- Monitor and evaluate the effectiveness of data scraping and lead generation strategies, making adjustments as necessary to optimize results.

You will collaborate with the business development team to lay out effective strategies and to move forward. 
KPI''s and targets will be set once the strategy is approved. We are looking for a long-term and proactive candidate that can provide accurate data and leads.","{'"Online Research'",Scrapy,'"Beautiful Soup'",'"Data Scraping'",'"Data Mining'",'"Lead Generation'",'"Data Entry'",'"List Building'",'"Prospect List'",'"Microsoft Excel'"}",Lebanon,$5.00-$50.00,"","",2024-02-23 17:34:16.022605,2024-02-23 17:34:16.022605
https://www.upwork.com/jobs/Optimization-Scrapy-script_~01d8a09c971cd3dcb2/?referrer_url_path=/nx/search/jobs/,Optimization of Scrapy script,2024-02-20 07:03:05,"Hello!

I''m looking for a specialist with experience in optimizing Scrapy for web crawling.

Currently I have an existing Python script that correctly extracts entire website as a text and saves it in JSON file. I don''t need to do any sophisticated data extraction by Scrapy, because I have offline scripts taking care of that.

In the crawler I am using headless browser (using Playwright package) to properly load entire website, as well as asyncio (mostly as an attempt to improve speed).

Script is deployed on Zyte (Scrapy Cloud) website and at the moment it maxes at around 12 items (i.e. pages) per minute. Which I find very slow and I''d like to improve that.

Websites that I am crawling are Polish real estate websites like otodom.pl . Based on my work so far there is no need to actually know any Polish because everything in the backend appears to be written in English.

Thank you and waiting for offers,
Sebastian ","{Scrapy,Python,'"Web Crawling'"}",United States,a,"","",2024-02-23 17:34:16.03294,2024-02-23 17:34:16.03294
https://www.upwork.com/jobs/Train-person-HTML-web-scraping-html-parsing-preprocessing-for-insert-into-Neo4j_~01cfc7cbd4dee2d39a/?referrer_url_path=/nx/search/jobs/,"Train a person to do HTML web scraping, html parsing,  preprocessing for insert into Neo4j db.",2024-02-20 17:34:16.046694,"Seeking a patient and knowledgeable HTML Parsing Trainer to provide one-on-one training sessions for a beginner. The focus of this training will be on hands-on learning experiences, allowing the individual to gain practical skills in HTML parsing and web scraping.

Key Responsibilities:
1. Conduct hands-on training sessions focused on HTML parsing and web scraping for the beginner. These sessions will involve guiding the individual through practical exercises and real-world examples to help them grasp key concepts.
2. Provide personalized instruction and support to address the specific learning needs and goals of the individual. This may include breaking down complex topics into simple, easy-to-understand explanations and offering additional guidance as needed.
3. Demonstrate best practices and techniques for navigating and extracting data from HTML documents using Beautiful Soup/other library tools. Show the individual how to apply these techniques in real-world scenarios to collect and analyze data effectively.
4. Offer guidance on troubleshooting common challenges and errors encountered during HTML parsing and web scraping activities. Help the individual develop problem-solving skills and strategies for overcoming obstacles independently.
5. Teach methods for loading the extracted data into databases, such as MySQL, PostgreSQL, or Neo4j. Provide guidance on designing database schemas, writing SQL queries, and automating data loading processes.
6. Instruct on how to convert the extracted data into JSON and CSV formats for further analysis or sharing. Cover topics such as data serialization, formatting, and transformation using Python libraries like Pandas or built-in functions.
","{'"Data Scraping'",Python,Selenium,HTML,ETL,'"Web Crawling'",'"Data Cleaning'",Automation,Scrapy,'"Data Extraction'"}",United States,bO,"","",2024-02-23 17:34:16.049355,2024-02-23 17:34:16.049355
https://www.upwork.com/jobs/Scrape-website-data-using-scrapy-scrape_~011c532ecad98857aa/?referrer_url_path=/nx/search/jobs/,Scrape website data using scrapy scrape,2024-02-19 17:34:16.065439,data scraped from website and added to microsoft excel format for all certified brands listed on this website: https://www.changeclimate.org/certified-brands,"{'"Data Scraping'",Scrapy,'"Data Mining'",'"Data Extraction'"}",United States,a,"","",2024-02-23 17:34:16.067694,2024-02-23 17:34:16.067694
https://www.upwork.com/jobs/Website-Scraping-PDFs_~017118ada3e43e34b5/?referrer_url_path=/nx/search/jobs/,Website Scraping to PDFs,2024-02-19 21:40:36,"Hi There, we would like to scrape a website of a partner of ours to extract all their screens into PDF documents. Ideally, this can be automated. However, it could also be done manually I guess. It''s a .com domain and the site is publicly available - no login required. Ideally, this is a short term project. ","{'"Data Extraction'",'"Web Scraping'",'"Summary Report'",'"Data Scraping'",Scrapy}",Switzerland,a,"","",2024-02-23 17:34:16.077035,2024-02-23 17:34:16.077035
https://www.upwork.com/jobs/Urgent-Scraper-Code-Script-Needed-for-LinkedIn-search-results_~01743e8886c624462d/?referrer_url_path=/nx/search/jobs/,Urgent: Scraper (Code/ Script Needed) for LinkedIn search results,2024-02-19 21:34:35,"Please read carefully before applying.

The primary skill is web scraping. It is even better if you do lead generation via LinkedIn. 

LinkedIn Business Account search results need to be scrapped. The project needs to make a script which can be run from cmd and can scrape data from LinkedIn Business account to an Excel sheet and also store to an MS Access database. Extract first name, last name, company, company size, link to company''s linkedin profile, contact location, title, time in role, email, phone number, link to contact''s linkedin profile.","{'"Data Scraping'",'"Lead Generation'",Python,Scripting,Scrapy,Automation,PHP,'"Microsoft Excel'"}",United States,$3.00-$15.00,"","",2024-02-23 17:34:16.086399,2024-02-23 17:34:16.086399
https://www.upwork.com/jobs/Scrapy-Web-Scraping-Experts_~013828517fe54e7924/?referrer_url_path=/nx/search/jobs/,Scrapy / Web Scraping Experts,2024-02-19 17:34:16.09315,"To scrape data from the website
-Data scraped to be saved into a database
-To fix some problems related to scrap

I will provide my existing py in py2.
You shall convert it into py3.
You shall install the applications required in my VPS to run those py3.","{pandas,SQL,Scrapy,Python,'"Data Scraping'"}",Egypt,a,"","",2024-02-23 17:34:16.094925,2024-02-23 17:34:16.094925
https://www.upwork.com/jobs/Web-scrapping-tool_~01ef288c9d15040f59/?referrer_url_path=/nx/search/jobs/,Web scrapping tool,2024-02-19 17:34:16.10176,"I need to create a web scrapping tool to retreive data from the following website :

www.wargamespirit.com",{Scrapy},France,a,"","",2024-02-23 17:34:16.10381,2024-02-23 17:34:16.10381
https://www.upwork.com/jobs/Python-PHP-Webscraping-Expert_~01295e7b3758514a7a/?referrer_url_path=/nx/search/jobs/,Python or PHP Webscraping Expert,2024-02-18 17:34:18.192298,"Looking for web scraping expert who can quickly create scripts to scrap data from web for analytics using python or php, teh scripts should be fast and efficient, no need for proxy as most is open data , the person should have good availability and excellent skills. ","{Python,'"Data Scraping'",PHP,MySQL,Scrapy,'"Python Script'"}",United Arab Emirates,$20.00-$45.00,"","",2024-02-23 17:34:18.194338,2024-02-23 17:34:18.194338
https://www.upwork.com/jobs/Data-Scrapping-from-the-list-websites_~019df6bd963a07ecfe/?referrer_url_path=/nx/search/jobs/,Data Scrapping from the list of websites,2024-02-19 17:34:16.111905,"As a Data Scraping Specialist, your primary responsibility will be to extract and collect numerical information from specified lists or sources. You will employ specialized scraping techniques and tools to efficiently gather relevant data while ensuring accuracy and completeness. Your role will involve understanding the intricacies of data sources, adapting to website structures, and overcoming potential obstacles in the scraping process. Additionally, you will collaborate with cross-functional teams to enhance data quality and provide valuable insights for further analysis. Strong attention to detail, problem-solving skills, and proficiency in programming languages commonly used in web scraping are essential for success in this role.","{'"Data Scraping'",Scrapy,'"Data Extraction'",Python}",Pakistan,cB,"","",2024-02-23 17:34:16.114191,2024-02-23 17:34:16.114191
https://www.upwork.com/jobs/Job-Board-scraper-aggregator_~01a150c290ad0cdf88/?referrer_url_path=/nx/search/jobs/,Job Board scraper aggregator,2024-02-19 17:34:16.122161,"I want to create a Python scraper as described involves several steps and requires handling various data formats and authentication methods. Below is a simplified version of a script that outlines the basic structure to accomplish your requirements. This example assumes that you have a CSV file with details for each endpoint (like URL, type of data format, and credentials if needed), and you are familiar with Python, requests, BeautifulSoup, and pandas libraries for web scraping, data parsing, and CSV manipulation.","{Selenium,'"Beautiful Soup'",'"API Integration'",'"Data Integration'",'"Web Crawling'",'"Screen Scraping'",Scrapy,'"Data Scraping'",Python,'"Data Mining'"}",United States,$18.00-$40.00,"","",2024-02-23 17:34:16.125002,2024-02-23 17:34:16.125002
https://www.upwork.com/jobs/Google-Maps-Data-scraping_~0182fd59069691ad44/?referrer_url_path=/nx/search/jobs/,Google Maps Data scraping ,2024-02-19 17:19:00,"Need company contact details scraped from Google Maps in a G-Sheets. 

Target Audience:
Company industry: Beauty salon, nail studios, massage studio and solarium
Location: Hamburg, Germany

!Important! - Company must have at least 4,5 stars and 50 reviews on Google Maps 

Needed information: Company name, e-mail, phone, address &amp; contact name ","{'"Data Scraping'",Scrapy,'"Data Mining'",'"Data Extraction'"}",Germany,a,"","",2024-02-23 17:34:16.13459,2024-02-23 17:34:16.13459
https://www.upwork.com/jobs/Social-Media-Automation-Tool_~013b31ea1da979f852/?referrer_url_path=/nx/search/jobs/,Social Media Automation Tool,2024-02-19 13:13:24,"Hello everyone.

I''m seeking someone with experience in building automation for social media apps and dating apps like Snapchat, TikTok, Instagram, Reddit, Tinder, and Bumble.

The automation will need some tasks such as:
- account creation
- verification of the account
- warm-up of the accounts
- integration via API of an LLM model provided by me

Please share any of the past projects you did in this field with me.
Only experts and people who had previous experience in this field.

PS: The budget is just a placeholder. I''m assuming quality work can cost even more.

Thanks.

","{'"API Integration'",Selenium,Scrapy,JavaScript,PHP,TypeScript,'"Data Scraping'",Automation,Python,API}",Italy,a,"","",2024-02-23 17:34:16.143024,2024-02-23 17:34:16.143024
https://www.upwork.com/jobs/Data-mining-expert-scrape-corporate-executive-contact-information_~016f2074eb8319d41a/?referrer_url_path=/nx/search/jobs/,Data mining expert to scrape corporate executive contact information,2024-02-19 13:00:37,"We are seeking a skilled and detailed data mining expert to assist us in finding accurate contact information for a list of identified executives within various companies. As part of our business development efforts, we require up-to-date and verified contact details, including email addresses and direct dial office phone numbers, for key decision-makers in these organizations.  We also want to have you find LinkedIn URL using sales navigator.  ","{'"Online Research'",'"List Building'",Scrapy,'"Data Scraping'",'"Data Mining'",'"Data Entry'",'"Prospect List'",'"Microsoft Excel'"}",United States,a,"","",2024-02-23 17:34:16.151215,2024-02-23 17:34:16.151215
https://www.upwork.com/jobs/commerce-Scraping_~016fe982cd5fa3aead/?referrer_url_path=/nx/search/jobs/,E-commerce Scraping,2024-02-19 08:48:28,"
Here are some of the fields we need:
title, product description (We want to improve descriptions and keywords using ChatGPT), category, product link, brand, brand_link, price, rrp, rating, review_count, review text (we want to use chatGPT to analyze reviews and suggest product improvement), Other offers (competing  offers), barcode (We can use it to check how many other sellers are competing), stock_status (Lead-Time, JHB or CPT, these are warehouses or merchant fulfilled methods) seller_name, seller_id, seller_link, merchandising_tags_text, merchandising_tags_link, image_url, Number of listings (If possible, the scipt should also click on the sell''s link and count the number of products they have listed), stock level (if possible the script should click on add-to-cart, add 50 items in the cart to see how many they actually have in the warehouse). Thanks, we will discuss more attributes						
","{Scrapy,Python,'"Data Mining'",Selenium,'"Data Scraping'",'"Beautiful Soup'",'"Data Extraction'",'"Data Engineering'",'"Web Scraping'",'"Web Scraping Framework'",Python-Requests,'"Screen Scraping'",'"Web Scraping Plugin'",'"Web Scraping Software'",'"Data Collection'"}",South Africa,a,"","",2024-02-23 17:34:16.160786,2024-02-23 17:34:16.160786
https://www.upwork.com/jobs/Web-scraping_~01398357d59e7e001d/?referrer_url_path=/nx/search/jobs/,Web scraping,2024-02-19 17:34:18.150462,"We are looking for a talented web scraping expert to help us extract data from various websites for a project we are working on. The ideal candidate should have experience with creating custom web scraping scripts and tools to efficiently extract data from websites and save it in a structured format.

Responsibilities:
- Develop custom web scraping scripts or tools to extract specific data from target websites
- Ensure data is extracted accurately and saved in a structured format such as CSV or Excel
- Optimize web scraping scripts for efficiency and performance
- Work closely with our team to understand project requirements and deliver data in a timely manner

Requirements:
- Proven experience with web scraping techniques and tools
- Proficiency in programming languages such as Python, Java, or similar
- Familiarity with web technologies including HTML, CSS, and JavaScript
- Strong attention to detail and problem-solving skills
- Good communication skills and ability to work collaboratively with a remote team

If you have the skills and experience to help us with this project, please submit your proposal with details of your previous web scraping projects and relevant experience. We are looking to hire a talented and reliable freelancer who can deliver high-quality results. Thank you.","{Scrapy,SQL,Python,'"Data Entry'",'"Data Scraping'",'"Data Mining'",'"Beautiful Soup'",Selenium,'"Lead Generation'",'"Web Crawling'",Django,'"Data Extraction'",Automation,'"Web Scraping'",JavaScript}",Georgia,a,"","",2024-02-23 17:34:18.153845,2024-02-23 17:34:18.153845
https://www.upwork.com/jobs/Create-proxy-based-server-for-python-script_~016acb495504559655/?referrer_url_path=/nx/search/jobs/,Create a proxy  based server for python script,2024-02-19 17:34:18.161465,I have 2 python scripts written to scrape data I need to create  proxy  based server to run them ,"{'"Data Extraction'",'"Data Mining'",'"Web Crawling'",Scrapy,'"Beautiful Soup'",Python,Automation,'"Data Scraping'",'"Python Script'",API}",Pakistan,a,"","",2024-02-23 17:34:18.163719,2024-02-23 17:34:18.163719
https://www.upwork.com/jobs/Extract-data-from-public-database-and-write-them-Gdrive-using-Python_~01c5fde6e1b0dbd7ec/?referrer_url_path=/nx/search/jobs/,Extract data from public database and write them in Gdrive using Python,2024-02-17 17:34:18.200857,"Build a robot (RPA) using Python, that will help the user interact with a public database and automatically extract certain data. 

I provide you two sources with useful files:
1. Attached pdf file with instructions/steps to be followed in building the robot
2. Gdrive link with other relevant files
https://drive.google.com/drive/folders/1YQF6NyV2WxJIQrHeLwNOPcLAa6FFsLtI?usp=drive_link

To note, I will prioritize candidates that have thoroughly read the instructions, before contacting me.","{'"Beautiful Soup'",Scrapy,Selenium,Python,'"Data Scraping'"}",Switzerland,a,"","",2024-02-23 17:34:18.202814,2024-02-23 17:34:18.202814
https://www.upwork.com/jobs/Webscrape-expert_~01f69e42328fae1f0d/?referrer_url_path=/nx/search/jobs/,Webscrape expert,2024-02-17 16:34:49,"Perform a data search for all wholesalers and retailers of lamps, lamp makers, makers of lamp parts, lamp shades in the US. Categorize by type of company.  Produce company name address, owner name, email, phone number; buyer name, phone and email, other employee name phone and email.

We are a company that sells glass lamps shades for lamps, chandeliers, fans, sconces, primarily to residential but some hotels and film industry. We do not need information on  large lighting corporations, outdoor lighting or the like.

Need asap.
Potential for more work.","{Python,'"Web Crawling'",'"Data Scraping'",Scrapy}",United States,a,"","",2024-02-23 17:34:18.21153,2024-02-23 17:34:18.21153
https://www.upwork.com/jobs/Lead-Scraping-Clean-Indian-Restaurant_~01a02b503106416351/?referrer_url_path=/nx/search/jobs/,Lead Scraping - Clean Indian Restaurant,2024-02-17 17:33:30,"Looking for some scrapers, or have built list of indianr estaurant.
","{'"Web Scraping'",'"Web Crawler'",'"Lead Generation'",'"Data Mining'",'"Lead Capture'",'"Data Extraction'",'"Data Scraping'",Scrapy,'"Email Marketing'",'"LinkedIn Lead Generation'",'"Web Scraping Software'",'"Screen Scraping'",Python,'"Data Entry'",'"List Building'"}",Norway,$4.00-$8.00,"","",2024-02-23 17:34:18.219858,2024-02-23 17:34:18.219858
https://www.upwork.com/jobs/Web-scraping_~016eb6773c2a295ada/?referrer_url_path=/nx/search/jobs/,Web scraping ,2024-02-17 17:34:18.226,"Hello, im looking for someone who can do web scrapping with python.Im creating an anime website and i want to import iframes from a website like animelek and anime4up for my wordpress plugins so when i scrap it i can automatically publish it.

 the script should be something like this:","{Selenium,'"Data Scraping'",pandas,'"Data Extraction'",'"Web Scraping Framework'",'"Beautiful Soup'",'"Web Scraping'",Python,Scrapy,'"Selenium WebDriver'",'"Web Crawling'",'"Browser Automation'",'"Data Mining'",Scripting,Automation}",Austria,a,"","",2024-02-23 17:34:18.228486,2024-02-23 17:34:18.228486
https://www.upwork.com/jobs/Machine-learning-for-stock-optimization_~0150ed8b8b2d00e1ca/?referrer_url_path=/nx/search/jobs/,Machine learning for stock optimization ,2024-02-17 17:34:18.236402,Looking to leverage sales and inventory data from several years to determine purchasing requirements of stock ,"{'"Beautiful Soup'",Scrapy,Python,'"Data Scraping'",Selenium,NLTK,'"Machine Learning'",'"Big Data'",'"System Deployment'",Automation,'"Artificial Intelligence'",'"Web Proxy'",'"Data Processing'"}",United States,a,"","",2024-02-23 17:34:18.239066,2024-02-23 17:34:18.239066
https://www.upwork.com/jobs/Need-python-scraper-script_~016fb00e2a6d27fb31/?referrer_url_path=/nx/search/jobs/,Need python scraper script ,2024-02-17 17:34:18.245481,"I want you to create a scraper that gathers every realestate listing from a URL and for it to run every single day, 

I want the code to extract every new listing and stop scraping once it finds yesterdays first listing that it has already scraped. 

This looks like an easy job to start, but it is a little challenging. The website uses anti-bot security called Kasada to protect their data from being scraped. Don''t bother applying if you''re going to use GPT, I have already tried!

This is an example URL, however, I want it to be expandable to other locations that i set. 
https://www.realestate.com.au/buy/property-house-with-1-bedroom-size-500-1750-between-50000-650000-in-deception+bay,+qld+4508%3b+bracken+ridge,+qld+4017%3b+crestmead,+qld+4132%3b+norlane,+vic+3214%3b+morphett+vale,+sa+5162/list-1?source=refinement

Thank you for reading this far, to know that you understand what I require and can prove to create the code

The code is already done in requests library but the issue it does not run on gcp cloud function and cookies expire after one day it needs to be done in request library","{'"Data Extraction'",'"Task Automation'",'"Web Crawling'",'"Beautiful Soup'",Selenium,Python,'"Data Scraping'",'"Python Script'",Scrapy,Automation}",Pakistan,a,"","",2024-02-23 17:34:18.247836,2024-02-23 17:34:18.247836
https://www.upwork.com/jobs/Scrape-website_~011988923a48162cd1/?referrer_url_path=/nx/search/jobs/,Scrape a website,2024-02-17 17:34:18.254974,"Scrape data from the website below (login required to view the data unfortunately). I received hundreds of resume but the site does not allow searches based on keywords. That''s why I need to scrape the data and dump it to a spreadsheet.

https://www.jobstreet.co.id/","{Python,'"Data Scraping'",'"Data Mining'",'"Web Crawling'",'"Data Extraction'",JavaScript,Scrapy}",United States,a,"","",2024-02-23 17:34:18.257162,2024-02-23 17:34:18.257162
https://www.upwork.com/jobs/Bot-For-Tik-Tok-Shop_~017217869a8e1d699f/?referrer_url_path=/nx/search/jobs/,AI Bot For Tik Tok Shop,2024-02-16 21:44:39,"I need a bot that contacts affiliates on my brands behalf, to work with us they would get 25% of each sale they make through there affiliate link and I just want a bot that’s at least being able to send 2000-3000 messages a day on Tik tok","{Python,Golang,Node.js,Blockchain,'"Python Script'",Bot,'"Bot Development'",'"Web Scraping'",Scrapy,'"Blockchain, NFT & Cryptocurrency'",'"Web Development'",Automation,'"REST API'",API}",United States,a,"","",2024-02-23 17:34:18.264303,2024-02-23 17:34:18.264303
https://www.upwork.com/jobs/Web-Scraping-Data-Collection_~017a42869cc921d0b4/?referrer_url_path=/nx/search/jobs/,Web Scraping Data Collection,2024-02-16 14:29:09,"We are looking for a skilled professional to collect data from websites for our business. The job will involve navigating through websites, identifying relevant data, and extracting it in a structured format. The ideal candidate should have experience in web scraping and data extraction techniques. Strong attention to detail and accuracy are essential for this role. The successful candidate will work closely with our team to ensure the data collected meets our requirements and specifications. This is a project-based job that can be completed within a short time frame. 

Relevant skills:
- Web scraping
- Data extraction
- Attention to detail
- Accuracy
- Data analysis","{'"Data Scraping'",'"Data Mining'",Scrapy,'"Data Extraction'"}",Germany,a,"","",2024-02-23 17:34:18.271737,2024-02-23 17:34:18.271737
https://www.upwork.com/jobs/LinkedIn-Data-Scraper_~01cac7b4fa71278cd0/?referrer_url_path=/nx/search/jobs/,LinkedIn Data Scraper,2024-02-15 05:08:01,"Need an expert to scraped LinkedIn data for us. We''d want as many fields as we can. We''d want to scrape the entire dataset. Only experienced scrapers that have experience scraping LinkedIn data please. Thanks.

","{'"Data Scraping'",Scrapy,Python-Goose,'"Lead Generation'",'"Data Mining'",Python,'"Data Entry'",pandas}",United States,$40.00-$65.00,"","",2024-02-23 17:34:18.404536,2024-02-23 17:34:18.404536
https://www.upwork.com/jobs/Python-Web-Scraping-Developer_~0166ff413f7a1aff9b/?referrer_url_path=/nx/search/jobs/,Python Web Scraping Developer,2024-02-16 17:28:37,"Job Overview:
We are seeking a skilled Python Web Scraping Developer to join our team. The successful candidate will be responsible for developing and maintaining web scraping scripts and tools to extract PDF files from various websites efficiently and accurately. This role requires a deep understanding of Python programming, web scraping techniques, and data handling.

Key Responsibilities:
Develop and maintain web scraping scripts: Write and optimize Python scripts to automate the extraction of PDF files from specified websites. Ensure scripts can adapt to different website structures and dynamically loaded content.

Automated data extraction and processing: Implement automated processes for extracting relevant data from PDFs, maintaining accuracy and integrity. Convert extracted data into a structured format for further analysis or storage, using automated tools where possible.

Website analysis and automated troubleshooting: Utilize automated tools to analyze website structures for efficient scraping methods. Develop scripts that automatically detect and resolve common scraping issues, such as changes in website layouts and anti-scraping mechanisms.

Automation of documentation and reporting: Create automated documentation processes for scraping activities and develop reporting tools that provide regular updates on scraping activities, data quality, and system performance.



Interested candidates with direct experience in web scraping using Python and BeautifulSoup are encouraged to apply. Additionally, include any relevant work samples or project portfolios that demonstrate your proficiency and accomplishments in Python web scraping with BeautifulSoup.","{Automation,Scripting,'"Data Extraction'",'"Beautiful Soup'",Python,'"Data Scraping'",'"Web Crawling'",Scrapy,Selenium,'"Data Mining'"}",India,$30.00-$60.00,"","",2024-02-23 17:34:18.278365,2024-02-23 17:34:18.278365
https://www.upwork.com/jobs/Scrapping-Database-hacking_~01658e9c5c2b4813df/?referrer_url_path=/nx/search/jobs/,"Scrapping, Database hacking ",2024-02-16 12:38:34,"I''m looking for a person who can access a source that transmits data in the form of live broadcasts, streams without delays to bookmakers.

At the moment there is the following information, I don’t know if it will help you in your work.
The main request is the possibility of receiving live broadcasts, broadcasts without delays from beter.co sources
https://www.beter.co/
https://www.esportsbattle.com/

These companies provide information to Bookmakers, some of them are given broadcasts (servers), public/stream/trading/demo.
Each server can have different variations, either public, or only stream, or trading or demo
The whole difference between them lies in the delay timings.

The minimum we need is trading - it should be + - level with the closing of the line in the bookmaker.
Change in goal odds (bet365 and other bookmakers) - approximately 1:1 on FIFA-1-2-3-4 channels with world time second per second)
It is unknown which server the broadcasts are on, the previous servers were disabled, these links were previously known:

https://streamarchive.beter.co/trading/fifa/1/embed.html?realtime=true

http://212.117.165.28/trading/fifa/1/embed.html?realtime=true

(same server)

(1,2,3,4)

As I understand it, they gave someone a demo test through the server, and perhaps they have a main one that clients use.

There was also access to https://console.beter.co/,
but the broadcasts there were inappropriate in terms of timing, they remained for 5 or more seconds.

For example eSportsBattle FIFA
2 players play FIFA on PS, from the game console the information is somehow transmitted to the server, processing is done, the players’ web cameras are superimposed and subsequent information is transmitted to another server, then to the trading department of bookmakers who keep the score (update the odds) - that’s all this is figurative, there is no understanding of how it actually works exactly.","{Scrapy,'"Data Scraping'",Python,'"Database Management'",PHP,SQL,'"Web Crawling'",'"File Management'",Python-Goose,MySQL}",Kazakhstan,a,"","",2024-02-23 17:34:18.286271,2024-02-23 17:34:18.286271
https://www.upwork.com/jobs/Data-Engineer-Web-Scraping-Specialist_~01b1746966643f24db/?referrer_url_path=/nx/search/jobs/,Data Engineer - Web Scraping Specialist,2024-02-16 17:34:18.292347,"We are seeking a skilled and motivated Data Engineer with expertise in web scraping, cloud technologies, and data extraction from various social media platforms. If you have a strong background in Python, Linux, Docker, and experience with GCP tools such as Big Query, Cloud Run, Cloud Functions, and VMs, we want to hear from you!
**Key Responsibilities:**
1. **Docker Knowledge:**
   - Proficient in Docker to create and manage containers for efficient deployment.
2. **Social Media Scraping:**
   - Utilize Selenium for Facebook, LinkedIn, and Twitter to open browsers and scrape relevant data.
   - Implement scraping strategies for Instagram using Requests and three proxies to gather valuable insights.
3. **YouTube Data Extraction:**
   - Leverage the Google YouTube API to extract data seamlessly and efficiently.
4. **Cloud Technologies:**
   - Apply expertise in GCP storage, Big Query, Cloud Run, and Cloud Functions for data storage, processing, and deployment.
**Qualifications:**
- Solid proficiency in Python, including web scraping libraries and frameworks.
- Strong knowledge of basic Linux commands.
- Experience with Docker and containerization techniques.
- In-depth understanding of GCP tools, including Big Query, Cloud Run, Cloud Functions, and VMs.
- Proven track record in web scraping using Selenium for major social media platforms.
- Familiarity with API integration, especially with the Google YouTube API.
- Ability to optimize web scraping processes for efficiency and reliability.
- Excellent problem-solving skills and attention to detail.
**How to Apply:**
If you are passionate about data engineering, web scraping, and leveraging cloud technologies, please submit your resume and a cover letter outlining your relevant experience. Be sure to highlight your expertise in Python, Linux, Docker, and your achievements in web scraping projects.
Join our dynamic team and contribute to cutting-edge projects at the intersection of data engineering and social media analytics!
Important Responsibilities:
Currently We have script which picks Facebook and Instagram pages URL from a file. Open these in selenium an fetch likes and follower from the page. We are facing issue in this script from few days it worked fine but now Facebook start detecting account and blocking it.
We need someone who can resolve this issue and some solution for it. Also check for any other security issue is there.
after fix at least one week''s tracking is required to verify if it doesn''t block accounts again.


","{'"Screen Scraping'",'"Web Crawling'",'"Selenium WebDriver'",Scrapy,Selenium,'"Beautiful Soup'",'"Data Scraping'",'"Data Mining'",'"Data Extraction'"}",India,$15.00-$35.00,"","",2024-02-23 17:34:18.294041,2024-02-23 17:34:18.294041
https://www.upwork.com/jobs/Python_~01669ac3028e57a286/?referrer_url_path=/nx/search/jobs/,"Python
",2024-02-16 17:34:18.300496,"Привіт, потрібно підтримка та апгрейд парсера на Python. Є парсер який працює, інколи там може щось злетіти або потрібно його оновити чи доробити.","{Python,'"Bot Development'",Scripting,Automation,MySQL,Django,Scrapy,'"Web Scraping'",'"Beautiful Soup'",'"Data Scraping'",'"Data Extraction'",Docker,CI/CD}",Ukraine,a,"","",2024-02-23 17:34:18.302714,2024-02-23 17:34:18.302714
https://www.upwork.com/jobs/Quick-webscraping-project-scrape-URL-nightly-table-using-python-columns_~0191196bf90ba433cc/?referrer_url_path=/nx/search/jobs/,Quick webscraping project - scrape URL nightly to a table using python. 5 columns.,2024-02-16 07:10:47,"A website publishes a simple table with 5 columns and about 100 rows. 

We need a python to check the site each night at 3AM EST. The site displays a date stamp in the header for when it''s updated. If it''s updated, scrape the table, add the data to rows in a database. We also need to merge in historic data from a spreadsheet that''s been hand compiled. 

The script will live on Azure. We need an Azure function or cron to trigger it nightly. 

The data will first live in a CSV for testing purposed, then we will need to modify Python to add the data to a MSSQL table. 

That''s Phase 1. Should only take a few hours to a day max.
","{'"Beautiful Soup'",'"Web Scraping'",'"Data Extraction'",'"Data Integration'",Python,'"Data Scraping'",Scrapy,pandas}",United States,a,"","",2024-02-23 17:34:18.311449,2024-02-23 17:34:18.311449
https://www.upwork.com/jobs/Bypass-queue-for-tickets_~011f5d09e3f9705622/?referrer_url_path=/nx/search/jobs/,Bypass queue for tickets,2024-02-16 02:00:00,"In short,  i need someone who can bypass and skip a queue when the tickets go on sale.  

Need a website scripter who can through scripts or any technology can be able to bypass datadome protected site.
Need to have experience with datadome bypassing sites
Need to have experience with ip routing  for not to get blocked
Need to have experience in building scripts or bots.
This you can write as a job post and can interact with whoever sends proposal","{Automation,'"Business Process Automation'",'"Beautiful Soup'",'"Trading Automation'",Scrapy,'"Automation Anywhere'",Python,HTML,Java}",United Kingdom,a,"","",2024-02-23 17:34:18.320474,2024-02-23 17:34:18.320474
https://www.upwork.com/jobs/Create-comprehensive-list-Immigration-Attorney_~01a77cee16f490e543/?referrer_url_path=/nx/search/jobs/,Create a comprehensive list of Immigration Attorney's,2024-02-15 18:38:40,"I am looking to build a list of all licensed immigration attorney''s in the top 20 cities in the US by populations and include the following states.

Missouri
Kansas
Florida
then top 20 cities by population

I will need, their name, email, phone number, address, website (if applicable) are they ranked on google, meaning do they have reviews","{'"Data Scraping'",'"Data Mining'",Python,Scrapy,pandas,'"Microsoft Power BI'",'"List Building'",'"Research & Strategy'",'"Legal Research'",'"Microsoft Excel'"}",United States,$7.00-$20.00,"","",2024-02-23 17:34:18.330707,2024-02-23 17:34:18.330707
https://www.upwork.com/jobs/Need-LinkedIn-scraper-script-python_~013ba10d0133c10461/?referrer_url_path=/nx/search/jobs/,Need LinkedIn scraper script in python,2024-02-15 18:08:57,"Need a python script for LinkedIn that can scrape profiles data like all education with dates and degrees ,all experiences with title ,company and dates ,name ,location ,email ,phone ,about ,skills I need script that is already done I nedd it done tomorrow urgently ","{'"Data Extraction'",'"Web Scraping'",'"Screen Scraping'",ETL,'"Selenium WebDriver'",Selenium,'"Data Scraping'",Python,Scrapy,'"Web Crawling'"}",Pakistan,a,"","",2024-02-23 17:34:18.34041,2024-02-23 17:34:18.34041
https://www.upwork.com/jobs/Parse-website-extract-data-database_~01aff4ddaced24e194/?referrer_url_path=/nx/search/jobs/,"Parse website, extract data to database",2024-02-16 17:34:18.41304,"Data Extraction: Navigate through the specified website to locate and extract data according to provided criteria and filters.
Data Organization: Format the extracted data into a CSV file, ensuring it is well-organized and adheres to the required structure for immediate use.
Accuracy and Efficiency: Ensure the data is accurately extracted and the file is delivered within the agreed timeframe.

","{'"Data Scraping'",'"Data Extraction'",Python,Scrapy,Database,'"Microsoft Excel'",SQL,'"File Management'"}",Kazakhstan,a,"","",2024-02-23 17:34:18.414895,2024-02-23 17:34:18.414895
https://www.upwork.com/jobs/Web-Scrapping-using-Python-Selenium_~01a278b32bbb15d011/?referrer_url_path=/nx/search/jobs/,Web Scrapping using Python (Selenium),2024-02-15 15:44:22,"Hi Upworkers!

We are excited to announce a project with a budget of $2,000 USD. As part of the selection process, we will conduct a paid trial task. 

This preliminary task will allow us to assess not only the speed of project delivery but also the quality of your code, its efficiency, and the ability to develop scalable code with future maintenance in mind.

The challenge involves developing a program using Python 3 and Selenium to automate interactions with the Temu.com website. 

The program must be able to extract videos/photos, prices, descriptions, and other relevant details from user-specified search results. 

Moreover, all information gathered from each product should be stored in an Excel sheet, including the URL to access the product directly.

If you successfully complete this trial and evaluation task, we will provide you with the complete details to proceed with the main $2,000 USD project budget.

IMPORTANT
- The trial task must be completed and delivered within a 1 business day timeframe to ensure payment.

- Advanced knowledge in object-oriented programming with Python 3 is essential.

- Experience in using explicit waits in Selenium and managing unique and scalable XPATHs is required.

If you are interested in this project, please let us know your rate for the trial task and share your relevant previous experience.

We will only respond to those who submit their quotation for this paid evaluation task and who can complete it before the deadline, to proceed as soon as possible with the main project.","{Selenium,'"Data Scraping'",Python,'"Selenium WebDriver'",Automation,'"Web Crawling'",Scrapy,pandas,'"Data Mining'"}",Puerto Rico,$15.00-$60.00,"","",2024-02-23 17:34:18.349335,2024-02-23 17:34:18.349335
https://www.upwork.com/jobs/Ecommerce-Website-scraping_~01dd18efcd29a3112d/?referrer_url_path=/nx/search/jobs/,Ecommerce Website scraping,2024-02-16 17:34:18.358642,"We''re collecting some ecommerce websites products information, please read the data format carefully.

Here''re list of websites:

https://global.oliveyoung.com/
https://www.marketonj.co.kr/goods/goods_list.php?cateCd=001
http://minscorporation.co.kr/?n_media=27758&amp;n_query=%EA%B1%B4%EA%B0%95%EA%B8%B0%EB%8A%A5%EC%8B%9D%ED%92%88%EB%8F%84%EB%A7%A4&amp;n_rank=2&amp;n_ad_group=grp-a001-01-000000019698114&amp;n_ad=nad-a001-01-000000122894567&amp;n_keyword_id=nkw-a001-01-000003467420036&amp;n_keyword=%EA%B1%B4%EA%B0%95%EA%B8%B0%EB%8A%A5%EC%8B%9D%ED%92%88%EB%8F%84%EB%A7%A4&amp;n_campaign_type=1&amp;n_ad_group_type=1&amp;n_match=1
http://www.ebobusang.com/
https://www.wsmon.co.kr/
https://nanowellservice.com/mall/index.php
https://dmall.co.kr/category/%EC%A0%84%EC%B2%B4%EB%B3%B4%EA%B8%B0/63/
https://doctorlean.co.kr/goods/catalog?code=00020001
https://doctorlean.co.kr/goods/catalog?code=00020002
https://seasonglass.kr/product/list.html?cate_no=542
https://www.apharmhealth.co.kr/category/%EC%9E%A5%EA%B1%B4%EA%B0%95/70/
https://www.apharmhealth.co.kr/category/%EB%BC%88%EA%B4%80%EC%A0%88/76/
https://www.apharmhealth.co.kr/category/%ED%99%9C%EB%A0%A5%EB%A9%B4%EC%97%AD/73/
https://leveb.kr/product/list.html?cate_no=42
https://na-well.com/shop/shopbrand.html?type=Y&amp;xcode=009
https://vitaminshop.co.kr/product/list.html?cate_no=490
https://vitaminshop.co.kr/product/list.html?cate_no=491
https://www.kgcshop.co.kr/shop/goodsList?ctgryId=51#page1
https://www.neworigin.co.kr/goods/goods_list.php?cateCd=024
https://varihope.com/product/list.html?cate_no=67
https://www.jc-mall.com/board/shop/list.php?ca_id=1020
https://www.jc-mall.com/board/shop/list.php?ca_id=1030
http://www.doctorwa.com/shop/shopbrand.html?type=Y&amp;xcode=047
https://www.cosrx.co.kr/
https://www.isoi.co.kr/product/goods_list
https://www.ckdhcmall.co.kr/
https://esthermall.co.kr/main/index.php
https://www.skinrx.co.kr/
https://troissant.co.kr/
https://ohui.com/
https://clubclio.co.kr/
https://dasique.co.kr/
https://www.oliveyoung.co.kr/store/main/main.do?oy=0&amp;t_page=%ED%99%88&amp;t_click=%ED%97%A4%EB%8D%94&amp;t_header_type=%EB%A1%9C%EA%B3%A0
https://sungboon.com/
https://coverqueen.net/index.html
https://www.naturalbinu.co.kr/shop/main/index.php
https://mixsoon.co.kr/
https://dermamaison.com/
https://easydew.co.kr/
https://www.artois.co.kr/
https://www.edkshop.com/
https://swanicoco.co.kr/
https://skyclear365.com/index.html



Relevant skills:
- Python Programming Language
- Web scraping
- Pyppeteer
- Scrapy
- DrissionPage
- Elasticsearch

For data format, please refer:

https://sdycui8w36l.larksuite.com/docx/NESldhi5wo37BNx6wsnuWaGMsAh?from=from_copylink","{'"Data Scraping'",Python,Elasticsearch,Scrapy}",United States,a,"","",2024-02-23 17:34:18.360908,2024-02-23 17:34:18.360908
https://www.upwork.com/jobs/Building-Scraping-Data-Mining-Tool-get-emails-birthdays-occupations-and-cell-phone-numbers_~01de7f4089ecd06b69/?referrer_url_path=/nx/search/jobs/,"Building Scraping/Data Mining Tool to get emails, birthdays, occupations, and cell phone numbers.",2024-02-15 14:25:32,"I am looking for a professional data scrapper/miner who could help script the code for doing a large scale automatic information scrapper. 

In easier words, I would like to get the code for the scraping tool, for any future needs related to similar data.","{'"Data Scraping'",'"Microsoft Excel'",Python,'"Data Mining'",'"Data Entry'",'"List Building'",Scrapy}",United States,$3.00-$20.00,"","",2024-02-23 17:34:18.369882,2024-02-23 17:34:18.369882
https://www.upwork.com/jobs/GOOGLE-APP-SCRIPT-CODERs_~0112913b0b80ab5578/?referrer_url_path=/nx/search/jobs/,GOOGLE APP SCRIPT CODERs,2024-02-16 17:34:18.375471,"Hi, 
Basically we currently need someone like you to replicate the existing work which have already been done. We have finished for few countries like Indonesian and US. So you can refer the codes from there. All you gotta do is just to replicate the code. Each country''s code is the same, you just need to replicate the codes which are already done but modifying some things like extensive stock according to set trigger for every country and also, check symbols are different in scrapped sources.
Please read everything in this google sheet, especially, the work full process flow : https://docs.google.com/spreadsheets/d/1RCqnS9_SFGf-caDhJveNQlBwJCfk_JG6upsDfLlKRlI/edit#gid=277414202
please view the video, https://www.dropbox.com/scl/fi/j98rqpvhs2y9a3a94c5hs/Screen-Recording-2023-12-09-at-13.36.07.mov?rlkey=tt42ingkdiegdn8652ydm4vx7&amp;dl=0
Meanwhile you can get all the existing codes here hence to replicate it : https://www.dropbox.com/scl/fo/6mx4bibf4xflxujnrkj9t/h?rlkey=182bmuxh7ujym3pf4xxe63r5b&amp;dl=0
So the first coder, already did his best to make the documentation here : https://docs.google.com/spreadsheets/d/16mN0Uh7WPG2cUO_QosqtUq58lEvelXcDQI9ZkXFKXJg/edit#gid=331043196 if that page still confusing for you, please let me know. Please ask me if you have any question and let me know the soonest if you''d like to start.
Because we need you to start working as soon as possible so I can stop finding someone else. You will be paid $50/country''s replication and modifying few things as for each country have different data (bonus available for fast delivery and perfection), but I may fund some few milestones for any such other kinds of works.
Only when you got all the answer is correct then you can work on this. To re-ensure you understood everything, please answer :
a. What are the first thing you need to do to start working on this project ?
 b. What is the output result of the project so we can consider the work is done for the first country/milestone you worked on ?.
","{Scrapy,JavaScript,'"Google Apps Script'",'"Google APIs'",Python,Scripting}",Pakistan,a,"","",2024-02-23 17:34:18.377,2024-02-23 17:34:18.377
https://www.upwork.com/jobs/Expert-Python-Developer-for-Web-Scraping_~01301610222a1d119d/?referrer_url_path=/nx/search/jobs/,Expert Python Developer for Web Scraping,2024-02-16 17:34:18.385333,"Expert Python Developer for Web Scraping


We''re searching for an experienced Python Developer, specialized in web scraping, to join our team. Your primary focus will be on developing robust, efficient scripts using Selenium, Requests, BeautifulSoup4 (bs4), and Pandas libraries.

Preferred candidates:

1. Proven track record with Python and web scraping.

2. Extensive use of Selenium, Requests, bs4, and Pandas.

3. Experience with Azure Tables, Blobs, Amazon, or other e-commerce data is a big plus.

4. Strong analytical and problem-solving skills.

5. Excellent communication.


Please note: Candidates will need to take a test round demonstrating proficiency in Python, Selenium, Requests, bs4, and Pandas.","{'"Web Scraping'",Python,Scrapy,'"Data Scraping'",Automation,Selenium,'"Data Mining'",API,'"Python Script'"}",India,$5.00-$10.00,"","",2024-02-23 17:34:18.387377,2024-02-23 17:34:18.387377
https://www.upwork.com/jobs/Fix-scraper-not-working-gcp_~015eff67c973f89d59/?referrer_url_path=/nx/search/jobs/,Fix scraper not working on gcp ,2024-02-15 08:57:42,I have a scraper which is working locally but when I deploy on Google cloud as a cloud function it does not work script is written in python,"{Automation,'"Data Extraction'",'"Data Scraping'",'"Web Crawling'",Scrapy,'"Beautiful Soup'",Python,'"Python Script'",'"Google Cloud Platform'",API}",Pakistan,a,"","",2024-02-23 17:34:18.396013,2024-02-23 17:34:18.396013
https://www.upwork.com/jobs/Data-scraping-from-website_~017df5649ef0d7b318/?referrer_url_path=/nx/search/jobs/,Data scraping from a website,2024-02-14 20:41:00,"Hello,

I need a data scraping program which can download everyday the data from this website pages into an excel file

https://www.portalecreditori.it/index.php?altre=liquidazioni_ccii

https://www.portalecreditori.it/index.php?altre=concordati_ccii

https://www.portalecreditori.it/index.php?altre=altre_ccii

I need also the data you may find by clicking the field in the “Professionista” column

How much does it cost?","{Python,React,'"Ruby on Rails'",JavaScript,Ruby,SQL,MySQL,Scrapy,Vue.js,Django,DevOps,'"Data Scraping'",Flask,Automation}",Italy,a,"","",2024-02-23 17:34:18.42253,2024-02-23 17:34:18.42253
https://www.upwork.com/jobs/Latin-America-websites-web-scraping_~01b52f3962c773ebb6/?referrer_url_path=/nx/search/jobs/,Latin America websites web scraping,2024-02-14 18:54:41,"I need to web scrape multiple government statistic websites into a common format CSV  to later ingest into a SQL database in AWS.

A few website examples are the following:

https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/dados-abertos

https://estadisticashidrocarburos.energia.gob.mx/

and many others","{'"Web Scraping'",'"API Integration'",'"Beautiful Soup'",'"Selenium WebDriver'",Selenium,Scrapy,pandas,Python}",United States,$15.00-$25.00,"","",2024-02-23 17:34:18.430425,2024-02-23 17:34:18.430425
https://www.upwork.com/jobs/Scrape-data-with-ChatGPT-from-any-website_~01d7b7741cf13c4858/?referrer_url_path=/nx/search/jobs/,Scrape data with ChatGPT from any website,2024-02-14 13:40:48,"We scrape date from about 50 websites using python with Scrapy. This approach works, but is very prone to errors. As websites change all the time, or the scraper gets blocked, even when we use https://www.zyte.com. 

We need a more flexible solution using AI that works 100%. Like for example https://axiom.ai/recipes/chatgpt-web-scraper. If you have experience scraping the web with AI, let us know.

","{'"Data Scraping'",'"Data Extraction'",Scrapy,Python}",Switzerland,a,"","",2024-02-23 17:34:18.439196,2024-02-23 17:34:18.439196
https://www.upwork.com/jobs/Web-Scraper-data-XLS_~019d4b7d2d619c2882/?referrer_url_path=/nx/search/jobs/,Web Scraper data to XLS,2024-02-16 17:34:18.448499,"I am looking for someone that can help me to set up a web scraper to scrape the listings on the following webpage and get the information into Excel:
https://www.seekbusiness.com.au/businesses-for-sale/in-gold-coast-qld
Should also work applying when filters on the above website, e.g. for specific location only.

Should be something that I can use again in future without programmer intervention.

Please briefly describe the proposed application that you will use.

Looking to make a quick decision if someone is able to deliver on my requirement.","{'"Data Scraping'",'"Data Mining'",Python,'"Microsoft Excel'",'"Data Extraction'",Scrapy,'"Web Crawling'"}",South Africa,a,"","",2024-02-23 17:34:18.45037,2024-02-23 17:34:18.45037
https://www.upwork.com/jobs/Python-trading-bot-development_~01259f5aea478112d9/?referrer_url_path=/nx/search/jobs/,Python/trading bot development,2024-02-14 11:59:39,"I have an unfinished code for Binance/crypto trading bot (coded in Python), which I don''t have time to work on. I am looking for someone to work on it (firstly - to finalize, launch it) long term (simply to add new features over the time, etc.). 

Please let me know if you''re interested and your conditions for the start.","{Python,'"Data Mining'",pandas,'"Data Scraping'",NumPy,Scrapy,Selenium,'"Beautiful Soup'",Flask,Django,'"Web Crawling'",'"RESTful API'",JSON,Database}",Lithuania,a,"","",2024-02-23 17:34:18.45886,2024-02-23 17:34:18.45886
https://www.upwork.com/jobs/Twitter-Post-Scrapper_~0173ea5f6c7c514128/?referrer_url_path=/nx/search/jobs/,Twitter Post Scrapper,2024-02-14 11:04:33,"Looking for someone to create a simple script for me (mostly open source) that would scrap twitter profile basic info, tweets, comments etc
Hiring today","{API,Python,'"Twitter/X API'",'"Data Scraping'",Scrapy,JavaScript,PHP,'"Data Mining'"}",Pakistan,a,"","",2024-02-23 17:34:18.467839,2024-02-23 17:34:18.467839
https://www.upwork.com/jobs/Web-Scraping-Specialist_~01fe09f6be195fb1cd/?referrer_url_path=/nx/search/jobs/,Web Scraping Specialist,2024-02-16 17:34:18.476178,"We are a Spain based company looking for a talented Web Scraping Specialist to help us in our business.

This job posting is for a long term remote position.

This role will require you to maintain existing python scripts built using the scrapy/selenium framework and to create new ones according to pre-defined design patterns to collect data from online e-commerce websites.

Required Skills:
• Excellent experience in python scripting
• Deep knowledge of the scrapy/selenium framework
• Good Level of reading and writing in English

When applying for this job, please write your favorite animal as a proof that you read the whole job description.

A video interview and a technical test will be required prior to hiring. You must have a reliable internet connection and a computer. Although most daily communication will happen via email, we will occasionally have video conferences. The ability to communicate in English is a must.

All AI generated applications are going to be immediately rejected.","{Scrapy,'"Web Crawling'",Scripting,JSON,'"Beautiful Soup'",Selenium,'"Data Scraping'",Python}",Spain,$5.00-$15.00,"","",2024-02-23 17:34:18.478446,2024-02-23 17:34:18.478446
https://www.upwork.com/jobs/Scrapping-Database-hacking_~016a83ec838b0d4b72/?referrer_url_path=/nx/search/jobs/,"Scrapping, Database hacking ",2024-02-14 07:14:06,"I''m looking for a person who can access a source that transmits data in the form of live broadcasts, streams without delays to bookmakers.

At the moment there is the following information, I don’t know if it will help you in your work.
The main request is the possibility of receiving live broadcasts, broadcasts without delays from beter.co sources
https://www.beter.co/
https://www.esportsbattle.com/

These companies provide information to Bookmakers, some of them are given broadcasts (servers), public/stream/trading/demo.
Each server can have different variations, either public, or only stream, or trading or demo
The whole difference between them lies in the delay timings.

The minimum we need is trading - it should be + - level with the closing of the line in the bookmaker.
Change in goal odds (bet365 and other bookmakers) - approximately 1:1 on FIFA-1-2-3-4 channels with world time second per second)
It is unknown which server the broadcasts are on, the previous servers were disabled, these links were previously known:

https://streamarchive.beter.co/trading/fifa/1/embed.html?realtime=true

http://212.117.165.28/trading/fifa/1/embed.html?realtime=true

(same server)

(1,2,3,4)

As I understand it, they gave someone a demo test through the server, and perhaps they have a main one that clients use.

There was also access to https://console.beter.co/,
but the broadcasts there were inappropriate in terms of timing, they remained for 5 or more seconds.

For example eSportsBattle FIFA
2 players play FIFA on PS, from the game console the information is somehow transmitted to the server, processing is done, the players’ web cameras are superimposed and subsequent information is transmitted to another server, then to the trading department of bookmakers who keep the score (update the odds) - that’s all this is figurative, there is no understanding of how it actually works exactly.","{Scrapy,'"Data Scraping'",Python,'"Database Management'",PHP,SQL,'"Web Crawling'",'"File Management'",Python-Goose,MySQL}",Kazakhstan,a,"","",2024-02-23 17:34:18.488156,2024-02-23 17:34:18.488156
https://www.upwork.com/jobs/Python-tutor_~01b22ce11c974e408d/?referrer_url_path=/nx/search/jobs/,Python tutor,2024-02-13 21:02:51,"Hi,
Do you teach Python coding? Looking to learn how to code Python and some libraries like Pandas. Would like to use python for data analysis and build up skills. Looking to expand career options so trying to learn to code. Do you have a specific curriculum you use? I have been trying to learn using Maven Analytics but its challenging learning from an online program. I like learning through projects and examples. ","{Scrapy,Automation,Python,Selenium,'"Data Scraping'",'"Web Crawling'",'"Scripts & Utilities'",XPath}",United States,a,"","",2024-02-23 17:34:18.497684,2024-02-23 17:34:18.497684
https://www.upwork.com/jobs/Scrape-results-from-google-Search-automatically-Not-Manually_~016dabd79c5c8c164d/?referrer_url_path=/nx/search/jobs/,Scrape results from a google Search automatically (Not Manually),2024-02-16 17:34:18.504836,"I will give you a set of word which you need to search on google.

Whatever results appear, I want you to Scrape them automatically. 

This is not manual work. Please do not copy paste and send proposals. Just mention in the proposal if you can do this automatically and time taken for this.

","{'"Data Scraping'",Python,'"Data Extraction'",Scrapy,Automation,'"Data Mining'",'"Data Entry'"}",India,a,"","",2024-02-23 17:34:18.506858,2024-02-23 17:34:18.506858
https://www.upwork.com/jobs/Page-Scraping-Project_~0186c1e0ca2e229e45/?referrer_url_path=/nx/search/jobs/,Page Scraping Project,2024-02-13 19:27:53,We have a Google search for a specific platform - we need the list from Google accessed and each page scraped to get the contact form URL and/or the email address. We would like to get more data - but need to review the options. We know that platforms like ScrapeBox can perform this.,"{'"Data Scraping'",Scrapy,'"Data Mining'",ScrapeBox}",United States,a,"","",2024-02-23 17:34:18.515456,2024-02-23 17:34:18.515456
https://www.upwork.com/jobs/Tweets-Twitter-Scraping-com_~018cb3d4b584172cb9/?referrer_url_path=/nx/search/jobs/,Tweets Twitter Scraping x.com,2024-02-13 18:09:10,I need to extract all tweets from an account twitter and have the tweets in a csv. I have to extract from 5 accounts.,"{'"Data Scraping'",'"Twitter/X API'",Scrapy,'"Data Extraction'"}",United States,a,"","",2024-02-23 17:34:18.523264,2024-02-23 17:34:18.523264
https://www.upwork.com/jobs/Data-Scraper_~0163374f3c5fb3b347/?referrer_url_path=/nx/search/jobs/,Data Scraper,2024-02-13 17:01:48,"We are looking for data scraper to get the products we need for our web shop. Were looking for a certain amount of in a certain amount of time, so we would like to discuss the time frame and budget with you.

If you have experience in data scraping please contact me to talk further.

Must be experienced, efficient and work well on deadlines. 

I look forward  to hearing from you.","{Selenium,'"Data Scraping'",pandas,'"Data Extraction'",'"Web Scraping Framework'",'"Beautiful Soup'",'"Web Scraping'",Python,Scrapy,'"Selenium WebDriver'",'"Web Crawling'",'"Browser Automation'",'"Data Mining'",Scripting,Automation}",Canada,a,"","",2024-02-23 17:34:18.53442,2024-02-23 17:34:18.53442
https://www.upwork.com/jobs/Web-Scraping-Specialist_~013186f1e411db57a6/?referrer_url_path=/nx/search/jobs/,Web Scraping Specialist,2024-02-13 15:39:47,"I am looking for a web scraping specialist to extract data from a particular website. The task involves extracting and cleaning the data and then structuring it in a format that can be easily imported into excel. I am seeking someone who is highly skilled in web scraping and has experience in using tools such as Python, Scrapy, and Beautiful Soup. The ideal candidate will have a strong attention to detail and be able to work independently.","{'"Data Scraping'",'"Data Mining'",Python,Scrapy}",Bangladesh,hE,"","",2024-02-23 17:34:18.545741,2024-02-23 17:34:18.545741
https://www.upwork.com/jobs/Udemy-Course-Creation_~01ba886eaa522b555a/?referrer_url_path=/nx/search/jobs/,Udemy Course Creation,2024-02-13 14:50:51,"We will have a few minutes call for you to decide if this project is the best fit for you but basically, I work with Gerard to help Udemy instructors rank their courses on the platform to maximize on their earnings. ","{'"Selenium WebDriver'",Selenium,Scrapy,Python-Requests,'"Beautiful Soup'",'"Web Crawling'",'"Web Crawler'",'"Data Scraping'",'"Data Extraction'",'"Python Script'",Scripting,'"Task Automation'",PyCharm,Pygame,Python}",Kenya,a,"","",2024-02-23 17:34:18.555785,2024-02-23 17:34:18.555785
https://www.upwork.com/jobs/Need-data-from-website_~01ed3a85990be6136b/?referrer_url_path=/nx/search/jobs/,Need data from a website,2024-02-13 15:02:48,I need data embedded in a website that's currently in table form.  Looking for an output into CSV file or alternative.  Fairly straightforward task that you can complete quickly.  Thanks!,"{Python,'"Web Scraping'",'"Data Scraping'",'"Beautiful Soup'",Scrapy,Selenium,'"Selenium WebDriver'"}",United States,a,"","",2024-02-23 17:34:18.565454,2024-02-23 17:34:18.565454
https://www.upwork.com/jobs/Office-assignment_~0133bf066e4d98b270/?referrer_url_path=/nx/search/jobs/,Office assignment,2024-02-13 09:01:40,Need to post two github links and make two youtube videos for task 1 and task 2 with AI voice.,"{'"Data Entry'",Java,ScrapeBox,Scrapy,'"Data Mining'",'"Data Scraping'",'"Web Crawling'",'"Mozenda Scraper'"}",Canada,a,"","",2024-02-23 17:34:18.574701,2024-02-23 17:34:18.574701
https://www.upwork.com/jobs/Python-crawler-development_~016dcce2b9de02eb19/?referrer_url_path=/nx/search/jobs/,Python crawler development,2024-02-16 17:34:18.581295,"crawler (with rotating proxies, ip''s and user agents) ,with an api to crawl specific (6) websites and extract info requested to dataframes, save to db/s3.

dynamic and generic (be able to quickly scrap new websites)","{Python,'"Data Scraping'",'"Data Mining'",'"Web Crawling'",API,pandas,Scrapy}",Israel,a,"","",2024-02-23 17:34:18.582811,2024-02-23 17:34:18.582811
https://www.upwork.com/jobs/Web-Scraper-Data-Extraction-Expert-Needed-Long-Term_~01409f7ebf7be4f6fc/?referrer_url_path=/nx/search/jobs/,Web Scraper / Data Extraction Expert Needed (Long-Term),2024-02-13 07:42:55,"We have several long-term data extraction projects. 

For example, we have an ongoing need to scrape ecommerce search results and return product links, prices, shipping for different countries, image links and other details from different websites. We are looking to get leads (email addresses) from US based TikTok and YouTube accounts.

We are looking for a development partner to build and maintain a set of scraping scripts.

If this sounds like something you can do, please get in touch. Look forward to working with you!

We hopefully will be able to work on an ongoing basis. The architecture of the sites is always changing, requiring updated scripts.","{Selenium,Scrapy,SQL,C#,'"Data Scraping'",PHP,Python,JavaScript,'"Data Mining'",'"Data Extraction'"}",United States,a,"","",2024-02-23 17:34:18.590218,2024-02-23 17:34:18.590218
https://www.upwork.com/jobs/Website-Automation_~011d90f39a25e63968/?referrer_url_path=/nx/search/jobs/,Website Automation,2024-02-13 04:34:50,"I am in need of automating about 8 steps regarding inputting data on a website which includes selecting a current date, clicking a few radio buttons and adding a url.  Would like for the bot to be able to run on a mac and or be browser based. If not can you create a VM that I can import into Virtual Box for it to run on a windows environment.","{Python,Selenium,'"Web Scraping'",'"Data Extraction'",Scrapy,'"Web Crawling'",'"Python Script'",'"Bot Development'",Automation,'"Automated Testing'",'"OCR Algorithm'",'"Web Development'",Django,'"Web Application'",'"Data Collection'"}",United States,hE,"","",2024-02-23 17:34:18.599236,2024-02-23 17:34:18.599236
https://www.upwork.com/jobs/Scraping_~01b84139a41996901c/?referrer_url_path=/nx/search/jobs/,Scraping,2024-02-11 14:32:52,"Hello!

hello I would like to know if you can scrape pages like this if yes how long will it take
https://www.leboncoin.fr/recherche?category=9&amp;locations=d_60&amp;owner_type=private&amp;real_estate_type=1&amp;immo_sell_type=old
 this is just an example and also I would like to know if there was a way to scrap airbnb
thank you 

Avidan M.","{Selenium,'"Data Scraping'",pandas,'"Data Extraction'",'"Web Scraping Framework'",'"Beautiful Soup'",'"Web Scraping'",Python,Scrapy,'"Selenium WebDriver'",'"Web Crawling'",'"Browser Automation'",'"Data Mining'",Scripting,Automation}",France,a,"","",2024-02-23 17:34:21.750011,2024-02-23 17:34:21.750011
https://www.upwork.com/jobs/Experienced-Web-Scraper-Needed-for-Apollo-and-Contact-Out-Data-Extraction_~0148a7f30cddf51b87/?referrer_url_path=/nx/search/jobs/,Experienced Web Scraper Needed for Apollo and Contact Out Data Extraction,2024-02-13 05:20:44,"We are in need of an experienced web scraper proficient in Python or similar languages to extract vital information from Apollo and Contact Out websites. The targeted data fields include the point of contact, email address, contact details, company size, and industry. The ideal candidate should possess strong problem-solving abilities and attention to detail, ensuring accurate and reliable extraction. Prior experience in web scraping, especially with targeted data fields, is highly preferred. Good communication skills are essential for effective collaboration.

Required Skills:
1. Proficient in Python, Scrapy, or Selenium.
2. Experience with web scraping, particularly extracting specified fields from Apollo and Contact Out.
3. Strong troubleshooting skills and attention to detail.
4. Excellent communication abilities.

Preferred Qualifications:
1. Familiarity with data cleaning and preprocessing.
2. Knowledge of APIs for data extraction.
3. Previous experience in similar projects.

Deliverables Expected:
1. Custom web scraping scripts in Python or similar languages, along with detailed running instructions for executing the scripts.
2. The output of the program should be an Excel file containing the extracted data fields (point of contact, email, contact information, company size, and industry) organized in a structured format. A sample format for the Excel file will be provided for reference.

Instructions for Applicants:
Please provide examples of past web scraping projects, especially involving extraction of specified fields from Apollo or Contact Out. Include your proposed approach and estimated timeline.

Budget:
Flexible based on experience.

Duration:
To be discussed.

Feel free to adjust any details to better fit your requirements.","{'"Data Integration'",'"Screen Scraping'",Selenium,'"Beautiful Soup'",Python,PHP,'"Python Script'",Scrapy,'"Data Mining'"}",India,a,"","",2024-02-23 17:34:21.661815,2024-02-23 17:34:21.661815
https://www.upwork.com/jobs/Scrap-Products-CSV-Excel_~011232700d9221d263/?referrer_url_path=/nx/search/jobs/,Scrap Products to CSV or Excel,2024-02-12 22:29:05,"Hello Guys,

I am in search of a web scraper capable of efficiently crawling products from a specific platform. The Task is to create/ import these products into a well-organized CSV or Excel file. 

The project is relatively straightforward and should be started right away.","{'"Data Scraping'",'"Data Entry'",'"Data Mining'",'"Spreadsheet Software'",Python,'"Microsoft Excel'",Scrapy}",Poland,cy,"","",2024-02-23 17:34:21.673251,2024-02-23 17:34:21.673251
https://www.upwork.com/jobs/looking-for-back-end-developer-help-integrate-automation-into-Agency_~0197f0652f91f05ddf/?referrer_url_path=/nx/search/jobs/,looking for a back end developer to help me integrate automation's into my Agency. ,2024-02-16 17:34:21.679744,"Looking to improve my agency with the use of automation. Looking for someone who can help me set up bots for me and give me technical advise on how i can improve my business. 

- Looking to set up custom bots for mother/child blackhat marketing method (instagram). 
- help me set up phone emulators and automate dating app swiping/messaging. 
- Advise on anything else that i can potentially automate. 

I''ve been tirelessly trying to figure this stuff out on my own but don''t have the technical knowledge to do so, so im looking to bring someone into the team who can help me with this and hopefully work together a lot. 

Thanks 
","{'"API Integration'",'"Web Scraping'",Scrapy,Python,Selenium,'"Data Extraction'",'"Data Scraping'",JavaScript,Automation,API,'"Web Scraping Framework'",'"Web Scraping Software'",'"Web Scraping Plugin'",ChatGPT,'"OpenAI API'"}",United Kingdom,a,"","",2024-02-23 17:34:21.683042,2024-02-23 17:34:21.683042
https://www.upwork.com/jobs/Data-Scraper_~01d4940cafb0bcf96d/?referrer_url_path=/nx/search/jobs/,Data Scraper,2024-02-12 21:21:21,"We are looking for a “Data scraper,” someone who can write code to scrape names, phone numbers, addresses, and about 5-10 other fields off of a website that serves as a directory for an up and coming Music startup aimed at helping small independent live music Venues and Musicians. I have an account with a directory to provide this information but I need to merge the information with my CRM, and it is way too slow. The site is clunky and somewhat annoying. I’d like to know how much it would cost, and how long it will take, and am happy to walk you through the site to see what it involves. I would need this information as soon as possible. We need someone with an English level that is excellent and who can show a history of doing data scraping with accurate information. The work would start right away.","{'"Machine Learning'",'"Data Entry'",SQL,Python,Scrapy,API,'"Beautiful Soup'",ETL,'"Data Mining'",'"Data Scraping'",'"Web Crawling'",'"Database Architecture'",Selenium,PostgreSQL}",United States,a,"","",2024-02-23 17:34:21.692266,2024-02-23 17:34:21.692266
https://www.upwork.com/jobs/Data-Scraping-Automation-Python-Engineer_~014668ae58c1757bdb/?referrer_url_path=/nx/search/jobs/,Data Scraping Automation Python Engineer,2024-02-12 20:39:12,"Looking for a skilled Python Engineer with experience in web scraping, data handling, and Django. 
The job involves extracting rent information from a website, transferring it to another site, and generating an Excel report. 
Previous similar work is a plus. Please share your related experiences.","{Python,'"Data Scraping'",Automation,Scrapy,'"Data Mining'",'"Data Extraction'",Selenium,'"Selenium WebDriver'",'"Automation Framework'"}",Brazil,a,"","",2024-02-23 17:34:21.700926,2024-02-23 17:34:21.700926
https://www.upwork.com/jobs/Web-Scraping-Data-Extraction_~01b31bbdec106b5e13/?referrer_url_path=/nx/search/jobs/,Web Scraping/Data Extraction,2024-02-12 19:42:14,"We are currently on the hunt for a skilled individual or team to undertake a comprehensive web scraping project. Our objective is to extract approximately 200,000 entries from a specified website.

Project Requirements:

Data Quantity: The project will involve scraping around 200,000 entries.
Data Fields: Each entry should consist of 12 specific fields; details will be provided to the selected candidate.
Output Format: The final dataset should be delivered in one of the following formats: JSON, XML, CSV, or SQL.

PROVIDE A QOUTE for the total project and an estimated time frame for completion. ","{'"Data Scraping'",Scrapy,'"Data Extraction'"}",United States,a,"","",2024-02-23 17:34:21.709359,2024-02-23 17:34:21.709359
https://www.upwork.com/jobs/Scraping-indeed-jobs-using-automation_~01963a521f9c48fb7b/?referrer_url_path=/nx/search/jobs/,Scraping indeed jobs using automation,2024-02-16 17:34:21.715934,"We need someone to create a script/application and scrape data on indeed uk.

we need data extracted from fields such as job title, company posting job, location, salary/hourly, email address inside job descriptions and job type.

before the script begins we need to be able to filter the options available and input data freely.

these options are in the attachment. ","{'"Data Scraping'",Python,Automation,Selenium,'"Data Mining'",'"Microsoft Excel'",'"Data Entry'",API,Scrapy}",United Kingdom,$3.00-$4.00,"","",2024-02-23 17:34:21.718256,2024-02-23 17:34:21.718256
https://www.upwork.com/jobs/Data-Scrape_~01f279d738a3c7adb7/?referrer_url_path=/nx/search/jobs/,Data Scrape,2024-02-12 15:26:40,"I am looking for data extraction expert. 
Target Regions - UK, Germany, France, Sweden, India.
Further details are shared with selected  freelancer.

Regards","{'"Data Scraping'",'"Data Mining'",'"Data Extraction'",Python,Scrapy}",United Arab Emirates,a,"","",2024-02-23 17:34:21.725988,2024-02-23 17:34:21.725988
https://www.upwork.com/jobs/Web-Scraping-Quick-Job_~01e99efada990e2c98/?referrer_url_path=/nx/search/jobs/,Web Scraping - Quick Job,2024-02-16 17:34:21.732552,"I need an expert who will scrape info from the webpage. More details I will provide to chosen candidate

Thanks","{'"Data Scraping'",Python,Scrapy}",Ukraine,a,"","",2024-02-23 17:34:21.734397,2024-02-23 17:34:21.734397
https://www.upwork.com/jobs/Python-bot_~0177696f6c2aaf6b82/?referrer_url_path=/nx/search/jobs/,Python bot,2024-02-11 20:25:55,I need a bot for ebay developed send proposal for more details,"{'"Data Extraction'",'"Beautiful Soup'",Scrapy,'"Web Crawling'",Python,'"Bot Development'",'"Data Scraping'",Selenium,Automation,'"Python Script'"}",Pakistan,a,"","",2024-02-23 17:34:21.741925,2024-02-23 17:34:21.741925
https://www.upwork.com/jobs/Data-Scraping-Lustyindustries-com_~014fa6531c6008bbdb/?referrer_url_path=/nx/search/jobs/,Data Scraping Lustyindustries.com,2024-02-16 17:34:21.755365,"Web/Data scraping for website lustyindustries.com

You will be provided with a login, which shows more information than the public version.

1) For single items, the following fields:
- Product Code
- Barcode
- Cost
- RRP
- Image URL 1, Image URL 2, Image URL 3 etc.
- Brand Logo
- Product Description (HTML)
- Product Description (No HTML)
- Product Specifications

2) For items with sizes, as above, plus:
- Size, Product Code, Barcode, Price for EACH variation (plus other fields repeated. Ie, one row per variation)

Deliverable: MS Excel OR Google Sheets.

This is a once-off project for this website, I need the results, but I do not need any scripting for regular scrapes. But I may have other scraping work ongoing of other websites.

Any questions please ask.
Please advise how soon you could complete the task.
 ","{'"Web Scraping'",Scrapy,'"Data Scraping'"}",Australia,a,"","",2024-02-23 17:34:21.756938,2024-02-23 17:34:21.756938
https://www.upwork.com/jobs/Data-Scraping-Bot-Developer_~018b07f4aa4f4da5da/?referrer_url_path=/nx/search/jobs/,Data Scraping Bot Developer,2024-02-11 11:11:48,"We are looking for a skilled and experienced Data Scraping Bot Developer to help us optimise our search processes. We are a non-profit, that generates most of our impact by being partner of different international projects. Thus, we need someone who could help us in developing a sophisticated bot that will automate the process of searching various websites and Facebook groups for the keywords &quot;partner search.&quot; The bot will aggregate data into a single Excel file for further analysis and reporting.

Responsibilities:
- Design and develop a high-performance data scraping bot tailored to specific requirements.
- Ensure the bot can efficiently search through designated websites and social media platforms for &quot;partner search&quot; and accurately gather relevant data.
- Implement data parsing and cleaning mechanisms to ensure high-quality data output.
- Create a user-friendly interface for non-technical users to interact with the bot, including options to start the search, specify keywords, and define output formats.
- Ensure compliance with all legal and ethical guidelines related to data scraping, including adherence to websites'' terms of service and data protection laws.
- Regularly update and maintain the bot to adapt to any changes in target websites or social media platforms.
- Provide detailed documentation and training materials for end-users.

Requirements:
- Proven experience in developing data scraping bots or similar automation tools.
- Strong programming skills, particularly in languages such as Python, and familiarity with web scraping libraries (e.g., Beautiful Soup, Scrapy).
- Experience with social media APIs and understanding of Facebook''s Graph API is highly desirable.
- Knowledge of data cleaning and formatting techniques to prepare data for analysis.
- Familiarity with Excel manipulation libraries (e.g., openpyxl, pandas) for data output.
- Understanding of legal and ethical considerations in web scraping.
- Excellent problem-solving skills and attention to detail.
Strong communication and documentation skills.","{'"Data Scraping'",'"Bot Development'",Automation,'"Data Extraction'",Scrapy,JavaScript,'"Data Mining'",Python}",Ireland,a,"","",2024-02-23 17:34:21.763659,2024-02-23 17:34:21.763659
https://www.upwork.com/jobs/Python-Scrapy-Cronjob-Web-Scraping-Experts_~01a56336fc18593598/?referrer_url_path=/nx/search/jobs/,Python / Scrapy / Cronjob :: Web Scraping Experts,2024-02-11 06:34:34,"To scrape data from website
-Data scraped to be saved into database
-To run a cronjob for the scraper to auto scrape at certain intervals
-To fix some problems related to scrap

I will provide my existing py in py2.
You shall convert it into py3.
You shall install the applications required in my VPS to run those py3.","{Scrapy,Python,'"Data Scraping'"}",Malaysia,a,"","",2024-02-23 17:34:21.772303,2024-02-23 17:34:21.772303
https://www.upwork.com/jobs/Scraping_~0158a6de9ac66d6420/?referrer_url_path=/nx/search/jobs/,Scraping,2024-02-11 00:20:02,"We are long for a data scraper to join our team, we are looking for data scraping, web scraping pros.. ","{'"Data Scraping'",'"Data Mining'",Python,Scrapy,Python-Goose,'"Data Extraction'"}",United States,cG,"","",2024-02-23 17:34:21.780003,2024-02-23 17:34:21.780003
https://www.upwork.com/jobs/Web-Scraping-BOT-Script-Needed_~0126e29361058c10f8/?referrer_url_path=/nx/search/jobs/,Web Scraping BOT / Script Needed,2024-02-10 22:56:01,"Hi, I have a web scraping project that requires the scraping of a few websites'' information. Essentially I need a script that will read a website, scrape the data, and clean the data into a cleaned, formatted Excel sheet as per requirements. 

Requirements:
- 5 Websites to Scrape
- Information Type: Dates, City, Time, Venue, Price, Space etc...
- Will need the script and first batch of data sent over as the deliverable

Thanks!","{'"Data Scraping'",'"Data Mining'",Scrapy,Selenium,'"Beautiful Soup'",'"Python Script'",'"Browser Automation'",'"Data Extraction'",'"Data Collection'",'"Web Crawling'",'"Task Automation'",'"Web Scraping'",'"Screen Scraping'",'"Web Scraping Software'"}",Canada,a,"","",2024-02-23 17:34:21.790061,2024-02-23 17:34:21.790061
https://www.upwork.com/jobs/Web-scraping_~01d5c58a0d24472d82/?referrer_url_path=/nx/search/jobs/,Web scraping,2024-02-10 16:07:10,"I need to pull some data informations from one website.

when we connect i''ll provide what website im aiming for and what type of data i need.

maybe they have API so your job might be just a find what API url it is but in my investagion i didn''t find it.
","{'"Data Scraping'",JavaScript,'".NET Core'",Python,Scrapy,'"Web Crawling'",'"Data Extraction'"}",Croatia,a,"","",2024-02-23 17:34:21.796946,2024-02-23 17:34:21.796946
https://www.upwork.com/jobs/Python-web-scraper-job_~0126929b7f5cfb49ec/?referrer_url_path=/nx/search/jobs/,Python web scraper job,2024-02-09 17:34:21.802313,"Hi,
We are looking for a Python web scraper to extract data from Etsy into an Excel sheet based on our requirements

The requirements of this task and the output template are attached please don''t send an offer if you didn''t go over it and understand the task.

2 notes:
1. Sometimes there are captcha challenges.
2. The script must run as fast as possible and in the background.

Thank you","{Python,'"Data Scraping'",'"Data Mining'",Scrapy,Selenium,'"Web Crawling'",pandas,'"Python Script'"}",Israel,a,"","",2024-02-23 17:34:21.804027,2024-02-23 17:34:21.804027
https://www.upwork.com/jobs/Web-Scraper-for-Corporate-Data_~01d8c5ba6efe0eb75d/?referrer_url_path=/nx/search/jobs/,Web Scraper for Corporate Data,2024-02-09 17:34:21.809008,"I am seeking a fluent Python developer to create a custom web scraper tailored to extract specified data from a range of company websites. This would be an ideal project for someone who has a strong background in web scraping, data extraction, and automation processes.

Key Requirements:

- Efficiently scrape contact information, product details, address specifics, and fundamental company descriptions.
- Ensure the accuracy and cleanliness of the scraped data.
- Implement a solution that can bypass basic anti-scraping mechanisms.

Skills and Experience:

- Proficiency in Python and web scraping libraries (e.g., BeautifulSoup, Scrapy, or similar).
- Familiarity with parsing HTML/CSS and working with APIs if needed.
- Experience in data manipulation and extraction.
- Capable of delivering scraped data in an Excel spreadsheet format.

Final Deliverables:

- A working Python scraper that can be run as needed.
- An Excel spreadsheet containing the extracted data.

The final product must adhere to legal and ethical standards regarding data scraping. Freelancers with a proven track record in similar projects and positive feedback will be considered first.","{'"Data Scraping'",'"Data Mining'",Python,'"Microsoft Excel'",Scrapy,'"Web Crawling'"}",United Kingdom,$15.00-$25.00,"","",2024-02-23 17:34:21.810561,2024-02-23 17:34:21.810561
https://www.upwork.com/jobs/Resolve-recaptcha-python_~01755979cad0887f6a/?referrer_url_path=/nx/search/jobs/,Resolve recaptcha in python,2024-02-10 09:55:24,I want to resolve recaptcha in python there is a recaptcha on a site,"{API,'"RESTful API'",'"Python Script'",Python,'"Data Scraping'",'"Web Crawling'",JavaScript,Scrapy}",Pakistan,a,"","",2024-02-23 17:34:21.819161,2024-02-23 17:34:21.819161
https://www.upwork.com/jobs/Python-and-Pandas-Developer-API-developer_~01cdf0167b1adb6b09/?referrer_url_path=/nx/search/jobs/,"Python and Pandas Developer, API developer",2024-02-09 17:34:21.826055,"**Executive Summary**

This Statement of Work (SoW) delineates the comprehensive plan for the development and deployment of a product-focused Master Data Management (MDM) application tailored for H4H. The application aims to streamline and automate the Extract, Transform, Load (ETL) processes using the pandas library, enhancing the efficiency and accuracy of data management within the organization. Built upon a robust technology stack comprising Flask, HTML, CSS, and a suite of Python libraries, the solution will be backed by a MySQL database to ensure secure and scalable data storage.

The core objective of this initiative is to facilitate a seamless supplier onboarding process, enabling H4H to efficiently integrate new suppliers into their ecosystem. By automating inventory and price monitoring, the application will provide real-time insights into stock levels and pricing dynamics, thus optimizing inventory management and pricing strategies. Furthermore, the implementation of intelligent product recommendations will leverage advanced analytics to enhance cross-selling and up-selling opportunities, driving revenue growth and improving customer satisfaction.

To ensure the seamless integration of data across diverse systems, the application will employ a RESTful API, which will facilitate the uploading of data into the company’s store using an ODBC driver. This approach guarantees a flexible and interoperable data exchange framework, enabling H4H to adapt quickly to changing business needs and technology landscapes.

The development of this MDM application represents a strategic investment in H4H’s digital infrastructure, aiming to achieve operational excellence and competitive advantage. By automating critical data management processes and providing actionable insights through advanced analytics, H4H will be well-positioned to respond dynamically to market trends, streamline supplier integration, and deliver enhanced value to its customers.","{'"Data Processing'",'"Data Cleaning'",'"Data Segmentation'",Python,'"RESTful API'",ETL,pandas,Scrapy,MySQL,Elasticsearch,API,BigCommerce}",United States,$7.00,"","",2024-02-23 17:34:21.828539,2024-02-23 17:34:21.828539
https://www.upwork.com/jobs/Web-Crawling-and-Scraping-Expert-Needed_~01a149b2d4d01d5b61/?referrer_url_path=/nx/search/jobs/,Web Crawling and Scraping Expert Needed,2024-02-09 19:17:19,"We are seeking a skilled freelancer with experience in web crawling and web scraping to help us find specific documents. The task involves extracting data from websites and retrieving specific files. The ideal candidate should have a deep understanding of web scraping techniques and be proficient in programming languages such as Python or JavaScript. Attention to detail and the ability to work independently are crucial for this project. If you have a proven track record in web scraping and can deliver accurate and timely results, we would like to hear from you.

Skills required:

- Web crawling
- Web scraping
- Data extraction
- Python
- JavaScript

This is a small to medium-sized project that is expected to last between 1 to 3 months.","{'"Data Scraping'",Scrapy,Python,'"Web Crawling'"}",United States,gO,"","",2024-02-23 17:34:21.838095,2024-02-23 17:34:21.838095
https://www.upwork.com/jobs/Complex-High-Output-Web-Scraper_~01666ea72aeafde9f5/?referrer_url_path=/nx/search/jobs/,Complex High Output Web Scraper,2024-02-09 17:34:21.843266,"High-output single-site web scraper with a long run-time: 
      500,000+ lines
      6-10 columns
      Scraper would probably run for multiple weeks.

Ideally looking for someone with Zyte API knowledge as well as skilled in Python.

We want the output of the scraper to get uploaded into an AWS S3 Bucket, so familiarity with AWS integration is needed.

Would like to have this whole project finished within a month.
We have one more project like this two that we would commission out if this job was done well.

","{Python,'"Data Scraping'",'"Data Extraction'",Scrapy,'"Amazon S3'",'"Web Crawling'",Automation,Database}",United States,a,"","",2024-02-23 17:34:21.845741,2024-02-23 17:34:21.845741
https://www.upwork.com/jobs/Develop-Website-Auto-Check-Government-Notices-Page_~01e664c7d55241f37d/?referrer_url_path=/nx/search/jobs/,Develop Website to Auto-Check Government Notices Page,2024-02-09 17:34:21.857872,"I am seeking a WordPress developer to create a website that automatically verifies results from a particular government page that posts notices and announcements related to companies and corporate entities.

The website would allow users to input and save a list of company names they want to track. It would then check the specified government page daily and email customized alerts to users if any new notice or announcement is posted related to their tracked companies.

This would function via a WordPress backend that stores user accounts, company lists, and email subscriptions. The site would use scrape the government page daily, compare new posts to user lists, and generate email notifications of matches.

The main components:


    User subscription and company watchlist database
    Custom script to regularly scrape government page
    Email notification system integrated with subscription data
    Custom tracking display showing announcements relevant to user

Please message me if you have experience developing automated checker and alert websites focused on monitoring third party sources.","{Automation,'"Data Extraction'",'"Data Mining'",'"Data Scraping'",Node.js,'"Beautiful Soup'",Scrapy,StormCrawler,'"Apache Nutch'",WordPress}",Mexico,$20.00-$45.00,"","",2024-02-23 17:34:21.860411,2024-02-23 17:34:21.860411
https://www.upwork.com/jobs/Content-heavy-website-development_~01594ff7781d4cde45/?referrer_url_path=/nx/search/jobs/,Content heavy website development ,2024-02-09 18:47:28,"Hi. I am hoping to create two websites - one for wage law and one for employment law. These sites are NOT for my practice. I want them to contain information which will get updated about the type of law. 
I would begin with CA law, but want an option to expand to 50 states. 

The websites would present legal content in different areas - e.g., overtime law, commissions law, minimum wages - heavy content w simple organization.

The goal is to get googleads and to generate enough traffic to allow for attorney advertising. I might have a link to my website ( which requires an upgrade,) but the goal here is long-term  advertising income generated from content. Is this something you can help with?","{Scrapy,SQL,Python,'"Data Entry'",'"Data Scraping'",'"Data Mining'",'"Beautiful Soup'",Selenium,'"Lead Generation'",'"Web Crawling'",Django,'"Data Extraction'",Automation,'"Web Scraping'",JavaScript}",United States,a,"","",2024-02-23 17:34:21.873817,2024-02-23 17:34:21.873817
https://www.upwork.com/jobs/Chatwoot-Evolution-API_~01d60fb4903dc77381/?referrer_url_path=/nx/search/jobs/,Chatwoot + Evolution API,2024-02-09 17:34:21.881482,"I have currently a Chatwoot installation in a subdomain of my ecommerce: https://soporte.multisononline.com/

I want two things: 

Install the Evolution API in order to make whatsapp work with multi agent. (I''ve already tried)
I didnt configured corretly the email in Chatwoot, so mails are not being sent to agents. 

Im working with a VPS with Ubuntu
","{Python,React,'"Ruby on Rails'",JavaScript,Ruby,SQL,MySQL,Scrapy,Vue.js,Django,DevOps,'"Data Scraping'",Flask,Automation}",Spain,cG,"","",2024-02-23 17:34:21.88428,2024-02-23 17:34:21.88428
https://www.upwork.com/jobs/Web-Scraping-CSV-Excel_~0103bb744eacf04686/?referrer_url_path=/nx/search/jobs/,Web Scraping to CSV or Excel,2024-02-09 14:51:26,"Hello,

I am in search of a web scraper capable of efficiently crawling products from a specific platform. The Task is to create/ import these products into a well-organized CSV or Excel file. The inventory must remain synchronized with the source platform at all times.

The project is relatively straightforward and should be started right away.","{'"Data Scraping'",'"Data Mining'",Python,'"Data Extraction'",'"Data Entry'",'"Web Crawling'",Scrapy,CSV}",Poland,$5.00-$15.00,"","",2024-02-23 17:34:21.89514,2024-02-23 17:34:21.89514
https://www.upwork.com/jobs/Scraping-Address-from-Company-Websites_~014b2f6ddca6db7320/?referrer_url_path=/nx/search/jobs/,Scraping Address from Company Websites,2024-02-09 10:12:31,"The task is to scrape location data from company websites which will be provided. The address data needs to be arranged into columns including:
--- Continent
--- Country
--- Street address
--- Zip code

Additional information on locations should be captured such as
--- Office name to the extent provided with each location (see example file attached)
--- To the extent there are additional categories (which can be selected on the website through filters), such as division, brand, etc. , this will need to be captured as well","{'"Data Scraping'",Scrapy,Python,'"Data Extraction'"}",Switzerland,a,"","",2024-02-23 17:34:21.904524,2024-02-23 17:34:21.904524
https://www.upwork.com/jobs/Python_~01d91a5dc1d63f82d7/?referrer_url_path=/nx/search/jobs/,Python,2024-02-09 10:40:40,For Schematic circuit automation project we are looking for a contract freelancer we are from technology services company,"{React,Scrapy,Django,Elasticsearch,Flask,MySQL,Python,'"Ecommerce Website'",'"Web Application'",'"NoSQL Database'",'"RESTful Architecture'",'"Data Scraping'",JavaScript,'"Software Architecture & Design'",'"Python Script'"}",India,a,"","",2024-02-23 17:34:21.915246,2024-02-23 17:34:21.915246
https://www.upwork.com/jobs/Email-prospecting_~015418a681d8cbbc95/?referrer_url_path=/nx/search/jobs/,Email prospecting,2024-02-09 17:34:21.921775,Looking for a VA to send cold emails (500 per day) to prospects on the list I would give you. ,"{'"List Building'",'"Data Entry'",'"Online Research'",LinkedIn,'"Email Marketing'",'"Administrative Support'",'"Lead Generation'",'"Internet Marketing'",'"Data Scraping'",'"Data Mining'",'"Data Extraction'",Scrapy,'"Web Crawling'"}",Croatia,a,"","",2024-02-23 17:34:21.926077,2024-02-23 17:34:21.926077
https://www.upwork.com/jobs/are-looking-for-python-scrapy-expert-with-flask-API-development_~011a9c8f4fd60e3d0a/?referrer_url_path=/nx/search/jobs/,We are looking for python scrapy expert with flask API development,2024-02-09 17:34:21.94108,"We are seeking a highly skilled Python Scrapy Expert to join our team on a project focused on web scraping and API development. The ideal candidate will possess extensive experience in scraping various websites and handling large volumes of data. Our project involves continuous scraping for price monitoring and other related tasks, requiring expertise in proxy management to prevent our scrapers from being blocked by targeted websites.

Responsibilities:

Develop and maintain web scraping scripts using Python Scrapy framework to extract data from hundreds of websites efficiently.
Implement strategies for handling large datasets and continuous scraping processes.
Utilize proxy management techniques to prevent IP blocking and ensure uninterrupted scraping operations.
Write and maintain business logic components to process scraped data effectively.
Collaborate with the team to integrate scraping functionalities into the larger project framework.
Develop APIs using Flask framework to expose scraped data for consumption by other modules or external applications.
Ensure code quality, performance, and reliability of scraping and API components.
Participate in code reviews, troubleshooting, and optimization efforts.
Adhere to Git workflows and agile methodologies for version control and project management.
Requirements:

Proficiency in Python programming language.
Extensive experience with web scraping using Scrapy framework, including handling dynamic content, pagination, and anti-scraping measures.
Strong understanding of proxy management techniques to avoid IP blocking.
Familiarity with Flask framework for API development.
Ability to write efficient and scalable code for handling large datasets.
Experience with implementing business logic in Python applications.
Proficient with Git for version control and collaboration.
Familiarity with agile development methodologies.
Excellent problem-solving skills and attention to detail.
Strong communication and collaboration skills to work effectively in a team environment.
This is a challenging role within a larger project where web scraping plays a crucial role. If you are passionate about extracting insights from data and have the expertise to overcome the challenges associated with web scraping, we encourage you to apply.

Please include relevant work samples or portfolio demonstrating your experience with Python Scrapy and Flask development when applying.","{'"Database Architecture'",Python,Flask,API,Scrapy,'"Python Script'",'"API Development'"}",India,cy,"","",2024-02-23 17:34:21.948086,2024-02-23 17:34:21.948086
https://www.upwork.com/jobs/Professional-scraping-websites_~0157fcafbcbc8af8e2/?referrer_url_path=/nx/search/jobs/,Professional scraping of 5 websites,2024-02-09 17:34:21.9599,"I need a professional webscraping engineer to join my team , all details will be discussed in private messages","{'"API Integration'",'"AI Trading'",Automation,'"Business Process Automation'",Scripting,'"Data Scraping'",'"Data Mining'",Scrapy,'"Data Extraction'",Python}",Egypt,a,"","",2024-02-23 17:34:21.966837,2024-02-23 17:34:21.966837
https://www.upwork.com/jobs/need-Web-Scrapper_~0124dca4c9435cac6d/?referrer_url_path=/nx/search/jobs/,I need a Web Scrapper,2024-02-09 17:34:21.973619,"Hi,
I need someone to scrape all pdf files from an openly accessible website: https://www.gwa.de/effie-cases/ There are approximately 800 pdfs in the archive (40 years with approx. 50 pdfs each year).
 it‘s pretty simple need to select the year, then click filter. The cases appear, then you click on each case, click on download button and save the pdf. 
Sometimes you have to click on „more years“ to show more cases on the overview page. 
You can save the PDFs in one folder or create one folder for each year.
Remember, if you download the files by hand, you need to click on „mehr laden“ (load more) on each years overview page to show more files. Sometimes it has to be done several times.","{'"Data Extraction'",'"Web Scraping'",'"Beautiful Soup'",pandas,'"Data Scraping'",Python,'"Data Mining'",'"Data Entry'",Scrapy}",Bangladesh,a,"","",2024-02-23 17:34:21.975625,2024-02-23 17:34:21.975625
https://www.upwork.com/jobs/Web-Scrapping_~01e17fe4d9cc6597cb/?referrer_url_path=/nx/search/jobs/,Web Scrapping,2024-02-08 14:32:38,"Looking to Extract LIVE AUDIO from one website and play the Feed on Youtube.

I am looking to take it from this website:

https://www.supremecourt.gov/oral_arguments/live.aspx

and play it the same way they are playing it:

https://www.youtube.com/watch?v=lIRbvJq4MIY","{'"Data Scraping'",Python,'"Data Mining'",'"Web Crawling'",Scrapy,'"Data Extraction'"}",United States,gO,"","",2024-02-23 17:34:21.984827,2024-02-23 17:34:21.984827
https://www.upwork.com/jobs/Web-Scraping_~01703565974e20295d/?referrer_url_path=/nx/search/jobs/,Web Scraping,2024-02-09 17:34:21.993012,"I''m looking for someone who can create a simple tool that extracts data from a website pages.

A google extension, or a simple software to install on my PC

text me for more details","{'"Data Scraping'",Python,'"Data Mining'",Scrapy,'"Data Extraction'"}",United Kingdom,a,"","",2024-02-23 17:34:21.995448,2024-02-23 17:34:21.995448
https://www.upwork.com/jobs/are-looking-for-python-scrapy-expert-with-flask-API-development_~016e2db360369aba7b/?referrer_url_path=/nx/search/jobs/,We are looking for python scrapy expert with flask API development,2024-02-09 17:34:22.002863,"We are seeking a highly skilled Python Scrapy Expert to join our team on a project focused on web scraping and API development. The ideal candidate will possess extensive experience in scraping various websites and handling large volumes of data. Our project involves continuous scraping for price monitoring and other related tasks, requiring expertise in proxy management to prevent our scrapers from being blocked by targeted websites.

Responsibilities:

Develop and maintain web scraping scripts using Python Scrapy framework to extract data from hundreds of websites efficiently.
Implement strategies for handling large datasets and continuous scraping processes.
Utilize proxy management techniques to prevent IP blocking and ensure uninterrupted scraping operations.
Write and maintain business logic components to process scraped data effectively.
Collaborate with the team to integrate scraping functionalities into the larger project framework.
Develop APIs using Flask framework to expose scraped data for consumption by other modules or external applications.
Ensure code quality, performance, and reliability of scraping and API components.
Participate in code reviews, troubleshooting, and optimization efforts.
Adhere to Git workflows and agile methodologies for version control and project management.
Requirements:

Proficiency in Python programming language.
Extensive experience with web scraping using Scrapy framework, including handling dynamic content, pagination, and anti-scraping measures.
Strong understanding of proxy management techniques to avoid IP blocking.
Familiarity with Flask framework for API development.
Ability to write efficient and scalable code for handling large datasets.
Experience with implementing business logic in Python applications.
Proficient with Git for version control and collaboration.
Familiarity with agile development methodologies.
Excellent problem-solving skills and attention to detail.
Strong communication and collaboration skills to work effectively in a team environment.
This is a challenging role within a larger project where web scraping plays a crucial role. If you are passionate about extracting insights from data and have the expertise to overcome the challenges associated with web scraping, we encourage you to apply.

Please include relevant work samples or portfolio demonstrating your experience with Python Scrapy and Flask development when applying.","{'"Database Architecture'",Python,Flask,API,Scrapy,'"Python Script'",'"API Development'"}",India,cy,"","",2024-02-23 17:34:22.005181,2024-02-23 17:34:22.005181
https://www.upwork.com/jobs/Data-Scraping-from-NFT-marketplace_~016d288b9bc1c40d51/?referrer_url_path=/nx/search/jobs/,Data Scraping from NFT marketplace,2024-02-08 06:34:47,"We are seeking a skilled Data Scraper with experience in web scraping to collect all the audiobook titles from Spotify''s Audiobooks section. Just give the titles in CSV or excel format.

https://open.spotify.com/genre/0JQ5DAqbMKFETqK4t8f1n3

Thanks","{'"Data Scraping'",JavaScript,Python,'"Data Mining'",Scrapy,'"Data Entry'",API,'"Data Extraction'"}",United States,$50.00-$60.00,"","",2024-02-23 17:34:22.014326,2024-02-23 17:34:22.014326
https://www.upwork.com/jobs/Data-scraping-brick-amp-mortar-retailer-webshops_~01a0710fa554063fcd/?referrer_url_path=/nx/search/jobs/,Data scraping brick&amp;mortar retailer webshops,2024-02-08 02:32:24,"I''m looking for a data scraper who can help me to extract data from the websites of diy-retailer. Mainly from Germany, France, USA, Australia.

I generally want to get customer reviews from different online shops in certain categories. 
If somehow trending products or sales quantity could be scraped too would be good.","{'"Web Scraping'",'"Data Scraping'",Python,'"Data Mining'",'"Data Extraction'",'"Browser Automation'",Selenium,'"Beautiful Soup'",Scrapy,'"Data Visualization'",'"Data Analysis'",'"Desktop Application'",'"API Integration'",Scripting,'"Scripts & Utilities'"}",Hong Kong,a,"","",2024-02-23 17:34:22.02616,2024-02-23 17:34:22.02616
https://www.upwork.com/jobs/Bot-that-can-scrape-county-websites-for-real-estate-leads-Web-scraper_~0128d4bfb4bcb7117e/?referrer_url_path=/nx/search/jobs/,"Bot that can scrape county websites for real estate leads, Web scraper",2024-02-09 17:34:22.032445,Need a bot created that can extract data from my county for my real estate business. ,"{'"Data Scraping'",'"Lead Generation'",'"Data Mining'",'"Web Crawling'",'"Data Entry'",Scrapy,'"List Building'"}",United States,a,"","",2024-02-23 17:34:22.03409,2024-02-23 17:34:22.03409
https://www.upwork.com/jobs/Seeking-Data-Scraping-Specialist_~016179e83819bd113a/?referrer_url_path=/nx/search/jobs/,Seeking Data Scraping Specialist,2024-02-07 17:25:26,"We''re searching for a skilled data scraping specialist to assist in collecting information from top industry platforms. The job will focus on finding and extracting important data to aid our business analysis and strategic planning.

Responsibilities:

Extract data from specific online platforms.
Maintain accuracy and proper format of the collected data.
Work with our team to pinpoint essential data points.
Requirements:

Demonstrated experience in data scraping.
Knowledge of scraping tools such as Beautiful Soup, Scrapy, Puppeteer","{Scrapy,Puppeteer,'"Data Scraping'",'"Data Extraction'",Node.js}",United Kingdom,a,"","",2024-02-23 17:34:22.04091,2024-02-23 17:34:22.04091
https://www.upwork.com/jobs/Scraping-Linkedin-emails_~01c1298b43b258043e/?referrer_url_path=/nx/search/jobs/,Scraping Linkedin emails,2024-02-07 15:05:54,"I am looking for someone who can scrape emails for up to 500 contacts to start each month that I will provide. To prove you can do this show me you can scrape these 3 from LinkedIn profiles as a test 

Mary McCann 
Krissy Cela 
Mia Thornburgh

","{'"Lead Generation Analysis'",'"Lead Generation Content Creation'",'"Lead Nurturing'",Leadfeeder,Unbounce,'"Data Scraping'",'"Lead Generation'",'"List Building'",Scrapy}",Pakistan,a,"","",2024-02-23 17:34:22.049803,2024-02-23 17:34:22.049803
https://www.upwork.com/jobs/Data-Scientist-for-Scraping-and-Analyzing-Estate-Agents-Data_~015476eb6304eb863d/?referrer_url_path=/nx/search/jobs/,Data Scientist for Scraping and Analyzing UK Estate Agents' Data,2024-02-09 17:34:22.057056,"Job Description:

We are seeking a highly skilled data miner or research specialist to create a detailed database of every estate agent operating in the UK. This project requires gathering extensive information, including the agency''s name, email, owner, main contact, phone number, and an estimated size based on the number of listings or staff. The right candidate will have a proven track record in advanced data mining techniques, email and contact verification, and a keen understanding of the UK real estate market.

Responsibilities:

Compile a comprehensive list of UK estate agents, categorised by their services in lettings, sales, or both.

Collect detailed information for each agency, including name, email, owner, main contact, and phone number.

Estimate the size of each agency, potentially based on the number of listings or staff, through available data or estimations.

Ensure data accuracy through verification processes.

Requirements:

Strong experience in data mining and web scraping, with a focus on accuracy and compliance with legal standards.

Proficiency in tools and languages for data scraping (e.g., Python, BeautifulSoup, Scrapy) and data analysis.

Experience in data verification and validation techniques.

Keywords: Data Mining, Web Scraping, Real Estate Data Collection, UK Estate Agents, Contact Verification, Data Analysis, Python, GDPR Compliance.

","{Scrapy,'"Beautiful Soup'",Selenium,'"Data Mining'",'"Data Scraping'",'"Microsoft Excel'",Python,'"Data Analysis'",'"Data Entry'",'"Data Extraction'"}",United Kingdom,$7.00-$20.00,"","",2024-02-23 17:34:22.059525,2024-02-23 17:34:22.059525
https://www.upwork.com/jobs/Automation-and-datadome-bypass_~013bd2adcbe5886fb7/?referrer_url_path=/nx/search/jobs/,Automation and datadome bypass,2024-02-09 17:34:22.065894,"Hi

I am looking for a developer with vast experience in automation. Ideally I require someone with previous experience and has the capabilities to solve problems on the go. The project requires an automation for some parts of the website whilst bypassing website security such as datadome. 

REQUIREMENTS
Bot for a site that’s capable of purchasing a high no. of products. The bot’s required to monitor continuously on the site and  as soon as products become available, add to the cart for the user to checkout manually.
Site is datadome protected and uses queue it at the time of sales (bypass both)
The bot will purchase products on official release day as soon as queue-it queue becomes active.
2 scenarios faced by user:

First scenario
Monitor site to see if products become available they must be carted which opens a new browser with carted products in the basket or a checkout link generated and sent to discord for checkout
Once the above is successfully completed, notification alert given on discord with checkout link. If the user is on the server, they start the process to checkout products that have been carted which would be a manual process.
Bot must continue running on the site for any further release of products (2+ minimum) and be carted during checkouts until stopped.
Second scenario
Setup bot for release day. Products go on sale to the general public on specified date and time. On that date, queue (using queue-it) would be active and needs to be bypassed to ensure the user is first on the site.
Then a task would be set for that day. On task setup the inputs required are firstly adding the targeted URL along with the refresh rate. Secondly, quantity of products being added into the basket would again be 2/3/4. Thirdly, adding the proxies.Lastly, how many chrome browsers to open if products carted successfully. This means how many browsers the bot needs to cart bulk products so a browser limit can be set by user for how many can be open at a certain time.
E.G. If browser limit set to 10 and quantity of products set to 2. If successful, 2 products would be carted per browser and 10 separate checkout browsers automatically pop up for user to manually process checking out.","{'"Software Architecture & Design'",Python,Selenium,Automation,'"Browser Automation'",'"Beautiful Soup'",Scrapy,'"Data Scraping'",Scripting,API,'"Bot Development'",'"Amazon Web Services'",JavaScript,'"Machine Learning'",Bot}",United Kingdom,a,"","",2024-02-23 17:34:22.069652,2024-02-23 17:34:22.069652
https://www.upwork.com/jobs/Experienced-web-scraper-grabbing-data-from-public-government-databases_~01a3040da357053474/?referrer_url_path=/nx/search/jobs/,Experienced web scraper grabbing data from (public) government databases,2024-02-09 17:34:22.076024,"We need to access public government databases in an automated manner.  Initially we are targeting U.S. federal and state website.  We are gathering only public data - this is not a secret hacking project.

Some of the data we want could be behind captchas and other speed bumps that would need to be scripted to address repeatedly.

For at least one federal database, there may be API access available.  

Bonus points if you have any experience related to trademark databases.
","{'"API Integration'",'"Data Scraping'",'"Data Extraction'",Scrapy}",United States,cG,"","",2024-02-23 17:34:22.077977,2024-02-23 17:34:22.077977
https://www.upwork.com/jobs/Producthunt-scraping-needed_~019a171892e65d769f/?referrer_url_path=/nx/search/jobs/,Producthunt scraping needed,2024-02-09 17:34:22.084561,"Hello!

I am looking for someone that can scrape Producthunt.com tool listings on scale (with additional info included like website, socials, emails, etc.) 

Priority will be to those freelancers that use particular publically available tools to achieve this. 

Let me know if you can do it and what the pricing would be per 1k leads.","{'"Data Scraping'",'"Data Mining'",'"Lead Generation'",Scrapy}",Latvia,$5.00-$10.00,"","",2024-02-23 17:34:22.086216,2024-02-23 17:34:22.086216
https://www.upwork.com/jobs/Web-Scrapping-Amazon_~0124e60b716ac905fa/?referrer_url_path=/nx/search/jobs/,Web Scrapping Amazon,2024-02-09 17:34:22.093101,"i just need some one who is aware how to do scrapping in amazon
i need to scrape the product reviews
the code is ready iam facing ip issues, i need someone who can solve this issue, since my ip is getting block
Besides, i have more such projects! looking for a long time contact!","{'"Data Scraping'",Python,'"Data Mining'",'"Web Crawling'",Scrapy}",United States,a,"","",2024-02-23 17:34:22.094827,2024-02-23 17:34:22.094827
https://www.upwork.com/jobs/Shopify-developer_~0114f0ee4c27bc086b/?referrer_url_path=/nx/search/jobs/,Shopify developer,2024-02-06 14:59:17,thanks for all the changes and now it seems to work that we can connect here,"{'"Blog Writing'",'"Beautiful Soup'",'"Data Mining'",'"Web Scraping'",WordPress,Scrapy,pandas,'"Data Extraction'",Selenium,'"PSD to WordPress'",'"Data Scraping'",'"Front-End Development'",'"SEO Writing'"}",Germany,a,"","",2024-02-23 17:34:22.10298,2024-02-23 17:34:22.10298
https://www.upwork.com/jobs/Scaper-Expert-Ticket-Project_~012b47fad45c844b31/?referrer_url_path=/nx/search/jobs/,Scaper Expert - Ticket Project,2024-02-06 14:41:37,"For a new project where we want to deliver tickets from museums we need a professional scraper builder.

We don''t have specific stack as long as you can work with our project developer to let him integrate the scraper in the project.

We start with this specific website:
https://www.annefrank.org/en/

First of all you need to scrape the availability from this step:
https://www.annefrank.org/en/museum/tickets/choose-your-ticket/tickets-2023/ 

When a consumer buys we need a bot that completes the check out as well, gets ticket from the email and send to our customer.

If this is something you have (a lot) of experience with and you can communicate well and work with our developer to make this a success, then please reply to this post.","{Scrapy,Selenium,'"Beautiful Soup'",'"Data Scraping'",'"API Integration'",'"Web Scraping'",'"Web Crawling'",Python,PHP,JavaScript}",Netherlands,$15.00-$45.00,"","",2024-02-23 17:34:22.112066,2024-02-23 17:34:22.112066
https://www.upwork.com/jobs/AWS-remote-server-Support-for-Django-Python-system-failure_~010686f44b9b736c67/?referrer_url_path=/nx/search/jobs/,AWS remote server Support for Django Python system failure ,2024-02-09 17:34:22.120775,we need a professional german speaking server admin who is willing to guides us in AWS server console and helps us to find the reason why server error 500 occurs when we try to change content within our backend.   ,"{Python,Django,SQL,Flask,Scrapy,'"AWS CodeDeploy'"}",United Arab Emirates,a,"","",2024-02-23 17:34:22.123122,2024-02-23 17:34:22.123122
https://www.upwork.com/jobs/Need-generic-crawler-for-real-estate-sites_~011aac3e3d08eb90d0/?referrer_url_path=/nx/search/jobs/,Need generic crawler for real estate sites,2024-02-06 13:02:29,I have thousands of real estate websites I need to filter listing urls from these websites as a start I will provide you some websites I need someone who can do it in scrapy there can be static and dynamic websites both ,"{'"Data Extraction'",'"Screen Scraping'",'"Web Scraping'",'"Web Crawling'",Scrapy,'"Beautiful Soup'",'"Data Scraping'",Python,JavaScript}",Pakistan,a,"","",2024-02-23 17:34:22.137738,2024-02-23 17:34:22.137738
https://www.upwork.com/jobs/Create-scalable-API-from-python-scraping-script_~01dd77223ee5d7104e/?referrer_url_path=/nx/search/jobs/,Create a scalable API from a python scraping script,2024-02-06 05:18:00,"We are looking for a skilled automation/scripting engineer to set up a serverless function that can be called to evoke an existing Python scraping script.

We assume that this script will work locally and at a low scale. We intend for the solution to work at scale (2,000-5,000 requests per day). We also assume that there are security measures on the website that we are scraping from, such as IP tracking, and limitations that should be avoided.

We expect the script to scrape and pass binary image data for another API for uploading and return a response.

More information about what exists already:

The script is a single python file, which is only 118 lines long. The script is designed to automate the process of scraping data and images from a listing page on a website using Python. It incorporates libraries such as os, time, requests, selenium, urllib.parse, bs4 (BeautifulSoup), and json to perform various tasks such as web scraping, parsing, and file management. Here''s a technical summary of its components and functionalities:

Directory Management: The function create_directory checks if a specified directory exists; if not, it creates the directory. This is used to organize downloaded images.

Image Downloading: download_image downloads images from given URLs and saves them with specified filenames. It uses the requests library to fetch the image and writes it to a file in binary mode.

Web Scraping: The script employs both BeautifulSoup and Selenium for web scraping. BeautifulSoup is used within scrape_page_information to parse HTML page source and extract specific data based on CSS class names. It includes a special case for extracting the &quot;Condition&quot; value of an item. Selenium is used for dynamic web pages that require JavaScript execution to render content, such as image galleries.

Selenium WebDriver Setup: extract_images_and_scrape_info sets up a Selenium WebDriver to interact with the web page. It navigates to the URL, waits for the page to load, and then performs operations like checking for specific elements (e.g., &quot;Authentication Guarantee&quot;) and scraping page information.

Image Extraction and Download: This part of the script interacts with image elements on the page using Selenium to find images in a carousel, build their URLs, and download them. It saves each image in a directory specific to the item being scraped, organizing images by item ID.

Data Extraction and Saving: After scraping data and downloading images, the script compiles scraped data (including an &quot;Authentication Guarantee&quot; flag) into a JSON file. This JSON file is saved within the item''s directory, providing structured data alongside the images.

Execution Flow: The script''s main block prompts the user for a URL, sets a base download directory, and then calls extract_images_and_scrape_info to perform the scraping and downloading tasks.

Error Handling: Minimal error handling is included, primarily through try-except blocks in check_authentication_guarantee to handle cases where elements are not found on the page.","{Python,API,Automation,'"Data Scraping'",Scripting,'"Python Script'",Scrapy,'"Data Mining'",JavaScript}",United States,$30.00-$60.00,"","",2024-02-23 17:37:44.371643,2024-02-23 17:37:44.371643
https://www.upwork.com/jobs/Web-Scraping-Specialist-for-Data-Extraction-and-Text-Document-Creation_~01032012b11d555e6c/?referrer_url_path=/nx/search/jobs/,"Web Scraping Specialist for Data Extraction and Text Document Creation. 

",2024-02-06 04:35:07,"seeking a skilled web scraping specialist to extract data from a specific website and organize it into text documents. The extracted data will be used to train a language model for various natural language processing tasks. 
Suitable for individuals with expertise in web scraping and data extraction techniques.","{'"Data Scraping'",Python,'"Data Mining'",Scrapy}",United States,$5.00-$11.00,"","",2024-02-23 17:37:50.441854,2024-02-23 17:37:50.441854
https://www.upwork.com/jobs/SCRAPING-GURU-needed-Scrape-JOBS-from-various-sites-get-contact-info-create-email-campaign_~01897734ab190d80e5/?referrer_url_path=/nx/search/jobs/,"SCRAPING GURU needed to Scrape JOBS from various sites, get contact info., create email campaign.",2024-02-06 00:56:44,"We want to build a portal that can help us scrape JOBS from multiple Job sites like Linkedin, Indeed, Dice, Monster, Careerbuilder, Ziprecruiter, Zippia.

Portal has to have following options:
Select Job Portal site fromt eh drodown (All sites will be listed in admin panel that can be displayed in dropdown).
USer will have an option to paste A URL from source site that results in job listed or User will enter the required keywords.

Knowledge of AI/LLM/EMbedding/Vector databases is a huge plus.
AutoGen with automatic browsing, headless browsing, stealth browsing, mimicking human behavior while scraping usign Puppeteer plugins will be very advantageous.

For Ex: (for more URL''s see attachement)
URL:
https://www.linkedin.com/jobs/search/?currentJobId=3822568956&amp;f_E=4%2C5&amp;f_I=96%2C11%2C4%2C43%2C47%2C6%2C14%2C84%2C1594&amp;f_JT=F&amp;geoId=103644278&amp;keywords=AWS&amp;location=United%20States&amp;origin=JOB_SEARCH_PAGE_JOB_FILTER&amp;refresh=true&amp;sortBy=R

OR 
Source: Linkedin
Keywords: Salesforce
Job Type: Contract
Location: New York

will retrieve JOBS from Linkedin with keyword Salesforce and location= New York and Jib Type =Contract

All scraped data will be saved in the database with Job URL as the key.
https://www.linkedin.com/jobs/view/3822486265
Do not save duplicate jobs.
Try to scrape all possible data elements from the job data
Job Posting Company, Location, Job Title, Job Poster if available.

Option to download the results in CSV file.

There will be next steps to find decision makers from these companies and get contact information of the decision makers using tools like Apollo, seamless and many other API''s.

Next phase will be to create a DRIP email campaign to send EMAILS to the decision makers with personalized message mentioning the site and job details in the email so that every message is personalized.

You need to submit proposal for only PHASE I to scrape Linkedin JOBS only. All other sites and next phases will be discussed after you completing the phase I.

THis can be a desktop app using tools like electron.js or web based app using puppeteer/selenuium. Expereince if usign headless browser and avoid any bot detentction expertise is a MUST have. Option to use Datacenter or Residential proxy or proxy providers will be required in future phases.

All data wil be stored in PostGres SQL database on Linode hosting.

All BOT responses will be deleted automaticaly.
Please mention *ScrapingExpert* ias the first word in your response, else your response will be dleeted.


","{Selenium,Puppeteer,'"Web Scraping Plugin'",'"Web Scraping Framework'",'"Data Scraping'",Scrapy,Python}",United States,$40.00-$100.00,"","",2024-02-23 17:37:50.449459,2024-02-23 17:37:50.449459
https://www.upwork.com/jobs/Web-Scraping-Specialist_~0182d916ceea5b65ad/?referrer_url_path=/nx/search/jobs/,Web Scraping Specialist,2024-02-05 21:15:23,"We are seeking a highly skilled and experienced Web Scraping Specialist to join our team. The ideal candidate will be responsible for developing and implementing web scraping scripts and tools to extract data from various online sources efficiently and accurately. This role involves analyzing and collecting data that is crucial for our business intelligence, market research, and strategic planning efforts. The Web Scraping Specialist will work closely with our data analysis and IT teams to ensure the quality and reliability of data collected.

Responsibilities:
Design, develop, and maintain web scraping scripts and tools to extract data from targeted websites.
Ensure the integrity and accuracy of scraped data through rigorous testing and validation processes.
Manage and optimize the performance of web scraping activities to handle large volumes of data without compromising on speed or efficiency.
Work with data analysts to understand data requirements and ensure that the scraping solutions meet business needs.
Stay up-to-date with advancements in web scraping technologies and methodologies, as well as changes in web standards and site architectures that may affect scraping activities.
Handle proxy servers, User-Agents, and CAPTCHAs to manage web scraping activities effectively.
Ensure compliance with legal and ethical standards related to web scraping and data privacy.
Troubleshoot and resolve any issues arising during the scraping process.
Requirements:
Proven experience in web scraping, data extraction, and data processing.
Strong programming skills in Python, including experience with web scraping libraries such as Beautiful Soup, Scrapy, or Selenium.
Knowledge of HTML, CSS, JavaScript, and web technologies.
Familiarity with database management, including SQL, and data storage solutions.
Ability to work with APIs and understand the technical documentation.
Strong problem-solving skills and attention to detail.","{'"Data Scraping'",'"Data Mining'",'"Microsoft Excel'",Scrapy,Python,'"Data Extraction'"}",United States,ct,"","",2024-02-23 17:37:50.457814,2024-02-23 17:37:50.457814
https://www.upwork.com/jobs/need-Expert-Web-scraper_~01adc9fa0bff1a741b/?referrer_url_path=/nx/search/jobs/,I need an Expert Web scraper ,2024-02-02 17:37:52.890834,"Hi.

I want all contact data pulled from https://edgehomefinance.com/our-team/.

I want all data organized into an excel spreadsheet and each record should have First Name, Last Name, Title (i.e. Loan Officer), NMLS #, Email, Phone #.

Email address and phone number can be captured by hovering over the &quot;email me&quot; and &quot;call me&quot; sections of each contact.

The end result should be around 950+ records.","{'"Data Extraction'",'"Web Scraping'",'"Beautiful Soup'",Selenium,'"Data Scraping'",Python,'"Data Mining'",Scrapy,'"Data Entry'"}",Bangladesh,a,"","",2024-02-23 17:37:52.892918,2024-02-23 17:37:52.892918
https://www.upwork.com/jobs/Scraping-bot-needed_~01651d540eea9d3308/?referrer_url_path=/nx/search/jobs/,Scraping bot needed,2024-02-09 17:37:50.463967,"We are looking for an expert who can build a bot for us that can scrape information from the web pages of canada.ca and other govt. websites.

At this moment we have to scrape the information from pages like these  sample links- https://www.canada.ca/en/immigration-refugees-citizenship/services/visit-canada/extend-stay.html https://www.canada.ca/en/immigration-refugees-citizenship/services/visit-canada/parent-grandparent-super-visa/apply.html

we need all the text from the pages like the ones mentioned above.
we need to scrape information from the govt websites of the whole world so our intention is not to build a separate bit for every country.

The bot should be able to detect any changes in all the pages which will be scraped. If any change is found, all the text should be scraped again, or only the section with the change.

We have to run the ML/AI on the extracted text but that most won''t probably won''t be your task.","{'"Data Scraping'",Python,Automation,'"Bot Development'",Scripting,Scrapy,'"Web Crawling'",Selenium}",Canada,a,"","",2024-02-23 17:37:50.465714,2024-02-23 17:37:50.465714
https://www.upwork.com/jobs/Website-Scraping_~015e51ff6aa40b707e/?referrer_url_path=/nx/search/jobs/,Website Scraping,2024-02-05 19:43:54,"I have 2 pieces to this project. I am looking to find the ISO''s (independent sales offices) for merchant processing (also known as acquirer''s or merchant processing acquirers) in certain states in the US. 

Step 2 would be on each of those ISO''s to extract the Terms and conditions of their contracts if they are listed on their websites.

Many ISO''s don''t have websites so finding those without websites would be very beneficial as well. ","{'"Data Scraping'",'"Data Mining'",Scrapy}",United States,a,"","",2024-02-23 17:37:50.478565,2024-02-23 17:37:50.478565
https://www.upwork.com/jobs/Web-scraper-web-scraping-data-mining-email-scraping-and-data-extraction-for-business-leads_~0184b76391ef36dbd6/?referrer_url_path=/nx/search/jobs/,"Web scraper, web scraping, data mining, email scraping and data extraction for business leads",2024-02-09 17:37:50.48598,"We are looking for an expert in web scraper, web scraping, data mining, email scraping and data extraction to help use generate business information.  We would need:

1. Email
2. Phone Number 
3. Address

An example of business information we would need to generate would be all in the USA all cities:

Target phone stores
Used phone stores
Electronic stores
Phone repair stores
Phone kiosk
Pawn stores
Authorized Carrier dealers example AT&amp;T/Tmob/Xfinity/Verizon/Spectrum etc.

If you are able to do this please do let me know ","{'"Data Scraping'",'"Data Mining'",'"Data Extraction'",Scrapy,'"Lead Generation'",'"Microsoft Excel'"}",Canada,$7.00-$20.00,"","",2024-02-23 17:37:50.488286,2024-02-23 17:37:50.488286
https://www.upwork.com/jobs/Python-Scraping-Script-for-Agencies-business-Profiles_~0109195e15e0d9e6e5/?referrer_url_path=/nx/search/jobs/,Python Scraping Script for Agencies business Profiles,2024-02-05 17:00:58,"A Date Collector is a professional adept at sourcing, cleaning, and sorting data. The role involves obtaining data from various sources, both manual and digital, and preparing organized data batches for use by business researchers, campaign executives, and sales teams.

Write a script to extract contact information (phone, email, next of kin) for property owners from apollo.com and update our spreadsheets.

Please quote me a price and tell me how long it''s going to take, and how much it will cost.","{'"Data Scraping'",Python,Scrapy,Python-Goose,Selenium,'"Web Crawling'"}",United States,a,"","",2024-02-23 17:37:50.501709,2024-02-23 17:37:50.501709
https://www.upwork.com/jobs/Developer-Needed-for-Automated-Data-Extraction-and-Spreadsheet-Integration_~015469daa8254b4d86/?referrer_url_path=/nx/search/jobs/,Developer Needed for Automated Data Extraction and Spreadsheet Integration,2024-02-05 14:23:40,"
Description:

We are seeking a skilled programmer to create an automated system that populates spreadsheet cells with data extracted from provided links to real estate listings. These links may direct to either web pages or online PDF documents. The successful candidate will have strong experience in web scraping, PDF parsing, and integrating with spreadsheet software such as Google Sheets or Microsoft Excel.

Project Requirements:

Web Scraping: 
Extract specific data points (e.g., property address, price, number of bedrooms and bathrooms, square footage) from real estate listing web pages.
PDF Parsing: 
Extract similar data points from online PDF documents.
Spreadsheet Integration: 
Automatically populate a spreadsheet with the extracted data, based on a link provided in one of the cells.
Automation Skills: Set up a trigger mechanism for the process, either manual or automatic.

Programming Languages: 

Proficiency in Python or a similar language, with experience using relevant libraries for web scraping (e.g., BeautifulSoup, Scrapy), PDF parsing (e.g., PyPDF2, pdfplumber), and spreadsheet integration (e.g., gspread, openpyxl).
Qualifications:

Proven experience with web scraping and PDF parsing projects.
Strong knowledge of spreadsheet APIs and automation techniques.
Ability to write clean, efficient, and well-documented code.
Excellent problem-solving skills and attention to detail.
Project Timeline: Please provide an estimated timeline for completion based on the project requirements.

Application Instructions: 

Interested candidates should submit a proposal outlining their approach to the project, including any similar projects they have completed. Please also include your estimated timeline and budget.","{Scrapy,'"Data Scraping'",Python,'"Data Extraction'",'"Google Sheets'"}",Israel,a,"","",2024-02-23 17:37:50.514964,2024-02-23 17:37:50.514964
https://www.upwork.com/jobs/Build-Twitter-Email-Scraper-get-emails-from-profiles_~01493752c1c31d6071/?referrer_url_path=/nx/search/jobs/,Build a Twitter Email Scraper to get emails from profiles,2024-02-05 13:18:07,"Hello, I need someone to create a Twitter Scraper that will get people''s emails, so we can use them in marketing campaigns.

Example of 2 tools that do the same thing:

https://tweetscraper.io
https://www.scrapybird.com

ONLY APPLY IF YOU KNOW 100% HOW TO DO IT.

Please quote me a price and tell me how long it''s going to take, and how much it will cost.","{'"Data Scraping'",'"Data Mining'",'"Lead Generation'",Python,Scrapy,'"Data Entry'",'"Prospect List'"}",Romania,a,"","",2024-02-23 17:37:50.524211,2024-02-23 17:37:50.524211
https://www.upwork.com/jobs/Data-Scraping-Script-Writer_~010fdc5149c2012664/?referrer_url_path=/nx/search/jobs/,Data Scraping Script Writer,2024-02-05 07:47:26,"We are looking for developers and Python experts to create a whole range of data scraping scripts that we can run on our servers

Some kinds of data we are interested in include but are not limited to 

- Investment data from platforms like Crunchbase &amp; Wellfound
- B2B Contact Information - especially work emails and direct dials
- IP address data for companies and servers
- Techno graphic data for companies (including CRM Systems, tech stacks, servers.etc.)
- Various industry specific data

We welcome candidates with a wide range of skills, the position is long term - starting with a few hours a week.

The ideal candidate should have experience with data scraping, but we also welcome juniors who are ready to take the step-up.

PLEASE NOTE: Any generic applications will be immediately rejected","{'"Data Scraping'",Python,Scripting,'"Data Mining'",Scrapy,Python-Goose}",Slovakia,$3.00-$12.00,"","",2024-02-23 17:37:50.534125,2024-02-23 17:37:50.534125
https://www.upwork.com/jobs/Lead-Generation-data-Extraction-from-Companies_~013f0b6ed1d0ed6c15/?referrer_url_path=/nx/search/jobs/,Lead Generation by data Extraction from UK Companies,2024-01-30 18:21:08,"hi, We need leads from Linkedin, google and other web directories of United kingdom only. If you have done sraping from these channels, then please submit the proposal. We will not accept if you this work manually.
We will only except proposals for scraping using programming.","{'"Data Extraction'",Scrapy,'"Web Scraping Framework'",'"Web Scraping Plugin'",Python,'"Data Scraping'",'"Lead Generation'",'"Market Research'"}",United Kingdom,$5.00-$35.00,"","",2024-02-23 17:37:52.900346,2024-02-23 17:37:52.900346
https://www.upwork.com/jobs/Account-Automation-Farming-Gmail_~0125c1cf5a84586c75/?referrer_url_path=/nx/search/jobs/,Account Automation + Farming + Gmail,2024-02-05 06:58:14,"We are seeking a Digital Account Creation Specialist to join our dynamic team. This role involves the strategic development and maintenance of digital accounts, primarily focusing on Gmail and Google Ads accounts. The ideal candidate will possess a deep understanding of digital footprints, proxy management, and the nuances of creating and maintaining digital identities that withstand scrutiny while delivering value across various platforms.

Need help with Gmail F@rming For G00gles / G M B R3vi3ws

","{Automation,'"AI Trading'",'"API Integration'",'"Business Process Automation'",Dashboard,'"Data Extraction'",'"Data Mining'",'"Data Scraping'",'"Forex Trading'",'"Google Sheets Automation'",'"Robotic Process Automation'",Scripting,'"Web Application Development'",'"Apache Nutch'",jQuery,'"Beautiful Soup'",Node.js,Scrapy,Selenium,StormCrawler,'"AI Builder'",'"Automation Anywhere'",'"Google Closure'",'"Kofax RPA'",'"Macro Programming'",Make.com,n8n,NinjaTrader,Python,Ruby,TypeScript,'"Apache Groovy'",AppleScript,Bash,Lua,JavaScript,PHP,'"Microsoft VBScript'",'"Microsoft Windows PowerShell'",Perl,'"Pine Script'",R,'"Visual Basic for Applications'",'"Data Entry'",'"Email Marketing'"}",Australia,a,"","",2024-02-23 17:37:50.545601,2024-02-23 17:37:50.545601
https://www.upwork.com/jobs/Need-telegram-session-full-request-creator_~01e18136bdac24a3cb/?referrer_url_path=/nx/search/jobs/,Need a telegram session full request creator,2024-02-04 22:57:58,"hello,,  we now need a telegram session creator full request based  python/node full source code

1 it can automatically api to create account( can give you example)
2 account should have session+json file  can show you example
3 make it support proxy and multi thread so it can run very fast
4 undetectable make sure all session wont get banned

if you can do this easily please submit if good and fast, we will havev lot more task for you!
we are looking for long term business

thanks and talk soon!
","{Node.js,Automation,Scrapy,Python,API,'"Telegram API'",PHP,Telegram,C#,JavaScript}",United States,a,"","",2024-02-23 17:37:50.556653,2024-02-23 17:37:50.556653
https://www.upwork.com/jobs/Scrape-website-with-all-data_~01e100226211fa0211/?referrer_url_path=/nx/search/jobs/,Scrape website with all data,2024-02-09 17:37:50.563879,"Hello

We need all companies that appear on this website scraped including all data you can scrape about them, full name, contact person, email, website, hall location, description etc

https://www.fruitlogistica.com/en/trade-visitors/exhibitor-search/#/search/f=h-entity_orga;v_sg=0;v_fg=0;v_fpa=FUTURE

","{'"Data Scraping'",Python,'"Data Extraction'",'"Web Crawling'",'"Data Entry'",Scrapy}",Israel,a,"","",2024-02-23 17:37:50.566057,2024-02-23 17:37:50.566057
https://www.upwork.com/jobs/Quick-scrape-data-from-website-using-Scrapy_~01b8ba6cb14e9432f4/?referrer_url_path=/nx/search/jobs/,Quick : scrape data from a website using Scrapy,2024-02-04 15:38:46,"Hi,
i want to scrape a data from website by using Scrapy and output this data as CSV file. ",{Scrapy},Morocco,a,"","",2024-02-23 17:37:50.583723,2024-02-23 17:37:50.583723
https://www.upwork.com/jobs/Automation-task-urgent_~017c13a5dd9d7fab9c/?referrer_url_path=/nx/search/jobs/,Automation task urgent ,2024-02-04 14:03:58,"Please watch the video need this task done as soon as possible 
https://www.veed.io/view/768367ef-b2dd-4241-acb2-36b8bfe5c323?panel=share","{'"Data Extraction'",'"Data Scraping'",'"Web Crawling'",Scripting,Scrapy,Selenium,'"Beautiful Soup'",Python,Automation}",Pakistan,a,"","",2024-02-23 17:37:50.598132,2024-02-23 17:37:50.598132
https://www.upwork.com/jobs/Data-extraction_~019a09fd67b9bdc646/?referrer_url_path=/nx/search/jobs/,Data extraction,2024-02-09 17:37:50.605281,"I have a list of 145k linked profile urls u am looking for someone who can go to each profile and scrape ,educational institues,degrees, dates of educational degrees,job companies ,job titles ,job years ,languages ,skills,about,location and store in a csv file I need someone who can do it through api for fast data scraping I need it done quickly within 3 days please bid fixed amount as well I will hire experienced and someone who bid less","{'"Screen Scraping'",'"Web Scraping'",'"Web Crawling'",'"Beautiful Soup'",Scrapy,Python-Requests,'"Data Extraction'",Python,'"Data Mining'",'"Data Scraping'"}",Pakistan,g$,"","",2024-02-23 17:37:50.60758,2024-02-23 17:37:50.60758
https://www.upwork.com/jobs/Data-Scraping-Expert_~01b63866512828d967/?referrer_url_path=/nx/search/jobs/,Data Scraping Expert,2024-02-09 17:37:50.614749,"We are looking for a skilled Data Scraping Expert to assist us in extracting and compiling data from various sources for our projects. 
(project duration: long-term, with one quarterly project.)

You will work directly with our project manager.

About BooxAI:
The startup operates in the book publishing vertical. We have developed an AI-based service for authors who want to publish their book on over 100 distribution channels in just 30 days instead of 6+ months.

Our AI handles tasks such as cover design, proofreading, formatting, and distribution, pivotal in the book publishing process. We are constantly adding more functionalities to our service.

Key requirements:
- Fluent English
- Positive attitude
- People person
- 3-4 years of experience in data scraping technologies
Ability to navigate and extract data from complex data structures.

Additional information:
We are currently in the process of finalizing our budget for these services. We plan to have a transparent discussion to determine a fair and mutually agreeable rate.

Website:
Booxai.com
","{'"API Integration'",'"Web Crawling'",'"Web Scraping'",Scrapy,Selenium,'"Data Scraping'",'"Microsoft Excel'",'"Data Extraction'",Python,'"Data Mining'"}",Israel,a,"","",2024-02-23 17:37:50.617461,2024-02-23 17:37:50.617461
https://www.upwork.com/jobs/Web-Scraping_~01e12616166271d785/?referrer_url_path=/nx/search/jobs/,Web Scraping,2024-02-02 17:37:50.625351,"I need help with a web scraping project. I have a list of companies and I would like to extract their contact information and other relevant data from their websites. The data I need includes the name of the company, address, phone number, and email. The data should be organized in a spreadsheet for further analysis. The project should be completed within 1 week. I am looking for someone who is familiar with web scraping tools and techniques.","{'"Data Scraping'",Python,'"Data Mining'",Scrapy}",India,ct,"","",2024-02-23 17:37:50.627439,2024-02-23 17:37:50.627439
https://www.upwork.com/jobs/Web-Scraping-Specialist_~01a893515a269580b6/?referrer_url_path=/nx/search/jobs/,Web Scraping Specialist,2024-02-03 14:17:44,I have to find talent web scraper who will scrape inventory product detail data from door dash website,"{'"Data Scraping'",Python,'"Data Entry'",Scrapy,'"Data Mining'",'"Microsoft Excel'",'"Data Extraction'",'"Lead Generation'"}",United States,$50.00-$70.00,"","",2024-02-23 17:37:50.636026,2024-02-23 17:37:50.636026
https://www.upwork.com/jobs/Webscraping-Support-amp-Knowledge-sharing_~013550f0104353f8c3/?referrer_url_path=/nx/search/jobs/,Webscraping Support &amp; Knowledge sharing,2024-02-02 17:37:52.907709,"We carry out online data collection. We mainly collect data from online stores, marketplaces and company websites.
We use proxies and web scraping technologies such as Scrapy, Puppeteer and solutions such as Selenium.

We are looking for support for projects from experienced specialists who have already implemented many projects with Selenium, Scrapy or Puppeteer and can help with the implementation of new projects and share their experience and best practices with our teammates to improve our scrapers. for the improvement of our scrapers.","{'"Web Scraping'",'"Data Mining'",Automation,'"Bot Development'",Selenium,'"Beautiful Soup'",Scrapy,XPath,PostgreSQL,XLSX,CSV,JSON}",Germany,a,"","",2024-02-23 17:37:52.910337,2024-02-23 17:37:52.910337
https://www.upwork.com/jobs/Web-Crawling-and-Data-Extraction_~01cb9406ac97e458b2/?referrer_url_path=/nx/search/jobs/,Web Crawling and Data Extraction,2024-02-02 22:20:42,"We are seeking a skilled Software Developer with expertise in web crawling and data extraction. The ideal candidate will be responsible for developing software to extract critical data from websites such as Airbnb and other specified platforms or other websites, with a focus on daily booking occupancy rates and unit pricing. The extracted data should be efficiently organized and presented in Excel format.

Key Responsibilities:

Develop and maintain software to extract data from specified websites, particularly Airbnb.
Accurately retrieve information like daily booking occupancy and unit pricing.
Manage large datasets and organize extracted data in Excel for easy analysis and reporting.
Collaborate with the team to ensure the smooth integration of extracted data into our existing systems.
Keep up-to-date with the latest web crawling technologies and methodologies.
Implement strategies to prevent detection and blocking by target websites.
Maintain clear documentation and ensure the reliability and scalability of the crawling system.

Qualifications:

Proven experience in web crawling and data extraction.
Strong programming skills in languages such as Python, Java, or similar.
Proficiency in using web crawling frameworks like Scrapy, BeautifulSoup, or similar.
Expertise in Microsoft Excel for data organization, analysis, and reporting.
Understanding of web technologies (HTML, CSS, JavaScript, AJAX) and HTTP protocol.
Experience in handling and processing large datasets.
Excellent problem-solving skills and attention to detail.
Preferred Skills:

Experience with cloud services (AWS, Azure, GCP).
Familiarity with database technologies (SQL, NoSQL).
Knowledge of data analysis and visualization tools.

How to Apply:
Please submit your resume and a cover letter detailing your experience in web crawling and data extraction, and your proficiency in Excel. Include examples of past projects or contributions, if available.","{'"Data Scraping'",'"Data Extraction'",'"Web Crawling'",Scrapy}",United States,hc,"","",2024-02-23 17:37:50.646784,2024-02-23 17:37:50.646784
https://www.upwork.com/jobs/Web-scraping_~011b2d157139148519/?referrer_url_path=/nx/search/jobs/,Web scraping,2024-02-02 17:37:50.655136,"Scrape data from a website that I provide, get it into a spreadsheet","{'"Data Scraping'",'"Data Mining'",'"Data Extraction'",'"Web Crawling'",Scrapy}",United States,ct,"","",2024-02-23 17:37:50.657597,2024-02-23 17:37:50.657597
https://www.upwork.com/jobs/Reverse-Engineer-Long-term-partnership_~019d3f815b3b5fdcac/?referrer_url_path=/nx/search/jobs/,Reverse Engineer | Long-term partnership,2024-02-02 17:37:50.664877,"I need a developer who is into reverse engineering for a long-term partnership. I''ve got a few codes that I need to deploy, connect them together, and fix and/or improve.

Please only apply if you know what you''re doing, and I don''t care what language you use for this as long as it gets the job done!

Note:
The budget includes multiple projects that will come as milestones.","{Python,API,JavaScript,HTML,React,CSS,'"API Integration'",'"RESTful API'",'"Web Development'",Database,'"Database Architecture'",'"Database Design'",'"Database Maintenance'",'"Software Architecture & Design'",'"Web Service'",'"Business Logic Layer'",'"Data Access Layer'",'"Automated Deployment Pipeline'",'"Infrastructure as Code'",'"PHP Script'",'"Python Script'",'"Requirements Specification'",Java,Kotlin,Scala,PHP,Ruby,SQL,TypeScript,C#,C++,Elixir,'"Apache Groovy'",ASP,Clojure,'"D Language'",Dart,Delphi,Erlang,F#,'"Fluid Hyper Text Markup Language'",Golang,GraphQL,Haxe,JADE,Objective-J,Perl,Rust,Transact-SQL,'"Visual Basic'",XQuery,'"Google Analytics'",'".NET Framework'",ASP.NET,'"ASP.NET MVC'",Git,HTTP,'"Jakarta Server Faces'",'"Jakarta Server Pages'",Scrapy,'"Amazon Web Services'",'".NET Compact Framework'",Act.Framework,Django,JUnit,Micronaut,SaaS,'"Spring Framework'",'"Apache Spark'",Dagger,NUnit,pandas,PyTorch,'"Python Scikit-Learn'",TensorFlow,'"ADF Faces'",ADO.NET,Agavi,Akka,Ansible,'"Apache Airflow'",'"Apache Axis'",'"Apache Camel'",'"Apache Cayenne'",'"Apache Click'",'"Apache Cocoon'",'"Apache Commons'",'"Apache CXF'",'"Apache Empire DB'",'"Apache FreeMarker'",'"Apache Jackrabbit'",'"Apache Jena'",'"Apache Log4j'",'"Apache Lucene'",'"Apache Maven'",'"Apache PDFBox'",'"Apache POI'",'"Apache Shiro'",'"Apache Sling'",'"Apache Struts'",'"Apache Struts 2'",'"Apache Subversion'",'"Apache Tapestry'",'"Apache Tiles'",'"Apache Turbine'",'"Apache Velocity'",'"Apache Wicket'",'"Apache Xerces'",AppFuse,Arrow,'"ASP.NET Core'",AspectJ,'"Atlassian Bamboo'",'"AWS Amplify'",Axon,'"Azure DevOps'",Barracuda,'"Big Faceless'",BioJava,Bitbucket,BlueBream,'"Bottle Web Framework'",Caffe,CakePHP,CherryPy,CircleCI,'"Content Management System'",Codefresh,CodeIgniter,Codeship,CogCompNLP,'"Apache Commons Logging'",Crawler4j,'"CUBA Platform'",CubicWeb,'"Concurrent Versions System'",Dash,'"Direct Web Remoting'",Docker,Dropwizard,Drupal,'"Easy Rules'",Deeplearning4j,'"Eclipse Jersey'",EclipseLink,Ehcache,EJB,EJML,ELI5,'"Entity Framework'",Facebook4J,'"Fat-Free Framework'",FlashText,Flask,'"Neos Flow'",FuelPHP,Gaelyk,Genshi,GeoAPI,GitLab,GoCD,'"Google Gson'",'"Google Guava'",'"Google Guice'",'"Google Web Toolkit'",Gradle,Grails,'"Grok Framework'",gServ,'"Gyroscope Framework'",Hanami,Hibernate,HK2,http4s,iBATIS,imbalanced-learn,Infinispan,IPython,iText,Jackcess,Jackson,JasperReports,'"Java Collections Framework'",'"Java Media Framework'",'"Java RMI'",'"Java Servlet API'",Javassist,'"JBoss Seam'",jcabi,JDBC,JDOM,Jenkins,'"JetBrains TeamCity'",'"JIDE Software'",Jinja2,jMock,Joda-Time,Jodd,Joomla,'"Java Persistence API'",JSTL,Kajona,Keras,Kubernetes,Logback,Laravel,Li3,Lift,LightGBM,Luminoth,Mako,MapDB,'"Couchbase Server'"}",United States,a,"","",2024-02-23 17:37:50.675503,2024-02-23 17:37:50.675503
https://www.upwork.com/jobs/Scraper_~01141082fb83fa794d/?referrer_url_path=/nx/search/jobs/,Scraper ,2024-02-02 14:27:44,"Scraping app for google busniess profile

I want to scrape all the details on each listing plus I want to devide it to claimed/verified unclaimed/unverified listing
But there is an issue we need to over come

To be able to scrape all the googles map listing I have a video that can describe the issue and how to over come it

https://youtu.be/op9MabaZNZo?si=Vrpx7y1egEFdk2T7

I''m pretty sure there are some of you already developed such tool so hope to find one ready 

","{'"Web Scraping'",'"Screen Scraping'",PHP,'"Data Scraping'",'"Data Mining'",Python,Scrapy,'"Web Crawling'",Scripting,'"Data Extraction'"}",Saudi Arabia,a,"","",2024-02-23 17:37:50.687594,2024-02-23 17:37:50.687594
https://www.upwork.com/jobs/Web-Scraping_~01efca0d9557ce24d5/?referrer_url_path=/nx/search/jobs/,Web Scraping,2024-02-02 14:26:38,"We need someone to perform web scraping on several websites to obtain all possible user phone numbers and email addresses.

The data collected must be compiled into a single spreadsheet with a column for phone numbers and a column for email addresses.

The target candidate will use scripting for this to automate the process, instead of doing it manually.

The target websites are:
sailboatlistings.com
sailboatsforsale.com
boattrader.com","{'"Lead Generation'",'"List Building'",'"Online Research'",'"Data Scraping'",'"Data Mining'",Scrapy,'"Web Crawling'",'"Data Extraction'",'"Data Entry'",'"Web Scraping'"}",United States,$5.00-$7.00,"","",2024-02-23 17:37:50.695954,2024-02-23 17:37:50.695954
https://www.upwork.com/jobs/Puppeteer-scraping_~0151c37facfd023e1a/?referrer_url_path=/nx/search/jobs/,Puppeteer scraping,2024-02-02 17:37:50.702152,"I have a puppeteer script that is scraping plugshare.com, Just need to edit it with a for loop to go through all the US locations, and run the script over a few days to get all the data.
Are you able to run it against all the places in the USA and put them in the mongo database ?","{Node.js,'"Data Scraping'",Scrapy,'"Web Crawling'",Selenium,JavaScript}",Rwanda,a,"","",2024-02-23 17:37:50.70377,2024-02-23 17:37:50.70377
https://www.upwork.com/jobs/LinkedIn-API-Python-web-scraping-expert_~01cc83ef0cff5e5cd9/?referrer_url_path=/nx/search/jobs/,LinkedIn API / Python web scraping expert,2024-02-01 23:45:46,Looking for a LinkedIn API / Python web scraping expert. This is a simple application to extract public posts made by accounts on LinkedIn. This is a small scale application to automate monitoring of a small list of accounts on LinkedIn. If this can be achieved using LinkedIn API that would be ideal. Otherwise I am open to other solutions and ideas. ,"{'"Web Scraping'",'"Data Scraping'",'"Data Mining'",'"Data Entry'",Python,'"Data Extraction'",'"Lead Generation'",'"List Building'",'"Microsoft Excel'",'"Prospect List'",Automation,Selenium,JavaScript,'"Web Crawling'",Scrapy}",United States,a,"","",2024-02-23 17:37:50.712433,2024-02-23 17:37:50.712433
https://www.upwork.com/jobs/Automation-Scraper-needed-for-woocommerce-website-data-scraping_~01ba3a6a639ae817fa/?referrer_url_path=/nx/search/jobs/,Automation / Scraper needed for woocommerce website data scraping,2024-02-01 21:23:22,"Hi there,

I need an automation / scraper professional for a website which contains a lot of productdata. I need it into csv or google sheet.

Project requirements;
1. Scraper should get all product data within max 1 hour
2. Maintenance for 3 months (if it brokes, you will fix it)
3. If the scraper doesnt need proxies, you will have a bonus.

Please do not message me if you haven''r prior experience in automation / scraping.

Thanks in advance.

Note: if you deliver high quality, I have a lot more projects for you longterm.","{'"Data Scraping'",Python,'"Data Mining'",Scrapy,Selenium,'"Data Extraction'",PHP,JavaScript,Automation}",Netherlands,a,"","",2024-02-23 17:37:50.720507,2024-02-23 17:37:50.720507
https://www.upwork.com/jobs/ILO-Survey-Digital-Platform-Work-Latin-America-available-English-espa-amp-portugu_~018d8cced2b3961113/?referrer_url_path=/nx/search/jobs/,"ILO Survey of Digital Platform Work in Latin America (available in English, español, &amp; português)",2024-02-01 17:54:54,"Esta tarea está disponible en inglés, español y portugués. Vea abajo el texto en otros idiomas.
Esta tarefa está disponível em inglês, espanhol e português. Veja abaixo o texto em outros idiomas. 

Español:
¿Eres un freelancer que vive en América Latina? ¿Encuentras trabajos en plataformas de trabajo colectivo? ¡Queremos saber de ti! Estamos estudiando por qué las personas eligen el trabajo independiente, cómo es y los patrones de estos empleos. ¡Damos la bienvenida a freelancers de todos los campos!
Somos un equipo de ciencias sociales con sede en Ann Arbor, Michigan, EE.UU., trabajando con la Organización Internacional del Trabajo (parte de las Naciones Unidas). La OIT quiere comprender mejor la vida laboral de los freelancers en América Latina y el Caribe.

Buscamos a varias personas que actualmente trabajan en plataformas de crowdwork (como Upwork) para completar la encuesta. Si deseas completar la encuesta, por favor responde y te proporcionaremos acceso a la misma. Solo te pedimos que una vez que completes la encuesta, copies un código que se te proporcionará de vuelta en esta tarea para que podamos aprobar el pago.

La mayoría de las personas que completan esta tarea lo encuentran un cambio agradable y refrescante al participar en un estudio tan importante.

Para calificar para el estudio, debes reconocer un formulario de consentimiento informado, ser mayor de 18 años, haber completado algún trabajo de freelance en línea, crowdwork, programación competitiva, o trabajo de competencia libre en una plataforma en línea. También debes vivir actualmente en Centroamérica, Sudamérica o en el Caribe.

¿Interesado? Esto es lo que necesitas saber:
Tiempo: La encuesta toma alrededor de 30 minutos.

Pago: Completa la encuesta y ganarás $7 USD. Solo asegúrate de prestarle toda tu atención y responder honestamente. Solo aceptamos una encuesta por persona. Las respuestas que muestren evidencia de falta de atención o deshonestidad serán excluidas.

Importante: Una vez que hayas terminado, envíanos un código que recibirás al final de la encuesta. Esto es necesario para recibir tu pago. 


Português:
Você é um freelancer que vive na América Latina? Você encontra trabalhos em plataformas de crowdwork? Queremos ouvir você! Estamos estudando por que as pessoas escolhem o trabalho freelance, como é e os padrões desses trabalhos. Freelancers de todas as áreas são bem-vindos!
Somos uma equipe de ciências sociais baseada em Ann Arbor, Michigan, EUA, trabalhando com a Organização Internacional do Trabalho (parte das Nações Unidas). A OIT está buscando entender melhor a vida de trabalho dos freelancers na América Latina e no Caribe.

Estamos procurando várias pessoas que atualmente trabalham em plataformas de crowdwork (como Upwork) para completar a pesquisa. Se você deseja completar a pesquisa, por favor responda e nós lhe proporcionaremos acesso à pesquisa. Apenas pedimos que, uma vez que você complete a pesquisa, copie um código que será fornecido de volta para esta tarefa para que possamos aprovar o pagamento.

A maioria das pessoas que completam esta tarefa acha uma mudança agradável e revigorante participar de um estudo tão importante.

Para se qualificar para o estudo, você deve reconhecer um formulário de consentimento informado, ter 18 anos ou mais, ter completado algum trabalho freelance online, crowdwork, programação competitiva ou trabalho de competição livre em uma plataforma online. Você também deve morar atualmente na América Central, América do Sul ou no Caribe.

Interessado? Aqui está o que você precisa saber:
Tempo: A pesquisa leva cerca de 30 minutos.

Pagamento: Complete a pesquisa e você ganhará $7 USD. Apenas certifique-se de dar sua total atenção e responder honestamente. Aceitamos apenas uma pesquisa por pessoa. Respostas que mostrarem evidências de falta de atenção ou desonestidade serão excluídas.

Importante: Quando terminar, envie-nos um código que você receberá no final da pesquisa. Isso é necessário para receber seu pagamento. 
","{API,Database,'"Database Architecture'",'"Database Maintenance'",'"Web Service'",'"Software Architecture & Design'",'"Database Design'",'"API Integration'",'"Automated Deployment Pipeline'",'"Python Script'",'"PHP Script'",'"API Development'",'"Data Access Layer'",'"Business Logic Layer'",'"RESTful API'",'"Back-End Development'",'"Infrastructure as Code'",'"Requirements Specification'",'"REST API'",'"SOAP API'",Java,Kotlin,Scala,PHP,Ruby,SQL,TypeScript,Python,C#,C++,Elixir,'"Apache Groovy'",ASP,Clojure,'"Google Analytics'",'".NET Framework'",ASP.NET,'"ASP.NET MVC'",Git,HTTP,Scrapy,Django,'"Amazon Web Services'",Micronaut,'"Apache HTTP Server'",'"Oracle WebLogic Server'",Cloudflare,SQLite,'"Realm Database'",MongoDB}",United States,a,"","",2024-02-23 17:37:50.730408,2024-02-23 17:37:50.730408
https://www.upwork.com/jobs/Tradingview-pinescript_~0198cc0f13fbec10a7/?referrer_url_path=/nx/search/jobs/,Tradingview pinescript,2024-01-30 11:50:21,I need small code for vertical( base on time frame )  and horizontal lines (  base on time frame ) etc,"{'"Data Entry'",SQL,Python,'"Microsoft Excel'",'"Data Scraping'",'"Data Mining'",Selenium,Scrapy,Automation,API,'"Web Crawling'",'"Web Scraping'",Scripting,'"Bot Development'",Python-Requests}",India,a,"","",2024-02-23 17:37:52.920267,2024-02-23 17:37:52.920267
https://www.upwork.com/jobs/Web-Scraping-Expert_~01fcb041375aeef805/?referrer_url_path=/nx/search/jobs/,Web Scraping Expert,2024-02-01 20:33:12,"
🚀 Join Our Team as a Long-term Web Scraping Developer 🚀

Are you a skilled Web Scraping Developer with expertise in Docker, Scrapy, Celery, RabbitMQ, APIs, CAPTCHA solving, mobile app scraping, proxy management, server administration, and CI/CD?

Key Details:

Position: Web Scraping Developer
Responsibilities: Develop, modify, and maintain scraping projects, integrate APIs, overcome CAPTCHA challenges, manage proxies, and implement CI/CD.
Requirements: Strong proficiency in mentioned technologies, proven experience in web scraping, adaptability, and effective communication.
Benefits:

Competitive salary with Upwork.
Career growth opportunities
Innovative work environment

How to Apply:
Send your resume and cover letter on Upwork. Include links to your portfolio or GitHub.","{'"API Integration'",'"Data Scraping'",Python,'"Data Mining'",Scrapy,JavaScript,'"Data Entry'",'"Data Extraction'",'"Microsoft Excel'",'"ETL Pipeline'",'"Web Crawling'",Docker,CI/CD,Celery,Selenium,'"Selenium WebDriver'",ETL,'"Data Migration'",'"AWS CodePipeline'",'"AWS CodeDeploy'"}",United States,a,"","",2024-02-23 17:37:50.74105,2024-02-23 17:37:50.74105
https://www.upwork.com/jobs/Website-Scraping_~01ce70033667841de9/?referrer_url_path=/nx/search/jobs/,Website Scraping,2024-02-01 17:23:53,"Scrape multiple websites for emails. They are all set up in different ways, so you have to crawl through the websites in depth to get to all the emails. They are often divided into subpages, they are not all on one page as there are a lot. Some pages also need to go into the individual agent page to get the info.
I need the following:
Name / Email / Phone","{'"Data Scraping'",'"Data Mining'",Scrapy,Python,'"Web Crawling'"}",United States,g$,"","",2024-02-23 17:37:50.756686,2024-02-23 17:37:50.756686
https://www.upwork.com/jobs/Expert-Needed-for-Using-NLM-with-OCR-extract-from-assorted-types-PDF_~0125e04128b62426a0/?referrer_url_path=/nx/search/jobs/,Expert Needed for Using AI / ML / NLM with OCR to extract from assorted types of PDF ,2024-02-02 17:37:50.76281,"I am looking for someone to fix existing code script I have

This script uses currently pytesseract records from each county of lead types (death certificates, probate, lis pendans, foreclosure auctions) 

It extracts very poorly the data. 

Need to implement OCR module based on AI and ML model and ML algorithms.

Must be experienced in Python and its Libraries for scraping, also need good knowledge of OCR AI MLM for  reading and recognizing certain fields in different quality PDF file Such As Name and Address. Some pdf''s are scanned, and several have watermarks on them.

","{'"Web Scraping'",'"Web Crawling'",'"Screen Scraping'",'"Data Scraping'",Python,'"Data Mining'",'"Data Extraction'",Scrapy,'"Data Entry'",'"OCR Algorithm'",'"OCR Software'",'"Tesseract OCR'",'"Python Numpy FastAI'"}",United States,a,"","",2024-02-23 17:37:50.76487,2024-02-23 17:37:50.76487
https://www.upwork.com/jobs/Web-Scraping-and-PDF-Data-Extraction-Specialist_~0182b0ebd8cb017b31/?referrer_url_path=/nx/search/jobs/,Web Scraping and PDF Data Extraction Specialist,2024-02-01 10:59:37,"We are seeking a skilled and reliable professional to assist us in automating the process of downloading PDF files from a specific website, extracting data from these PDFs, and generating Excel files for further analysis. This project requires expertise in web scraping, PDF data extraction, and Excel automation.

Responsibilities: 
1.⁠ ⁠*Web Scraping:*   - Develop a script or tool to automate the download of PDF files from a specified website.   - Ensure the scraping process is efficient, reliable, and adheres to ethical practices. 

2.⁠ ⁠*PDF Data Extraction:*   - Implement a solution to extract relevant data from the downloaded PDF files.   - Handle variations in PDF formats and structures to ensure accurate data extraction. 

3.⁠ ⁠*Data Cleaning and Transformation:*   - Cleanse and transform the extracted data to ensure consistency and accuracy.   - Handle any inconsistencies or anomalies in the PDF data. 

4.⁠ ⁠*Excel Generation:*   - Generate Excel files containing the extracted data in a structured format.   - Ensure that the Excel files are user-friendly and ready for analysis. 

5.⁠ ⁠*Automation and Scheduling:*   - Develop a system for scheduled automation to keep the data up-to-date.   - Implement error handling mechanisms to address any issues during the automation process.

Requirements:
•⁠  ⁠Proven experience in web scraping and data extraction from PDF files.
•⁠  ⁠Proficiency in programming languages such as Python, Java, or similar for automation tasks.
•⁠  ⁠Strong knowledge of PDF parsing libraries and tools.
•⁠  ⁠Experience in generating structured Excel files.
•⁠  ⁠Attention to detail to handle variations in PDF structures.
•⁠  ⁠Excellent problem-solving skills to address challenges in the data extraction process.","{'"Web Crawling'",'"Web Scraping'",'"Screen Scraping'",Selenium,'"Beautiful Soup'",'"Data Scraping'",'"Data Extraction'",Scrapy,'"Data Entry'",Python}",United States,hc,"","",2024-02-23 17:37:50.773109,2024-02-23 17:37:50.773109
https://www.upwork.com/jobs/Canada-Census-Data-Scrape_~0137561c5c3263f788/?referrer_url_path=/nx/search/jobs/,Canada Census Data Scrape,2024-02-02 17:37:50.779955,"I need someone to download as a CSV/Excel all the values where the DISSEMINATION AREA ID starts with &quot;59&quot;. Only apply if you can complete the task in a day or less. Thank you!

https://www150.statcan.gc.ca/t1/tbl1/en/cv.action?pid=9810012901","{'"Data Scraping'",'"Data Mining'",'"Data Extraction'",Scrapy}",United States,a,"","",2024-02-23 17:37:50.781809,2024-02-23 17:37:50.781809
https://www.upwork.com/jobs/Python-and-Pandas-Developer-API-developer_~016f86dc175b70adb4/?referrer_url_path=/nx/search/jobs/,"Python and Pandas Developer, API developer",2024-02-01 05:37:43,"**Executive Summary**

This Statement of Work (SoW) delineates the comprehensive plan for the development and deployment of a product-focused Master Data Management (MDM) application tailored for H4H. The application aims to streamline and automate the Extract, Transform, Load (ETL) processes using the pandas library, enhancing the efficiency and accuracy of data management within the organization. Built upon a robust technology stack comprising Flask, HTML, CSS, and a suite of Python libraries, the solution will be backed by a MySQL database to ensure secure and scalable data storage.

The core objective of this initiative is to facilitate a seamless supplier onboarding process, enabling H4H to efficiently integrate new suppliers into their ecosystem. By automating inventory and price monitoring, the application will provide real-time insights into stock levels and pricing dynamics, thus optimizing inventory management and pricing strategies. Furthermore, the implementation of intelligent product recommendations will leverage advanced analytics to enhance cross-selling and up-selling opportunities, driving revenue growth and improving customer satisfaction.

To ensure the seamless integration of data across diverse systems, the application will employ a RESTful API, which will facilitate the uploading of data into the company’s store using an ODBC driver. This approach guarantees a flexible and interoperable data exchange framework, enabling H4H to adapt quickly to changing business needs and technology landscapes.

The development of this MDM application represents a strategic investment in H4H’s digital infrastructure, aiming to achieve operational excellence and competitive advantage. By automating critical data management processes and providing actionable insights through advanced analytics, H4H will be well-positioned to respond dynamically to market trends, streamline supplier integration, and deliver enhanced value to its customers.","{'"Data Processing'",'"Data Cleaning'",'"Data Segmentation'",Python,'"RESTful API'",ETL,pandas,Scrapy,MySQL,Elasticsearch,API,BigCommerce}",United States,$7.00,"","",2024-02-23 17:37:50.790782,2024-02-23 17:37:50.790782
https://www.upwork.com/jobs/Linkedin-exprianced-scraper_~01ea283803b4c0ef20/?referrer_url_path=/nx/search/jobs/,Linkedin exprianced scraper,2024-01-31 21:48:13,"Total Profiles to Scrape: 300,000 LinkedIn profiles, divided into two segments.

Segment One: 150,000 Chief Technology Officers (CTOs) from technology companies with a workforce ranging between 10 to 500 employees.
Segment Two: 150,000 Directors of Operations and Directors of Project Management from companies employing between 10 to 50 individuals.
Data Fields Required:

- First Name
- Last Name
- Email Address
- Phone Number
- Current Company
- Current Position
- Number of Employees in the Current Company","{'"Data Scraping'",'"Data Mining'",Python,'"Lead Generation'",Scrapy,LinkedIn,'"LinkedIn Development'",Python-Goose}",Bulgaria,a,"","",2024-02-23 17:37:50.800292,2024-02-23 17:37:50.800292
https://www.upwork.com/jobs/Stubhub-Ticket-Listing-Scraping-Module_~01f9212c32b3d54b4a/?referrer_url_path=/nx/search/jobs/,Stubhub Ticket Listing Scraping Module,2024-02-02 17:37:50.807913,"
Request for Proposal (RFP) - StubHub Ticket Listing Scraping Service
1. Introduction
We are seeking proposals from experienced web scraping service providers to develop a solution that scrapes ticket listings from StubHub for specific events using provided Event IDs. The objective of this project is to retrieve ticket listings in JSON format and ensure the process can be completed in under 2 seconds for events with listings under 600.

2. Scope of Work
The selected vendor will be responsible for developing a web scraping solution that can perform the following tasks:

2.1 Data Extraction
Receive an Event ID as input.
Use the Event ID to access the StubHub website and extract ticket listings for that specific event.
Retrieve essential ticket listing details including seat information, ticket prices, and availability.
	
Transform the extracted data into a structured JSON format.
** See extracted example of 1 ticket Attached**

2.2 Performance Requirements
The scraping process should be completed in under 2 seconds for events with up to 600 listings.
The solution should be able to handle multiple Event IDs in a repeated fashion, using provided proxy details for each request.
2.3 Proxy Support
The solution should accept proxy details in the following format:
Proxy IP:Port
User:Pass

3. Proposal Submission
Interested parties should submit their proposals via email to [Your Contact Email] no later than [Submission Deadline]. The proposal should include the following:

A detailed description of the proposed solution, including the technologies and tools that will be used.
A breakdown of the proposed timeline for development and testing.
Information on the scalability and reliability of the proposed solution.
Pricing details, including any ongoing maintenance or support costs.
A list of relevant references or prior experience in web scraping projects.

4. Evaluation Criteria
Proposals will be evaluated based on the following criteria:

Technical feasibility and capability to meet performance requirements.
Experience and expertise in web scraping projects.
Proposed timeline and project management approach.
Cost-effectiveness and pricing structure.
Quality of references or prior work.

5. Confidentiality
All information provided in response to this RFP is considered confidential and should not be disclosed to any third parties.


6. Ownership
Ownership of the source code will belong to our firm, you will not contain the rights to it.

*** IMMEDIATE START ***
","{C#,Python,SQL,JavaScript,'"Beautiful Soup'",Scrapy,'"Data Extraction'",'"Web Scraping'",'"Data Scraping'"}",United States,a,"","",2024-02-23 17:37:50.81005,2024-02-23 17:37:50.81005
https://www.upwork.com/jobs/Lead-Generation_~017e7aead6949a7b82/?referrer_url_path=/nx/search/jobs/,Lead Generation,2024-02-02 17:37:50.817723,I need 6K leads for the week of Canadian business owners that have a company earning $500K to $100M. I need them to have phone numbers. ,"{'"Web Scraping'",'"Lead Generation'",'"Lead Capture'",'"Email Marketing'",'"LinkedIn Lead Generation'",'"Data Mining'",'"Data Scraping'",'"Data Extraction'",Scrapy,'"Screen Scraping'",'"Web Crawler'",'"Web Scraping Software'",Python,'"Data Entry'",'"List Building'"}",Canada,a,"","",2024-02-23 17:37:50.8199,2024-02-23 17:37:50.8199
https://www.upwork.com/jobs/Social-media-scraping_~010d0b472d43e0c1d9/?referrer_url_path=/nx/search/jobs/,Social media scraping,2024-01-31 17:21:42," I want you to do web scraping on the LinkedIn, Instagram and Facebook. My intention is that we want to collect user’s behavior, what do users like on Fb, how they behave on Linkedln.
Please apply if you know how to do it.","{'"Web Crawling'",'"Screen Scraping'",'"Web Scraping'",'"Beautiful Soup'",Scrapy,Python-Requests,'"Data Scraping'",'"Social Media Marketing'",Python,'"Data Mining'"}",Pakistan,$5.00,"","",2024-02-23 17:37:50.828172,2024-02-23 17:37:50.828172
https://www.upwork.com/jobs/Syst-automatis-pour-identifier-surveiller-des-noms-domaines-expir_~018b5134c756e0b3d9/?referrer_url_path=/nx/search/jobs/,Système automatisé pour identifier et surveiller des noms de domaines expirés.,2024-01-31 16:50:13,"Description du Projet :

Le cœur du projet consiste à utiliser une interface web et nous référencons les noms de domaines expirés que nous souhaitons acheté, pour cela il faudra utiliser une API WHOIS pour rechercher des noms de domaines expirés et vérifier leurs dates d''expiration &quot;pendingdeleted&quot; ajouter à ça 30jours de temps de rédemption. Une fois qu''un domaine arrive à expiration, le système doit immédiatement vérifier sa disponibilité pour achat. Cette vérification doit être extrêmement rapide, se produisant à intervalles de secondes ou même de millisecondes.

Fonctionnalités Clés :

- Interface web où on peut rajouter les domaines, avec les informations du domaine date expiration, date disponbilité
- Recherche Automatisée de Domaines Expirés : Utilisation d''une API WHOIS pour identifier les domaines dont la date d''expiration est proche.
- Surveillance en Temps Réel : Dès qu''un domaine expire, le système doit vérifier sa disponibilité pour achat presque instantanément.
- Intégration avec les Registars : Le système doit pouvoir interagir avec les APIs de registars populaires, tels qu''OVH ou GoDaddy, pour vérifier la disponibilité et potentiellement initier l''achat de domaines.","{Scrapy,JavaScript,React,Python,'"Front-End Development'",'"Web Scraping'",Scripting,Django,'"RESTful API'",API,'"Python Script'",Selenium,'"Back-End Development'"}",France,a,"","",2024-02-23 17:37:50.838602,2024-02-23 17:37:50.838602
https://www.upwork.com/jobs/Professional-scraping-system-for-websites_~01fc99261f3ff2c4e7/?referrer_url_path=/nx/search/jobs/,Professional scraping system for 5 websites,2024-02-02 17:37:50.845695,"I have a list of 5 websites that I need to make a scraping system for them and make integrations for this scraping system with my database, so the requirements are the following :
- scraping using scrapy and selenium.
- data integration to the database.

","{'"API Integration'",Dashboard,Automation,'"Business Process Automation'",'"Data Extraction'",Selenium,Python,'"Data Scraping'",'"Data Mining'",Scrapy}",Egypt,a,"","",2024-02-23 17:37:50.848301,2024-02-23 17:37:50.848301
https://www.upwork.com/jobs/Consolidate-conference-attendees-list_~01e3759e1a0c7d45f0/?referrer_url_path=/nx/search/jobs/,Consolidate conference attendees list,2024-01-31 14:02:57,"I have a quick project if you have time

- I registered to this business event: https://www.worldaicannes.com/en/attendees

- Goal would be for me to understand who in my network is going to this event. I would compare attendees to my linkedin network

-What I need: csv file with all participants, and their details (first name, last name, position, company, link, seniority, industry, company size). Python script/ notebook to do so
- I was thinking of using Beautifulsoup for example
- I would do the matching with my linkedin myself

What would be the all inclusive price for this project? 

You can register yourself for free and check the attendees page layout and evaluate authentification","{Python,'"Beautiful Soup'",'"Data Extraction'",Selenium,Scrapy,'"Data Scraping'"}",France,a,"","",2024-02-23 17:37:50.855725,2024-02-23 17:37:50.855725
https://www.upwork.com/jobs/Noon-amp-Amazon-Scrapper_~01c182e718183b6bc8/?referrer_url_path=/nx/search/jobs/,Noon &amp; Amazon Scrapper,2024-01-31 13:45:54,"Contract title
Web scrapper for Noon and Amazon
Add a description of the work
I need a new scrapper to built which can scrape data from Noon and Amazon as per my content listing template. So that i can list products of Noon and Amazon on our website. Attaching the file for all categories for your reference.","{'"Data Scraping'",'"Data Entry'",'"Data Mining'",Scrapy}",United Arab Emirates,a,"","",2024-02-23 17:37:50.863079,2024-02-23 17:37:50.863079
https://www.upwork.com/jobs/Python-Web-Scraping-Project_~0164eeace239e3dcb0/?referrer_url_path=/nx/search/jobs/,Python Web Scraping Project,2024-01-29 16:08:15,"Client needs ongoing web scraping development. 

The first project will be updating an existing Scrapy Spider that has recently started to get blocked by CloudFlare resulting in 403 responses. Cloudscraper and scrapy-selenium have been unsuccessful at solving the problem.

If this project is successful there will be more work in the future adding new spiders to the system.

Additional details will be provided to interested candidates. ","{Scrapy,'"Web Scraping'",Selenium,'"Data Scraping'",Python}",United States,a,"","",2024-02-23 17:37:52.995115,2024-02-23 17:37:52.995115
https://www.upwork.com/jobs/Python-Data-scrapper_~01519e89d31620829f/?referrer_url_path=/nx/search/jobs/,Python Data scrapper,2024-01-31 13:03:12,"Scrape the reviews of one of the following websites in Python. 
Share your codes in GitHub and send the URL of the source code.
In addition, please add an instruction on how to run your code.
Good luck.


The URLs: 
Option A:
https://www.lazada.co.id/products/celana-cargo-wanita-highwaist-bonnie-cargo-pants-celana-kargo-wanita-i7706390243-s14174328153.html?spm=a2o4j.product-not-exist-m.just4u.1.4c9c268dTctOlL&amp;&amp;search=error&amp;clickTrackInfo=d4d4a5eb-e0bc-48e3-83a0-a479dfd90636__7706390243__6567__hot__327975__0.0__0.2202121913433075__0.34739277__0.0__0.004694291__0.8888394832611084__0________0.0________95000.0__0.5947368421052632__4.581538461538462__650__38500.0__127620%2C255084%2C255127%2C255313%2C328068%2C333604%2C350221%2C350829%2C357502%2C366991%2C380123%2C381309%2C522897%2C524869%2C524875%2C525007%2C525880________3650.16539_955.3631_4560.21196____32745____0.22395138__0.0____________0.0__0.0__0.0

OR

Option B:
https://www.amazon.com/Samsung-27-inch-Business-C27F390FHN-LED-Lit/product-reviews/B01IPHVFUI/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&amp;reviewerType=all_reviews&amp;sortBy=recent&amp;formatType=current_format


Scrape all the reviews with all a. Required fields:
Review Body
Review start rating 
Author
Post Date","{Python,Scrapy,'"Web Crawling'",'"Data Scraping'"}",Mongolia,$5.00-$6.00,"","",2024-02-23 17:37:50.871636,2024-02-23 17:37:50.871636
https://www.upwork.com/jobs/Web-scrapper-for-Noon-and-Amazon_~014918afa23a722849/?referrer_url_path=/nx/search/jobs/,Web scrapper for Noon and Amazon,2024-01-31 13:31:37,"I need a new scrapper to built which can scrape data from Noon and Amazon as per my content listing template. So that i can list products of Noon and Amazon on our website.

Attaching the file for all categories for your reference.","{'"Microsoft Excel'",'"Microsoft Word'",'"Data Entry'",'"Data Mining'",'"Data Scraping'",'"Market Research'",'"Topic Research'",'"Virtual Assistance'",'"Data Collection'",'"Web Crawling'",Scrapy,'"Prospect List'",'"List Building'"}",United Arab Emirates,a,"","",2024-02-23 17:37:50.879778,2024-02-23 17:37:50.879778
https://www.upwork.com/jobs/Scraping-Expert_~01aa507f6fb88aaf91/?referrer_url_path=/nx/search/jobs/,Scraping Expert,2024-01-31 13:13:15,"Hi, we are a US based firm and looking for an expert in Data Scraping. Its a short-term opportunity but the contract may be extended to long term opportunity. The person will be required to scrap data and is able to customize the data scraping tool according to our needs.

Job Requirements
2+ years of experience with scraping
Amazing communication skills
A good command of the English language
An ability to keep deadlines
You must be highly motivated

Below are the skills that are preferred but not required: 
Any level of skill in Laravel
","{'"Data Scraping'",Python,'"Data Mining'",'"Data Extraction'",Scrapy,Laravel}",Pakistan,$3.00-$5.00,"","",2024-02-23 17:37:50.887226,2024-02-23 17:37:50.887226
https://www.upwork.com/jobs/Data-Scrapping_~01c6d3932196d289ee/?referrer_url_path=/nx/search/jobs/,Data Scrapping,2024-01-31 08:47:57,Need to extract data from webpages. Need to organise the same in CSV files.,"{Scrapy,'"Web Scraping'",Python,Selenium,'"Data Scraping'",'"Data Extraction'",'"Web Crawling'",Automation,API,Django,'"Web Scraping Software'",'"Data Mining'",'"Web Development'",'"API Development'",'"Scraper Site'"}",India,a,"","",2024-02-23 17:37:50.895527,2024-02-23 17:37:50.895527
https://www.upwork.com/jobs/Data-Scraping_~0145331ff3daa0da8e/?referrer_url_path=/nx/search/jobs/,Data Scraping,2024-01-31 08:46:11,Need to extract data from webpages. Need to organise the same in CSV files.,"{'"Data Extraction'",Python,'"Data Scraping'",Scrapy}",India,$4.00-$10.00,"","",2024-02-23 17:37:50.904489,2024-02-23 17:37:50.904489
https://www.upwork.com/jobs/Web-Scraping-Expert-needed-build-reliable-scraper-collect-data-from-complex-site_~018f28c3022431fe85/?referrer_url_path=/nx/search/jobs/,Web Scraping Expert needed to build a reliable scraper to collect data from complex site,2024-02-02 17:37:50.912419,"IMPORTANT!! - If you send an AI generated response and do not read and follow all instructions in this posting, your proposal will not be considered. 

We need a stable scraper built to scrape a complex e-commerce website with a few million items listed for sale. This scraper will need to run 24 hours per day and continuously update the database. It will need to crawl deep into menus and gather data from individual product pages.

The scraper will need to be deployed to Digital Ocean and write data to a Postgres Database within a Supabase install. Other than where it is going to be hosted and the database type, we do not have any preference at all on the rest of the stack used to scrape the data.

The final deliverable will need to be a fully functional scraper capable of writing the data into our database following the pre defined schema. Some sort of front end for monitoring and restarting is a requirement as well. This needs to be a production ready scraper.  ","{'"Web Scraping'",'"Beautiful Soup'",'"Selenium WebDriver'",pandas,'"Data Scraping'",Scrapy,'"Data Mining'",Python,'"Data Extraction'",'"Web Crawling'"}",United States,a,"","",2024-02-23 17:37:50.914563,2024-02-23 17:37:50.914563
https://www.upwork.com/jobs/Scrape-Jackson-County-Treasurer-site-build-Spreadsheet_~01fa45c675f65b0a56/?referrer_url_path=/nx/search/jobs/,Scrape Jackson County Treasurer site build Spreadsheet,2024-02-02 17:37:50.921347,"Ok, this would be the first of many.  I am a real estate investor that focuses on buying properties off market.  There are variables that we search for that are generally easily extracted off the tax roll, and compiled with some other data points, code violations, etc, and linked to a google earth allows us to specifically target market deals.  

All Data is found on the tax roll, the tax roll should be extracted by cells,
All liens, or judgements are found on the recorders office
Owed back taxes, can also be found on tax roll or treasury
This would be extracting all the pertinent data off the tax roll and then cross referencing with taxes, liens, judgements and code violations, then linking it to the Google Earth Link.  ","{'"Data Scraping'",'"Data Mining'",'"Microsoft Excel'",'"Spreadsheet Software'",'"Data Entry'",Scrapy,'"Data Extraction'"}",United States,$50.00-$75.00,"","",2024-02-23 17:37:50.92346,2024-02-23 17:37:50.92346
https://www.upwork.com/jobs/Comprehensive-Job-Site-Data-Scraping_~013e84222c7272dca6/?referrer_url_path=/nx/search/jobs/,Comprehensive Job Site Data Scraping,2024-01-30 20:34:30,"One time scrape from the following websites:

Scrape from:
1. LinkedIn.com
2. Talent.com
3. Ziprecruiter.com
4. Indeed.com
*Minimum 500 from each.

Project Requirements – minimum 2,000 leads. Ideally 5k to 10k

Job Search Titles
1. &quot;Market Research Director&quot;
2. &quot;Market Research Manager&quot;
3. &quot;Insights Director&quot;
4. &quot;Customer Success Director&quot;
5. &quot;Customer Success Manager&quot;
6. “Customer Experience Director”
7. “Customer Experience Manager”
8. “Analytics Director/Manager”
*Minimum 100 from each title

Output in Excel. Columns:
1. Source
2. Job Title
3. Job Details/Description (“About the job”)
4. Job Requirements
5. About Us (If available)
6. Company Name
7. Contact/Recruiter name
8. Contact/Recruiter title (If available)
9. Contact/Recruiter email
10. Company website link (If available)
11. Company description (If available)
12. Pay (If available)
13. Onsite/Remote/Hybrid (If available)
14. Post Date

LEADS MUST INCLUDE Contact/Recruiter Name and Email Address. If not, it has no value and does not count.

OUTPUT IN XLSX. See attached example.","{'"Beautiful Soup'",Selenium,Python,JavaScript,'"Data Scraping'",'"Data Entry'",'"Data Mining'",'"Microsoft Excel'",Scrapy,'"Data Extraction'"}",United States,a,"","",2024-02-23 17:37:52.882885,2024-02-23 17:37:52.882885
https://www.upwork.com/jobs/Django-Selenium-Developer_~01ba129656abc78a3b/?referrer_url_path=/nx/search/jobs/,Django Selenium Developer,2024-01-30 10:08:37,"====================================
Requirements &amp; Selection Criterias
====================================

MUST HAVE:

1 - Two years experience in Django
2 - Two years Experience in Selenium Python Library for automation
3 - Experienced in filling web form as well as pop-up form through selenium library.
4 - Experience in Downloading PDFs &amp; capturing screenshots after filling the form by selenium
5 - Experience in Celery
6- Good experience of AWS services &amp; deployment
7- Experience in Postgre
8 - Experience in migration


OPTIONAL / GOOD TO HAVE:
= Maintaining the running web crawlers full stack application
= Design, build web crawlers to scrape data and URLs
= Integrate the data crawled and scraped into our databases
= Create more ways &amp; better ways to crawl relevant information
= Strong data structures 
= JavaScript frameworks
= Scrapy crawling framework would be an advantage
= Firewall &amp; Networking would be an advantage
= Experience in image processing like captcha decoding and reading
= Experience in integrating 3rd party APIs (like payment gateways)
= Experience in file handling
= Experience in Python Libraries - BOTO3 &amp; Panda



==================================== 
PROJECT TASK - Fill certain online forms with Captcha
==================================== 

STEPS TO FOLLOW
1. Create an array data set for form
2. Fill the the array data in the form via code
3. Select / enter values in the forms as required
 - in dropdown
 - in radio buttons
 - in multi-select checkboxes 
 - in date selector
 - in text fields with validations

4. Decode the image captcha value and fill in the form using Anticaptcha API
5. Submit the forms
6. Fetch &amp; store the results obtained after submitting the form","{Python,'"Web Crawling'",'"Data Scraping'",Scrapy,Django,Celery,API,PostgreSQL,Docker}",India,$8.00-$12.00,"","",2024-02-23 17:37:52.92985,2024-02-23 17:37:52.92985
https://www.upwork.com/jobs/Web-scrapping_~01ebd0b9b0e410df6e/?referrer_url_path=/nx/search/jobs/,Web scrapping,2024-01-30 06:49:14,Extract data from a medical website. Put data in an Excel file. ,"{'"Data Scraping'",'"Data Mining'",Python,'"Web Crawling'",Scrapy,'"Data Extraction'"}",Australia,$5.00-$15.00,"","",2024-02-23 17:37:52.937981,2024-02-23 17:37:52.937981
https://www.upwork.com/jobs/Web-Scraper_~01b99bcd7cb91339b9/?referrer_url_path=/nx/search/jobs/,Web Scraper,2024-02-02 17:37:52.944199,"I need a web scraper who is able to scrape job data from various job websites in a timely and efficient manner. If you are interested, please share your portfolio and experience. Please begin your proposal with &quot;EQ&quot; to demonstrate that you read this entire posts. Candidates who do, will be given greater attention. Candidates who don''t, will not.","{'"Data Scraping'",Python,'"Data Mining'",Scrapy,'"Data Extraction'",'"Web Crawling'"}",United States,f$,"","",2024-02-23 17:37:52.945787,2024-02-23 17:37:52.945787
https://www.upwork.com/jobs/Scraping-used-mobile-phone-prices_~0108297bf94b357838/?referrer_url_path=/nx/search/jobs/,Scraping of used mobile phone prices,2024-02-02 17:37:52.951643,"I am sure there must be someone who has already developed a script to scrape sites that sell used mobile phones. I am particularly interested in scraping UK sites like ebay.co.uk, gumtree.com, facebook marketplace. 
This can then be used to develop further features I require, but I would like this as a basic starting point","{'"Data Extraction'",'"Data Integration'",'"Web Crawling'",'"Beautiful Soup'",Selenium,Scrapy,pandas,'"Data Scraping'",Python}",United Kingdom,a,"","",2024-02-23 17:37:52.95329,2024-02-23 17:37:52.95329
https://www.upwork.com/jobs/API-Programmer_~01861f5cfd7f70ea5f/?referrer_url_path=/nx/search/jobs/, Ai / API Programmer,2024-01-29 19:11:27,"Im looking to pay someone to create a program that can do the following:
Step 1) I want something built that can extract custom data from designated public websites that has information about a home owners and their property
Step 2)   take that data of the homeowner name and address and have the program automatically reverse look up their contact info that might be available from public sites or pay sites 
Step 3)  I want that data to connect to some sort of text bot that can automatically text the home owner a simple message. Is this in your realm of experience?","{'"Web Scraping'",'"Data Scraping'",Python,'"Data Mining'",'"Data Extraction'",'"Browser Automation'",Selenium,'"Beautiful Soup'",Scrapy,'"Data Visualization'",'"Data Analysis'",'"Desktop Application'",'"API Integration'",Scripting,'"Scripts & Utilities'"}",United States,a,"","",2024-02-23 17:37:52.962502,2024-02-23 17:37:52.962502
https://www.upwork.com/jobs/Development-web-scraping-tool-that-collects-data-from-LinkedIn-and-stores-database_~01058e45c2357386dd/?referrer_url_path=/nx/search/jobs/,Development of a web scraping tool that collects data from LinkedIn and stores it in a database.,2024-01-29 18:36:00,"Can you develop a web scraper to collect data from LinkedIn and store it in a database?

I''m looking for the development of a web scraping tool that can collect data from LinkedIn, store it in a database, and provide access to search open content. 
I want to register a professional LinkedIn account, log in, and access a simple search bar for content. This development can help me to add value to my research market, so it should be simple to use, with the ability to collect and extract data from the API.

Additionally, I would like to access the data in a database to be able to read the collected content and download basic information about user profiles in a sheet data format, including first name, company name, zip code or country, market sector, and job function. 
As I''m not an expert in this field, I would like to understand which content can be collected and stored to extract valuable insights for my company from LinkedIn. 

Who we are: 
We are a technology-driven company that connects workers through our proprietary platform to enable new opportunities with a user-friendly solution. Our service is designed to tackle work-life balance issues with a simple approach, focusing on enhancing the user experience for both B2B and B2C sales.

I''m looking forward to working with you, so in your response, please reply &quot;I READ EVERYTHING&quot; with a short way of how you would start to gather data from the LinkedIn API and store it, so we can adjust the scope and even increase the hourly rate.


","{'"API Integration'",'"Microsoft Excel'",Scrapy,'"Data Extraction'",'"Data Collection'"}",Brazil,$5.00-$20.00,"","",2024-02-23 17:37:52.970292,2024-02-23 17:37:52.970292
https://www.upwork.com/jobs/Web-Crawler-Scraper-for-Facebook-Data-Gathering_~019f8494baf443dcc0/?referrer_url_path=/nx/search/jobs/,Web Crawler/Scraper for Facebook Data Gathering,2024-01-29 17:36:18,"I am looking for a freelancer who can develop a web crawler or web scraper to extract data from Facebook. The ideal candidate should have experience in web scraping and be able to create a tool that can effectively collect the data I need. This project will require the ability to navigate and crawl Facebook pages and retrieve the required information. The freelancer should also be familiar with web scraping techniques and best practices to ensure the accuracy and efficiency of the crawler/scraper. 

Relevant skills:
- Web scraping
- Python or JavaScript
- Facebook API
- Data extraction
- Website navigation
- HTML/CSS/JS","{'"Data Scraping'",'"Data Mining'",Scrapy,'"Web Crawling'"}",United States,$8.00-$150.00,"","",2024-02-23 17:37:52.979627,2024-02-23 17:37:52.979627
https://www.upwork.com/jobs/PDF-non-structured-membership-directories-into-formatted-into-google-sheets_~01d0579398d6fa8402/?referrer_url_path=/nx/search/jobs/,PDF non structured membership directories into formatted into google sheets,2024-01-29 17:24:56,"I have numerous membership directories of societies in pdf that have full contact and titles with emails. It is NOT structured

Lists range from 50 pages to 250 pages.

I WILL NOT PAY PER RECORD! We already own the records and Need someone that can structure the data into google sheets or CSV that we can put into our CRM.

Example of data we want extracted and most complex / Multiple contacts and titles under same company across pages in non structured tables
Pages 34 to 155.
https://user-zaechmz.cld.bz/FIA-Membership-Directory/","{'"Beautiful Soup'",Scrapy,Selenium,'"Selenium WebDriver'",pandas,'"Document AI'",'"Google Apps Script'",Import.io,Camelot,'"Power Query'"}",United States,a,"","",2024-02-23 17:37:52.987552,2024-02-23 17:37:52.987552
https://www.upwork.com/jobs/Web-Scraper_~01097eb3f819742c6e/?referrer_url_path=/nx/search/jobs/,Web Scraper,2024-01-29 10:39:00,"We are seeking a skilled and experienced web scraper to join our team. As a Web Scraper, you will be responsible for extracting valuable data from various websites, ensuring accuracy and efficiency in the process. The ideal candidate should have a strong background in web scraping technologies, programming, and data analysis.

Responsibilities:

Develop and implement web scraping scripts or tools to extract data from target websites.
Ensure the quality and accuracy of the extracted data.
Collaborate with the team to understand data requirements and deliver results accordingly.
Monitor and optimize scraping processes for efficiency and performance.
Stay updated on the latest web scraping techniques and technologies.
Requirements:

Proven experience as a web scraper with a portfolio of successful projects.
Proficiency in programming languages such as Python, JavaScript, or other relevant languages for web scraping.
Familiarity with web scraping libraries and frameworks (e.g., BeautifulSoup, Scrapy).
Strong understanding of HTML, CSS, and web structures.
Attention to detail and ability to troubleshoot and debug scraping scripts.
Excellent communication and collaboration skills.
","{'"Data Scraping'",'"Data Extraction'",'"Screen Scraping'",Scrapy,Python,'"Web Development'"}",France,$4.00-$6.00,"","",2024-02-23 17:37:53.003031,2024-02-23 17:37:53.003031
https://www.upwork.com/jobs/Video-Data-Scrapper_~012de9566c4967b3d2/?referrer_url_path=/nx/search/jobs/,Video Data Scrapper ,2024-02-02 17:37:53.009309,"Are you a data enthusiast with a passion for video content? We''re looking for a dedicated Video Data Scraper to join our team and unlock the power of visual information. You''ll be responsible for extracting valuable insights from videos, including metadata, transcripts, and visual features, using cutting-edge scraping techniques and AI-powered tools.

Responsibilities:
1. Develop and implement video scraping scripts using Python or other scripting languages, leveraging libraries like OpenCV and ffmpeg.
2. Extract diverse data points from videos, including titles, descriptions, tags, speakers, timestamps, and visual cues.
3. Utilize natural language processing and computer vision techniques to generate video transcripts and analyze scenes
4.Clean and pre-process the scraped data to ensure accuracy and prepare it for further analysis
5. Implement data quality control measures to monitor and track data integrity.
6. Document and maintain scraping scripts and methodologies for future reference.
Stay up-to-date with the latest advancements in video scraping and AI technologies.
Collaborate with data scientists and researchers to understand data needs and ensure successful outcomes.

Qualifications:
1. Bachelor''s degree in Computer Science, Data Science, Media Technology, or a related field (preferred).
2, 1+ years of experience in web scraping and data extraction, ideally with video-specific projects.
3. Strong understanding of video formats, codecs, and encoding principles.
4. Familiarity with Python and libraries like OpenCV, ffmpeg, and NLTK.
5. Experience with natural language processing and computer vision tools is a plus.
6. Excellent problem-solving and analytical skills.
7. Attention to detail and ability to work with large datasets accurately.
8. Strong communication and teamwork skills.","{'"Data Integration'",'"Screen Scraping'",JavaScript,PHP,R,Python,'"Data Mining'",'"Data Scraping'",'"Data Extraction'",Scrapy}",India,$5.00-$30.00,"","",2024-02-23 17:37:53.011227,2024-02-23 17:37:53.011227
https://www.upwork.com/jobs/need-reverse-engineering-website-see-which-api-they-use_~01a8ad85f3ae2e6e47/?referrer_url_path=/nx/search/jobs/,"I need to reverse engineering a website to see which api they use

",2024-01-26 17:37:53.018519,"Greetings!

I need to reverse engineering this website to see which api they use for the Instagram profile picture Zoom 
","{'"AI App Development'",'"Web Application'",Scrapy,API,PHP,Python,C#,WordPress,HTML,HTML5}",Norway,a,"","",2024-02-23 17:37:53.020988,2024-02-23 17:37:53.020988
https://www.upwork.com/jobs/Web-Crawling-Web-Scraping-Developer_~0164ba7e52d907419f/?referrer_url_path=/nx/search/jobs/,Web Crawling/Web Scraping Developer,2024-01-27 18:52:06,"Dear valued freelancer,
For our project we are hiring a developer to support our team.
We have an onlineshop which is feeded by a Rest API interface.
The feed does contain information from other webshops such as availability of products.

Issues we are facing:
#1 non available products are catched as available
#2 the web scraper does not get all the products

Immediate support is required.
You will get access to Digital Ocean and Github.

You can work on weekends as well, if you like.
However, we need a fast communication therefore we are using Skype.

Your portfolio shall cover the following:
- Python required (Priority)
- Selenium
- Scrapy
- Proficient in any of front-end tech such as (react/vue/angular) (not 100% required)
- Familiarity with API - esp. Rest API (Priority)
- Experience with version control software (Git/GitHub).
- Digital Ocean Platform
Thx
Chris","{Selenium,Python,'"Web Crawling'",Scrapy,'"Data Scraping'",'"REST API'",GitHub}",Germany,$8.00-$15.00,"","",2024-02-23 17:37:53.030483,2024-02-23 17:37:53.030483
https://www.upwork.com/jobs/web-scraping-monitoring-needed_~0148ed0a0ca916ea99/?referrer_url_path=/nx/search/jobs/,24/7 web scraping monitoring needed,2024-01-26 17:37:53.037563,"Hey

I need to be updated about new entries on several websites 24/7. Data need to be scraped. 

BR
Kevin","{'"Data Scraping'",Python,'"Data Mining'",'"Data Entry'",Scrapy,'"Data Extraction'",'"Microsoft Excel'"}",Germany,cp,"","",2024-02-23 17:37:53.039883,2024-02-23 17:37:53.039883
https://www.upwork.com/jobs/Acquiring-Data_~01f3f404f63ac5d73a/?referrer_url_path=/nx/search/jobs/,Acquiring Data,2024-01-27 15:27:46,"Acquiring Data
Specific Field
Can you do this everywhere, mostly Canada
I would need Data for at least 500 to 1000 people.
","{'"Web Scraping'",'"Data Scraping'",'"Data Mining'",'"Data Entry'",Python,'"Lead Generation'",'"Data Extraction'",'"List Building'",'"Prospect List'",Scrapy,Selenium,'"Web Crawling'",Automation,'"Microsoft Excel'",JavaScript}",Canada,a,"","",2024-02-23 17:37:53.049297,2024-02-23 17:37:53.049297
https://www.upwork.com/jobs/Web-Scraping_~01334d831bbf6fc51f/?referrer_url_path=/nx/search/jobs/,Web Scraping,2024-01-27 09:51:14,"I need app.publicsq.com scraped for products, sellers, businesses, and their contact information including phone, email, socials. I would like this in a CSV file format, but any excel sheet should work. Mind, app.publicsq.com is just the base directory, I want the whole site scraped. I do not care what technology you use, I just care about the data. ","{'"Data Scraping'",Python,'"Data Mining'",Scrapy,'"Web Crawling'",'"Data Extraction'",'"Data Entry'"}",United States,f$,"","",2024-02-23 17:37:53.058198,2024-02-23 17:37:53.058198
https://www.upwork.com/jobs/Need-scraping-from-ecommerce-marketplaces_~01a43194e7c262c992/?referrer_url_path=/nx/search/jobs/,Need scraping from ecommerce marketplaces ,2024-01-27 07:29:29,"We are looking for an expert to perform one-time data scraping.

We would need to scrape for 5 brand names.
Brands will be shared in chat 

Places/websites to scrape:
- Google Shopping (worldwide)
- Amazon (worldwide)
- Walmart
- Mercadolibre
- Bol.com
- eBay (.com and .co.uk)
- Rakuten

For these 5 brand names, we would need to scrape which Vendor is selling them on these different marketplaces.

The delivered file should be an Excel file, with the following columns:
- Brand name
- Product name
- Vendor (seller) name
- Price
- Link to article page

We would need this scrape to be done till coming Tuesday ","{'"Data Extraction'",'"Screen Scraping'",'"Web Crawling'",'"Web Scraping'",'"Beautiful Soup'",Python-Requests,Selenium,'"Data Scraping'",Scrapy,Python}",Pakistan,a,"","",2024-02-23 17:37:53.066096,2024-02-23 17:37:53.066096
https://www.upwork.com/jobs/Ensemble-stacked-model_~012218a38d5ac8acca/?referrer_url_path=/nx/search/jobs/,Ensemble stacked model ,2024-01-25 13:29:40,"I want to make a ensemble modelling.
The data set has no image data 
Data already preprocessed.","{Python-Requests,Scrapy,Python,Selenium,'"Data Scraping'",JavaScript,CSS,'"Scripts & Utilities'",HTML,Scripting,'"Virtual Private Server'",Vue.js,Django,'"Responsive Design'"}",India,a,"","",2024-02-23 17:37:53.174917,2024-02-23 17:37:53.174917
https://www.upwork.com/jobs/Build-web-scraping-tool_~01f54732cc8f7eb3e0/?referrer_url_path=/nx/search/jobs/,Build a web scraping tool,2024-01-27 06:18:39,"I need someone to build a program that will scrape pricing data on apartments from their websites and build a predictive analytics model of trends in the market based on either a map radius model or direct input of the website to scrape.  Then, I need that data to be viewed on screen and/or export into a semi advanced Excel sheet.  There would be an AI modeling component I would want someone to incorporate.  Ideally, I want this to be set up on a dedicated website for multiple users to be able to login and do the same thing.

I''m happy to answer any questions.  From my limited research it sounds as though I need someone with Python background, Scrapy, Machine Learning/AI predictive analytics and web design.  I forsee this project to be developed and fine tuned to get it ready for multiple users. 
 Thanks!","{'"API Integration'",'"Data Scraping'",Python,Scrapy,'"Web Crawling'"}",United States,$25.00-$65.00,"","",2024-02-23 17:37:53.073732,2024-02-23 17:37:53.073732
https://www.upwork.com/jobs/Social-media-profile-post-scraper_~011d1c0e9610b06dac/?referrer_url_path=/nx/search/jobs/,Social media profile post scraper,2024-01-26 18:54:32,"I need a tool that can take in a social media handle from various social media sites such as LinkedIn, twitter, facebook, youtube, tiktok, Instagram, etc and extract links to every post that handle has made.

Preferably it would make calls to an API to handle the scraping and will convert the response into a provided standardized format or just receive the post links. Should be scalable and cost-efficient and only call 1-3 API providers.","{'"API Integration'",'"Data Scraping'",'"Data Extraction'",'"Web Scraping Framework'",Scrapy,'"Beautiful Soup'"}",United States,a,"","",2024-02-23 17:37:53.082009,2024-02-23 17:37:53.082009
https://www.upwork.com/jobs/commerce-Product-Data-Scraping_~01370f2ae360765a3a/?referrer_url_path=/nx/search/jobs/,E-commerce Product Data Scraping,2024-01-26 18:44:37,"Product Information: Gather details for each product, including Name, Description, SKU, and Pricing.

Attributes: Collect additional product attributes such as Color, Size, and other relevant details.

Images: Retrieve multiple images associated with each product, including swatches for different attributes.

Requirements:

Previous experience with web scraping and data extraction.
Familiarity with e-commerce websites and product data structures.
Proficient in organizing data in Excel.
Ability to handle a large volume of products (approximately 150+).
Deliverables:

Excel spreadsheet with organized product data, including images and attributes.
How to Apply:

Share your relevant experience with web scraping and data extraction.

Provide examples of similar projects you have completed.

Share your approach to handling large volumes of data efficiently.

Include your estimated timeline for completing the project.","{'"Data Entry'",'"Data Scraping'",'"Microsoft Excel'",Python,'"Data Extraction'",Scrapy}",Pakistan,a,"","",2024-02-23 17:37:53.091428,2024-02-23 17:37:53.091428
https://www.upwork.com/jobs/Scrape-list-from-website_~01e6d6690ec7e1cb7a/?referrer_url_path=/nx/search/jobs/,Scrape a list from a website ,2024-01-26 17:37:53.098195,"Looking for a scrapping pro to extract couple of basic data from a website page + data entry. It''s a quick to get job, hoping to get it done in the next few hours.","{'"Data Scraping'",Python,'"Data Mining'",'"Data Entry'",Scrapy,'"Data Extraction'"}",China,$3.00-$25.00,"","",2024-02-23 17:37:53.1002,2024-02-23 17:37:53.1002
https://www.upwork.com/jobs/need-whatsapp-lists-extracted-from-specific-sites_~0173c7b3b3a2f04ecb/?referrer_url_path=/nx/search/jobs/,I need whatsapp lists extracted from specific sites.,2024-01-26 17:37:53.106125,"I need WhatsApp lists taken from specific websites.

I hire a technology professional who can retrieve this data for me. ","{'"Data Scraping'",'"Data Entry'",'"Data Mining'",'"Lead Generation'",Scrapy,'"Prospect List'"}",Brazil,a,"","",2024-02-23 17:37:53.107752,2024-02-23 17:37:53.107752
https://www.upwork.com/jobs/Scrape-Amazon-Reviews-for-Specific-Product_~017042091076d715c5/?referrer_url_path=/nx/search/jobs/,Scrape Amazon Reviews for a Specific Product,2024-01-26 12:31:54,"We are conducting academic research that involves sentiment analysis of product reviews for a specific beauty product. The task requires scraping 8k+ product reviews from Amazon.com for this specific product. We aim to capture a wide array of data points from each review to facilitate a comprehensive analysis.

Key Responsibilities:
•	Develop a Python script(s) for web scraping product reviews from Amazon.com for a specific beauty product.
•	Ensure the script is capable of navigating through multiple review pages to capture all available reviews.

Data Points to be Scraped:
•			Reviewer''s screen name/username
•			Full review text
•			Review date
•			Star rating (1 to 5 stars)
•			Review title (if available)
•			Whether the review is sponsored or not (if this information is available)
•	             Country
•	             All additional metadata associated with the review (e.g., verified purchase, helpful votes, etc.)
	
Technical Requirements:
•	Proficiency in Python programming, particularly with web scraping libraries such as BeautifulSoup, Requests, Selenium (if dynamic content needs to be scraped), and Pandas for data manipulation.
•	Experience in handling pagination and dynamically loaded content on web pages.
•	Ability to implement respectful web scraping practices, including adhering to the robots.txt file, using headers to mimic a web browser, and managing request rates to avoid IP bans.
•	Capability to structure the scraped data into a well-organized format, preferably a CSV file, for easy analysis.

Deliverables:
			1.  Python script(s) with clear documentation and comments.
			2.  CSV file(s) containing the scraped data from both websites.
			3.  A brief report summarizing the scraping approach, challenges encountered, and solutions implemented.
","{Python,'"Data Extraction'",'"Web Scraping'",'"Beautiful Soup'",Selenium,pandas,'"Data Scraping'",'"Data Mining'",Scrapy}",United States,cp,"","",2024-02-23 17:37:53.118043,2024-02-23 17:37:53.118043
https://www.upwork.com/jobs/Web-Scraping_~01a82356c3dc023a0d/?referrer_url_path=/nx/search/jobs/,Web Scraping ,2024-01-26 08:20:27,Need someone for high volume web scraping project for an academic assignment ,"{'"Data Scraping'",Python,'"Data Mining'",Scrapy,'"Web Crawling'",'"Data Extraction'"}",United States,a,"","",2024-02-23 17:37:53.128223,2024-02-23 17:37:53.128223
https://www.upwork.com/jobs/Web-Scraping-extract-data-from-website_~01199cdfd945515918/?referrer_url_path=/nx/search/jobs/,Web Scraping-extract data from website,2024-01-26 17:37:53.135239,"Forbes publishes a list of the Top 100 USA-based charities each year. I want you to put that list into an Excel spreadsheet. I need data for the past 20 years.
https://www.forbes.com/lists/top-charities/?sh=780c85dc5f50
","{'"Data Scraping'",Scrapy,'"Web Crawling'",'"Data Extraction'",Python,Python-Goose,'"Data Science'"}",United States,a,"","",2024-02-23 17:37:53.137656,2024-02-23 17:37:53.137656
https://www.upwork.com/jobs/Scrape-Google-Shopping-and-other-websites_~01a8b8cb9fcea329a2/?referrer_url_path=/nx/search/jobs/,Scrape Google Shopping and 8 other websites,2024-01-25 23:55:26,"

Websites to scrape:
Google Shopping
Woolworths
Coles
Chemist Warehouse
Big W
Steel City Beverage Co
https://mysweeties.com.au/collections/beverages
https://www.ibmetsocoast.com.au
https://dandenong.accredited.com.au/shop/BEVERAGES
https://www.thedistributorsbrisbane.com.au/shop/BEVERAGES
https://kellysdistributors.com.au
www.ibmroadelaide.com.au
www.jbmetro.com.au
www.jbmetrosouthcoast.com.au



Key objectives:

1. Create an API endpoint that will allow us to &quot;POST&quot; and receive scraped results based on a keyword searched of a product


Responsibility and accountability:

1. must be able to run the scraper for 3 months successfully prior to getting paid the remaining amount
2. Must be familiar with technologies such as 2captcha etc

Budget is NON-Negotiable!

Sites to scrape:
Google Shopping
Woolworths
Coles
Chemist Warehouse
Big W
Steel City Beverage Co
https://mysweeties.com.au/collections/beverages
https://www.ibmetsocoast.com.au
https://dandenong.accredited.com.au/shop/BEVERAGES
https://www.thedistributorsbrisbane.com.au/shop/BEVERAGES
https://kellysdistributors.com.au
www.ibmroadelaide.com.au
www.jbmetro.com.au
www.jbmetrosouthcoast.com.au


More project details:
- Data Storage: System to save product data; output a confirmation message.
- Product Price Query: Fetch real-time prices from Coles, Woolworths, Chemist Warehouse; display pricing data.
- Error Display for Missing Product: Detect and display errors for missing products.
- Image Link Display: Provide image links for each product.
- RabbitMQ: Manage scraping requests through a messaging queue system.
- Server Configuration: Handle POST requests and multiple simultaneous requests.
- API Endpoint Implementation: Develop /api/scan-products endpoint for POST requests.
- Script Integration: Backend to integrate with scripts for automated web interactions.
- Scraping Logic Development: Handle various product scenarios during scraping.
- Scripting Framework: Framework for script execution and management.
- Response Structuring: Compile results into structured JSON.
- Error Handling &amp; Logging: Implement robust error handling and logging.
- API Security: Secure API endpoint, implement rate limiting.
- Scheduled Timer: Trigger scrapes as per schedule to update the product database.
- Website Scraping: Initiate scrapes based on a timer to update the product database.
- Product Database Lookup: Perform lookups in the database when scrapes are triggered.
- Query Products: Execute queries post-scrape for product availability.
- Flag Products Not Found: Mark and snapshot ''not found'' products for database accuracy.
- Snapshot Creation: Generate snapshots for ''not found'' products for future reference.
- Save Scraped Data: Append snapshot data to records for storage.
- Database Saving: Store data in the database post-snapshot or product addition.
- Staff Login: Secure login for Sun Road staff to access website lists.
- Display Websites List: Show website list post-login for navigation.
- Downloading Latest Scrape: Enable Excel file download of latest scraped data.
- Excel Download Automation: Automate Excel file download on user request.

We already have Zyte - and we will be implementing a rotating proxy




","{'"API Integration'",'"Data Scraping'",Python,Scrapy}",Australia,a,"","",2024-02-23 17:37:53.14634,2024-02-23 17:37:53.14634
https://www.upwork.com/jobs/Scraping-Facebook_~0171d8641d5eb6a319/?referrer_url_path=/nx/search/jobs/,Scraping Facebook,2024-01-25 22:28:44,"I need to target any FB profiles that follow school districts within the U.S. - Or any profiles that label themselves as parents. Or Self Employed. 

Happy to discuss further, or if you already have an existing list or access this data in other formats, happy to discuss as well. ","{'"Data Scraping'",Scrapy,'"Data Extraction'",'"Data Mining'",Python}",United States,cp,"","",2024-02-23 17:37:53.15647,2024-02-23 17:37:53.15647
https://www.upwork.com/jobs/Need-scraping-script-scrapy-requests_~01268976fb63e8967d/?referrer_url_path=/nx/search/jobs/,Need scraping script in scrapy or requests ,2024-01-25 18:36:38,"https://shopee.vn/search?keyword=syngenta

I need a scraping script in scraping or request to scrape data when we search something on this website just as above url 
I need the name,price ,currency,images,seller name ","{'"Task Automation'",Automation,'"Beautiful Soup'",Selenium,'"Data Scraping'",Scrapy,Python,'"Web Crawling'",'"Data Extraction'"}",Pakistan,a,"","",2024-02-23 17:37:53.166322,2024-02-23 17:37:53.166322
https://www.upwork.com/jobs/Scraping-Expert_~01bb2ec3a2a6bab4a0/?referrer_url_path=/nx/search/jobs/,Scraping Expert,2024-01-25 09:45:59,"Hi, we are a US based firm and looking for an expert in Data Scraping. Its a short-term opportunity but the contract may be extended to long term opportunity. The person will be required to scrap data and is able to customize the data scraping tool according to our needs.

Job Requirements
2+ years of experience with scraping
Amazing communication skills
A good command of the English language
An ability to keep deadlines
You must be highly motivated

Below are the skills that are preferred but not required: 
Any level of skill in Laravel
","{'"Data Scraping'",Python,'"Data Mining'",'"Data Extraction'",Scrapy,Laravel}",Pakistan,$3.00-$5.00,"","",2024-02-23 17:37:53.184146,2024-02-23 17:37:53.184146
https://www.upwork.com/jobs/Scrap-data_~011d964d5334de0e50/?referrer_url_path=/nx/search/jobs/,Scrap data,2024-01-25 08:50:20,extract data from site by generating potential certificate and serial number and captcha,"{'"Data Scraping'",'"Data Extraction'",Scrapy,Python,Python-Goose}",Kazakhstan,a,"","",2024-02-23 17:37:53.194266,2024-02-23 17:37:53.194266
https://www.upwork.com/jobs/scrape-data-for-10K-contacts_~01b26cad123a5db0fd/?referrer_url_path=/nx/search/jobs/,scrape data for 10K contacts. ,2024-01-25 05:17:41,"Hi, 
We need someone to scrape data for us. 
We will provide Company name and URL and we need a list of their
CEO Name
CEO Email
CEO Phone

It is a list of around 10k companies. ","{'"Data Scraping'",'"Data Mining'",'"Microsoft Excel'",'"Data Extraction'",'"List Building'",Scrapy}",India,a,"","",2024-02-23 17:37:53.202739,2024-02-23 17:37:53.202739
https://www.upwork.com/jobs/Research-and-Data-extract-project_~0184229fdc09454ab1/?referrer_url_path=/nx/search/jobs/,Research and Data extract project,2024-01-25 03:25:30,"We have a list of 30,000 small businesses with website url, shop name, in most cases owner name, shop phone and shop email.

We are looking for someone who can do web research, use tools to extract below additional details for us

Owner contact details like personal email, personal phone and if possible address. We use this ONLY to target with paid advertising if possible.","{Scrapy,'"Data Scraping'",'"Data Mining'",'"Data Extraction'"}",United States,a,"","",2024-02-23 17:37:53.211814,2024-02-23 17:37:53.211814
https://www.upwork.com/jobs/Scrape-information-from-website_~018a758aefd5256da3/?referrer_url_path=/nx/search/jobs/,Scrape information from website,2024-01-24 23:55:41,"I have a list of 6000 company names (CIN). I need to scrape some information for these companies from a website: www.zaubacorp.com. 

For example, if you enter &quot;L00000CH1990PLC010573&quot; in the search, it displays several tables for this company. I want to scrape the table called &quot;Director Details&quot;. This will be done for 6000 companies. 

","{'"Data Scraping'",'"Beautiful Soup'",Selenium,'"Selenium WebDriver'",Python,Scrapy}",United Kingdom,a,"","",2024-02-23 17:37:53.22043,2024-02-23 17:37:53.22043
https://www.upwork.com/jobs/Google-Chrome-Extension-for-web-scraping_~016a3639c455f30c79/?referrer_url_path=/nx/search/jobs/,Google Chrome Extension for web scraping,2024-01-26 17:37:53.226155,"Please watch the video, the website is creating a google chrome extension to scrape data from this website while browsing it and export agents info and most importantly contact info.

Watch the video for more details and contact me with an exact fixed price because the project is straightforward.

https://www.loom.com/share/790bb99bacae4a4f899e92d4ec1ff7ea?sid=2895073f-0d24-4632-9c09-a0b6f70a3f88","{'"Data Scraping'",JavaScript,'"Google Chrome Extension'",HTML,API,Scrapy,Automation,PHP,Python}",Morocco,$3.00-$40.00,"","",2024-02-23 17:37:53.228061,2024-02-23 17:37:53.228061
https://www.upwork.com/jobs/need-someone-create-tool-that-can-scrape-list-websites-and-get-the-technologies_~01e217fa0a3b679b14/?referrer_url_path=/nx/search/jobs/,I need someone to create a tool that can scrape me a list of websites and get me the technologies ,2024-01-24 19:12:03,"I need someone who can scrape me a list of websites and get me the following:

- Technologies they use
- SEO score
","{'"Data Scraping'",Python,'"Data Mining'",'"Data Entry'",'"Microsoft Excel'",Scrapy,JavaScript}",Spain,a,"","",2024-02-23 17:37:53.237257,2024-02-23 17:37:53.237257
https://www.upwork.com/jobs/Web-Scraping-and-aggregation-into-Excel_~011ae9b231ff0517cf/?referrer_url_path=/nx/search/jobs/,Web Scraping and aggregation into Excel,2024-01-24 18:38:56,"I am looking for someone who can extract / scrape data from different websites and aggregate them all into a single spreadsheet. 
Then edit the spreadsheet to refine the data.
Part time job, but will need this work done every month or so.
Proficiency with spreadsheets.
Must be willing to provide the code / script.
Looking for someone I can work with on a regular basis.","{'"Microsoft Excel'",'"Data Scraping'",'"Data Mining'",'"Data Extraction'",Automation,'"Google Sheets'",Python,Scrapy}",United States,$4.00-$25.00,"","",2024-02-23 17:37:53.247229,2024-02-23 17:37:53.247229
https://www.upwork.com/jobs/Web-scraping_~01b4afc3faed6cd594/?referrer_url_path=/nx/search/jobs/,Web scraping ,2024-01-24 18:30:26,"Can you do a quick run and tell me how many results from the link you can extract?

https://www.yellowpages.com.au/find/swimming-pool-designs-construction/australia/page-1","{Automation,'"Beautiful Soup'",Selenium,'"Data Scraping'",'"Web Crawling'",Python,Scrapy,'"Data Extraction'"}",Pakistan,a,"","",2024-02-23 17:37:53.255926,2024-02-23 17:37:53.255926
https://www.upwork.com/jobs/Expert-Python-Developer-for-Web-Scraping_~012cdd754cf6ab9128/?referrer_url_path=/nx/search/jobs/,Expert Python Developer for Web Scraping,2024-01-24 17:37:53.262257,"Expert Python Developer for Web Scraping


We''re searching for an experienced Python Developer, specialized in web scraping, to join our team. Your primary focus will be on developing robust, efficient scripts using Selenium, Requests, BeautifulSoup4 (bs4), and Pandas libraries.

Preferred candidates:

1. Proven track record with Python and web scraping.

2. Extensive use of Selenium, Requests, bs4, and Pandas.

3. Experience with Azure Tables, Blobs, Amazon, or other e-commerce data is a big plus.

4. Strong analytical and problem-solving skills.

5. Excellent communication.


Please note: Candidates will need to take a test round demonstrating proficiency in Python, Selenium, Requests, bs4, and Pandas.","{'"Web Scraping'",Python,Scrapy,'"Data Scraping'",Automation,Selenium,'"Data Mining'",API,'"Python Script'"}",India,$5.00-$10.00,"","",2024-02-23 17:37:53.26425,2024-02-23 17:37:53.26425
https://www.upwork.com/jobs/Amazon-Web-page-Data-Scraping-Google-sheets-Airtable-using-Python_~013671fecbe553ba0c/?referrer_url_path=/nx/search/jobs/,Amazon Web page Data Scraping to Google sheets or Airtable using Python,2024-01-24 17:37:53.270342,"Hi,

I am interested in developing a Python script for extracting data from Amazon web pages and transferring it to Google Sheets or Airtable through web scraping. The script should have the capability to fetch information from Amazon''s website and offer flexibility in selecting and updating the products to be scraped.

Please see the google sheets link to see what information we need from an Amazon Webpage:  https://docs.google.com/spreadsheets/d/17xsjH-Fg7LLjQPuVlFR2Bb2yZbK2xKrWnbgzGyQCwiU/edit?usp=sharing

There will be 3 data sources we will pull data from:
Amazon product page, sample page: https://www.amazon.com/dp/B0BZCPJRJW/
Amazon''s Fee Calculator: https://sellercentral.amazon.com/fba/revenuecalculator/
Helium-10 Extension
","{Python-Requests,Scrapy,Python,Selenium,'"Data Scraping'",JavaScript,CSS,'"Scripts & Utilities'",HTML,Scripting,'"Virtual Private Server'",Vue.js,Django,'"Responsive Design'"}",Taiwan,a,"","",2024-02-23 17:37:53.272533,2024-02-23 17:37:53.272533
https://www.upwork.com/jobs/Web-Scraper-Data-Analysis-Python-Review_~013fda168eb781e8b4/?referrer_url_path=/nx/search/jobs/,Web Scraper Data Analysis Python Review,2024-01-23 21:01:14,"Goal is to write a repeatable code finds 4 main peices of data from a csv file list of websites and pull that data into a final product csv file. The 4 main pieces of data I need: 1) if that website is on shopify or not (found in the HTML), 2) if they have a returns app (included in a list of return app names) 3) if they offer free returns. Note: 2 &amp; 3 might be found in the main link or a sublink of each domain listed. And 4) that websites similarweb ''Monthly Visits'' score.  Then with all of that data, I want to download all of that data into a csv file.

Along with those 4 peices I want the list to include the orginal values of company, domain, and any other columns that came in the orginal files. 

I believe I have written the majority of the code below, but I am stuck for the time being. I just dont know how to get it to RUN and save to a csv file. I would love to save error coding, speed work with running tasks asynchronously, and only run the code a few times from each website in order to not be blocked by shopify

For point #4 - Ideally I would want someone to use selenium or a similar program to dive into the similar web chrome extension to pull the monthly visits number INSTEAD of using the second csv file. 

I want to do a consultation video call before hand. 
","{Scrapy,SQL,Python,'"Data Entry'",'"Data Scraping'",'"Data Mining'",'"Beautiful Soup'",Selenium,'"Lead Generation'",'"Web Crawling'",'"Data Extraction'",Automation,'"Web Scraping'",'"Selenium WebDriver'",Shopify,'"Web Crawler'",pandas}",United States,a,"","",2024-02-23 17:37:53.280859,2024-02-23 17:37:53.280859
https://www.upwork.com/jobs/Scrape-all-pizza-shops-and-quick-service-restaurants_~013d2e9e690c1ab8a8/?referrer_url_path=/nx/search/jobs/,Scrape all pizza shops and quick service restaurants,2024-01-23 20:18:43,"I need all pizza shops and quick service restaurants in New Jersey.

Shop name
Address
Zip Code
Phone number

this is all I need","{'"Online Research'",'"Microsoft Word'",'"Microsoft Excel'",'"Data Entry'",'"Data Mining'",'"Google Docs'",'"Data Scraping'",'"Company Research'",'"Lead Generation'",Scrapy,'"Data Analysis'",'"Data Extraction'",'"Web Scraping'",Typing,'"Computer Skills'"}",United States,a,"","",2024-02-23 17:37:53.289497,2024-02-23 17:37:53.289497
https://www.upwork.com/jobs/Seeking-expert-web-scraping-Scrapy-for-writing-articles_~0194b5b25479c3a87b/?referrer_url_path=/nx/search/jobs/,Seeking expert in web scraping (Scrapy) for writing articles,2024-01-23 13:21:55,"We are looking for a skilled and knowledgeable web scraping expert to write insightful and engaging articles and content focused on the niche of web scraping.

Responsibilities:
- Write high-quality, original content about various aspects of web scraping.
- Create articles that are informative, engaging, and easy to understand for a wide range of readers, from beginners to advanced users.
- Stay up-to-date with the latest trends and advancements in web scraping technology and incorporate them into your writing.
- Collaborate with our team to develop content ideas and strategies.
- Ensure all written content is SEO-friendly.

Requirements:
- Proven experience in web scraping, with a deep understanding of its techniques, tools, and applications.
- Excellent writing skills with a portfolio of published articles or content in a relevant field.
- Ability to explain complex technical concepts in an easy-to-understand manner.
- Familiarity with SEO best practices for content writing.

Ability to meet deadlines and manage multiple tasks efficiently.

To apply, please submit the following:
- A brief cover letter explaining your experience in web scraping and content writing.
- Links to or samples of relevant articles or content you have written.","{Scrapy,Python,'"Data Mining'",'"Data Scraping'",'"Web Crawling'"}",Serbia,a,"","",2024-02-23 17:37:53.297589,2024-02-23 17:37:53.297589
https://www.upwork.com/jobs/Python-web-scrapper-required_~01f2e54b7dbeac8b15/?referrer_url_path=/nx/search/jobs/,Python web scrapper required,2024-01-23 13:10:46,"Hello All,

We are a placements company and hence would be regularly requiring clients where we can recruit candidates

So as of now we are searching clients who are posting their jobs in:

Indeed
Linkedin

Apnajobs
WorkIndia
Shine.com

Etc

I wanted to make an tool in Python (web based tool) where the tool can 

1) Automatically scrap jobs and the contact details (mainly number and email id)
2) Then directly send the proposal email (official gmail) to clients and also whatsapp (not business api but through url method) ( we will give predefined templates where only few customization would be there on each clients
3) Make the daily real-time report of above in Google drive of the above and email to us

Process 2
1) Need to  see automatically and understand (through AI) that if number and email id is or not their, in the extracted jobs data in process 1 , if not then make separate daily report of the same as non-contact data and then automatically take one by one number from excel and search the contact details of  that company HR in Linkedin and in google and then make update the list of contacts (mainly email id and number) and then again send email and whatspp and remake the report 

2) Atlast there would be a possiblity where the contact details wont be extracted by Automation and AI then, make its final report of non-contact data and named as &quot;Final non-contact data&quot; at end of each day  and save it in google drive also email to us.

Let me know if you can do this?
and within how many days?
and how much is the final qoute?

Have a great day.","{Selenium,'"Beautiful Soup'",Python,'"Data Scraping'",Scrapy,'"Data Mining'",'"Web Crawling'",'"Python Script'",API,JavaScript}",India,a,"","",2024-02-23 17:37:53.305834,2024-02-23 17:37:53.305834
https://www.upwork.com/jobs/HIRING-Web-Scraping-Developer_~01c6fb2c3404d156d3/?referrer_url_path=/nx/search/jobs/,[HIRING] Web Scraping Developer,2024-01-23 09:52:19,"I am looking for a skilled and experienced Web Scraping Developer. As a Web Scraping Developer, you will be responsible for monitoring and extracting new items added to various e-commerce websites.

Required skills and experience:

- Proficiency in web scraping libraries and frameworks.
- Understanding of HTTP protocols, networking, and be adept at handling dynamic website content.
- Experience with data parsing, cleaning, and storing in databases.
- Experience working with the Discord API to send messages, embeds, or other content to a Discord server
- Knowledge of how to develop Discord bots using libraries such as discord.py (for Python) or other relevant frameworks for other programming languages.
- Familiarity with setting up and using webhooks to enable communication between your scraping script and the Discord server.
- Understanding of asynchronous programming, especially if you''re using Discord libraries that rely on asynchronous operations.
- Knowledge of CI/CD tools and practices for automating the deployment and maintenance of your scraping and Discord integration.
- Designing the solution with scalability in mind to handle potential increases in data volume or server load.

This role is paid competitively based on the candidate''s skills, experience, and the complexity of the responsibilities involved. Please note, paid work will be required after project delivery with new website additions and updates. ","{'"API Integration'",'"Data Extraction'",'"Web Crawling'",Selenium,'"Selenium WebDriver'",Python,'"Data Scraping'",Scrapy,API}",United Kingdom,$3.00-$15.00,"","",2024-02-23 17:37:53.314967,2024-02-23 17:37:53.314967
https://www.upwork.com/jobs/Web-Scraper-Data-Analysis-Python-Review_~012865c68f1e1718e6/?referrer_url_path=/nx/search/jobs/,Web Scraper Data Analysis Python Review,2024-01-23 01:24:15,"Essentially my goal is to run a code that pulls 1 or 2 csv files (included those templates below) that include a list of domains and scrubs the data from those websites to find 1) if they are on shopify or not (in the HTML), 2) if they have a returns app (included in a list of return app names), and this can be in sublinks from the main page, and 3) if they offer free returns. Then with all of that data, I want to download all of that data into a csv file.

I believe I have written the majority of the code below, but I am stuck for the time being. I just dont know how to get it to RUN and save to a csv file. Im thinnking it is probably an easy fix, but Idk...

Ideally I would also want to include selenium to utilize a similar web chrome extension to pull the monthly visits number INSTEAD of using the second csv file. 

OBO - willing to pay more if we do a consultation and you tell me how you''ll get it done. 
","{Scrapy,SQL,Python,'"Data Entry'",'"Data Scraping'",'"Data Mining'",'"Beautiful Soup'",Selenium,'"Lead Generation'",'"Web Crawling'",Django,'"Data Extraction'",Automation,'"Web Scraping'",JavaScript}",United States,a,"","",2024-02-23 17:37:55.431707,2024-02-23 17:37:55.431707
https://www.upwork.com/jobs/Bot-Automation-Developer_~0157c96430c815793e/?referrer_url_path=/nx/search/jobs/,X Bot Automation Developer ,2024-01-23 00:53:38,I am searching for an individual that is about to help me automate my X account. ,"{'"Data Scraping'",'"Data Extraction'",Scrapy,Selenium,ETL,'"Web Crawling'",'"Machine Learning'",'"Bot Development'",Chatbot,'"Artificial Intelligence'",'"Software Testing'",'"Data Collection'",Automation,'"Data Science'",'"Data Mining'"}",United States,a,"","",2024-02-23 17:37:55.444605,2024-02-23 17:37:55.444605
https://www.upwork.com/jobs/Data-Scraping-and-cleaning_~0107fbe63446e729f4/?referrer_url_path=/nx/search/jobs/,"Data Scraping and cleaning
",2024-01-24 17:37:55.452616,"We are in search of a proficient company or individual capable of undertaking the following data scraping project:

Step One:
Extracting details of Technical Recruiters specialized in recruiting profiles such as Data Analysts, Data Engineers, and Data Scientists from LinkedIn.

Details to be scraped include First Name, Last Name, LinkedIn profile Link, Email, Current Company, and Title.

Step Two:
Filtering the collected data based on activities or job posts within the past 1 week to 1 month.

Sample Data:
https://www.linkedin.com/in/carlisle-mccullough-03b523208/
https://www.linkedin.com/in/jeanee-campoy/
https://www.linkedin.com/in/jeffhpatterson/

If you or your company possesses the skills for this task, please reach out to us with your qualifications and approach. We look forward to collaborating on this exciting project!","{'"Data Mining'",'"Data Scraping'",'"Data Entry'",Python,Scrapy}",Pakistan,a,"","",2024-02-23 17:37:55.454818,2024-02-23 17:37:55.454818
https://www.upwork.com/jobs/Web-Scraping-Help_~01c007a2b2e6555271/?referrer_url_path=/nx/search/jobs/,Web Scraping Help!,2024-01-24 17:37:55.465367,"We are looking for someone to help us scrape the web for businesses in Maui, Hawaii:

- Business Name
- Website
- Email Address
- Phone
- Owner Name(s)

In Business Categories:

- House Cleaning
- Commercial Cleaning
- Restaurant Cleaning
- Window Cleaning
- Gutter Cleaning
- Carpet Cleaning
- Tile and Grout Cleaning
- Upholstery Cleaning
- Pressure Washing
- Janitorial Services
- HVAC cleaning
- Crime Scene Cleanup
- Biohazard Cleanup
- Post-Construction Cleaning
- Air conditioning contractor
- HVAC contractor
- Air conditioning repair service
- Landscaping and Gardening: Lawn care, garden maintenance
- Pet Grooming
- Pet Boarding
- and more....

Result Desired:
A google sheet with clean data. No duplicates — many businesses may offer a combination of these services. We will provide a google sheet with headings filled out so it is easy for you.","{'"Data Scraping'",Python,'"Data Mining'",Scrapy}",Singapore,a,"","",2024-02-23 17:37:55.467409,2024-02-23 17:37:55.467409
https://www.upwork.com/jobs/Expert-Apify-Developer-for-Targeted-Business-Data-Extraction-and-Periodic-Scraping_~01e2490cdace1ee2a4/?referrer_url_path=/nx/search/jobs/,Expert Apify Developer for Targeted Business Data Extraction and Periodic Scraping,2024-01-21 10:57:52,"We are in search of a proficient Apify developer for a specialized web scraping project. We aim to extract detailed information and contact data of commercial businesses located within 300-500 meters of 9000 predefined geographic coordinates (latitude and longitude points).

Project Scope:

Data Extraction: Utilize Apify to extract comprehensive data about commercial businesses around each of the 9000 points. This includes names, addresses, contact information, and other relevant details.

Deep Scraping for Owner Details: Further scrape each business''s website and Instagram profiles to find the owner''s name and contact information, primarily email addresses.

Updates: We want to be able to repeat the scraping process every month, focusing on identifying and adding new maps that were not present in the previous data sets with ease.

Responsibilities:
- Develop custom web scraping solutions using Apify for targeted data extraction.
- Store and format the extracted data systematically for easy analysis.
- Ensure the confidentiality and integrity of the data collected.

Qualifications:
- Proven track record with Apify and sophisticated web scraping techniques.
- Proficiency in JavaScript, Node.js, and other relevant technologies.
- Experience in geolocation-based scraping and handling large datasets.
- Familiarity with data privacy and web scraping legalities.
- Excellent problem-solving, communication, and project management skills.
Project Details:

Communication: Frequent updates and adherence to agreed timelines are crucial.

Application Process:
Please submit a proposal detailing your experience in similar projects, particularly those involving geolocation-based scraping and social media/website data extraction. Include any relevant examples of your work, your availability, and your rate. We are keen to collaborate with someone who can efficiently manage this complex and recurring project.

We look forward to working with a developer who can adeptly handle these specific requirements and contribute to our data-driven initiatives.","{'"API Integration'",'"Web Scraping'",'"Data Scraping'",Scrapy}",Portugal,a,"","",2024-02-23 17:37:55.486408,2024-02-23 17:37:55.486408
https://www.upwork.com/jobs/Scrape-stock-data-into-database_~01607cff63ebcdad91/?referrer_url_path=/nx/search/jobs/,Scrape stock data into database,2024-01-21 08:34:21,"A stock exchange publishes multiple reports in tabular format updated daily, weekly, quarterly, annually. The reports are roughly the same format but have different data.

We''d like to build a scrapper that given the URL of the report, extracts the data and saves it into an SQL database.

We want this to be in Python. For the scrapping library, we''re flexible between BeautifulSoup and Scrappy (depending what you recommend).","{SQL,'"Beautiful Soup'",Python,'"Data Scraping'",'"Data Extraction'",Scrapy}",United States,$15.00-$30.00,"","",2024-02-23 17:37:55.506086,2024-02-23 17:37:55.506086
https://www.upwork.com/jobs/Need-data-scraped-from-instagram_~01c12c0c8b1a5cbe58/?referrer_url_path=/nx/search/jobs/,Need data scraped from instagram ,2024-01-20 19:25:39,"I need around 1900 emales and phones that are already scraped from instagram data should be already available I need a csv file with id ,username,first name ,last name,phone no,emale and insta profile url ","{'"Screen Scraping'",'"Web Crawling'",'"Web Scraping'",'"Beautiful Soup'",Selenium,Python-Requests,'"Data Scraping'",Python,Scrapy,'"Data Extraction'"}",Pakistan,a,"","",2024-02-23 17:37:55.521693,2024-02-23 17:37:55.521693
https://www.upwork.com/jobs/Python-Web-Scrapper_~013452d122b14ac146/?referrer_url_path=/nx/search/jobs/,Python Web Scrapper,2023-12-22 02:45:01,"Hi, I''m a founder of Shopilot.
Here''s my product page.
https://tryshopilot.com/

I want to make the automation that scrap some websites and make it into my database and make it as automation.
We can talk further in Messages.

I prefer to look for &quot;python developer&quot; and especially familar with &quot;Selenium&quot; and &quot;BeatifulSoup&quot; and &quot;scrappy&quot;","{Automation,'"Beautiful Soup'",Selenium,Python,'"Data Scraping'",Scrapy,'"Web Crawling'",'"Python Script'",pandas,API}",United States,$15.00-$20.00,"","",2024-02-23 17:37:55.757347,2024-02-23 17:37:55.757347
https://www.upwork.com/jobs/Web-scraper-development-python_~013b200ec76f301b90/?referrer_url_path=/nx/search/jobs/,Web scraper development in python,2024-01-24 17:37:55.528821,"Looking to build a web scraper plug in where I can go into linkedin jobs, put in my search parameters  about jobs and then have the scraper go to each jobs page, scrape the data from that page and put it into a CSV file or spread sheet.

URL Link to job, Company, Job title, location, industry compensation budget, Job poster first name, Job poster last name, Job poster title, Job poster linkedin profile link (if possible), total number of applicants should be in icsv file 
Need it done today should be a simple script not too complex ","{'"Data Extraction'",'"Screen Scraping'",'"Web Scraping'",'"Beautiful Soup'",Python-Requests,Scrapy,Python,'"Data Scraping'",'"Web Crawling'",'"Python Script'"}",Pakistan,a,"","",2024-02-23 17:37:55.531091,2024-02-23 17:37:55.531091
https://www.upwork.com/jobs/Need-scroll-table-selenium-python_~0161e931245479fad2/?referrer_url_path=/nx/search/jobs/,Need to scroll a table in selenium python,2024-01-24 17:37:55.537775,"from this link

https://www.sec.gov/edgar/browse/?CIK=829224&amp;owner=exclude

click on

[+] Ownership disclosures

and then
View all insider transactions

this will take u to a list of links like this

i need a script in selenium to scroll the table for all elements till all elements are loaded  and store all links in a list ","{Automation,'"Data Extraction'",'"Web Crawling'",'"Beautiful Soup'",Scrapy,Python,Selenium,'"Data Scraping'",'"Selenium WebDriver'"}",Pakistan,a,"","",2024-02-23 17:37:55.540216,2024-02-23 17:37:55.540216
https://www.upwork.com/jobs/Scrapping-tool-for-image-and-data-scrap-from-shopping-website_~01c7633b626fb24f39/?referrer_url_path=/nx/search/jobs/,Scrapping tool for image and data scrap from shopping website ,2024-01-24 17:37:55.547245,"i want to scrap data from shopping website
like
https://www.flipkart.com/
https://www.amazon.in/
https://www.myntra.com/
https://www.meesho.com/
https://www.ajio.com/

if product variation than also need to extract with variation
data like excel attached file","{'"API Integration'",Automation,Dashboard,'"Data Scraping'",Python,Scrapy,'"Data Mining'",'"Web Crawling'",'"Data Extraction'",Python-Goose}",India,a,"","",2024-02-23 17:37:55.549647,2024-02-23 17:37:55.549647
https://www.upwork.com/jobs/Scraping-Verizon-amp-Mobile-Coverage-Data_~015aeee499676721f0/?referrer_url_path=/nx/search/jobs/,Scraping Verizon &amp; T-Mobile Coverage Data,2024-01-24 17:37:55.556929,"We are seeking a skilled and detail-oriented freelancer to conduct a comprehensive data collection and analysis project involving Verizon and T-Mobile''s internet service availability across multiple ZIP codes. This task requires accessing specific URLs provided for each vendor and inputting a variety of ZIP codes to gather information on service availability and status.

Visit the following URLs for data collection:
Verizon: https://www.verizon.com/home/internet/5g/
T-Mobile: https://www.t-mobile.com/home-internet/eligibility
Input a pre-defined list of ZIP codes (to be provided) into each website and record the available data for each ZIP code.
Categorize the status of internet service availability for each ZIP code based on the information provided by the vendors.
Collect any additional relevant data that appears when querying each ZIP code. Essentially we want all the raw data that shows up when you hit this line with multiple zip codes.

You can use this zip code list as a reference point: https://digitalmarketingwebdesign.com/complete-list-of-all-us-zip-codes-all-of-the-postal-codes-in-the-united-states/

Ideal output would be an automated scraper which we can run to get a dataframe output with columns like: 

Date, Operator (Verizon/T-Mobile), Zio Code, Status + Other columns available to scrape information from.","{'"ETL Pipeline'",'"Data Extraction'",'"Beautiful Soup'",pandas,Scrapy,'"Data Scraping'",'"Data Mining'",Python}",United States,a,"","",2024-02-23 17:37:55.559443,2024-02-23 17:37:55.559443
https://www.upwork.com/jobs/Webstore-information-scrapping_~017a32f545f56afa3e/?referrer_url_path=/nx/search/jobs/,Webstore information scrapping,2024-01-24 17:37:55.56774,"I would like to extract all data of the products for sell on this webstore :

https://www.warhammer.com/fr-FR/home","{'"Data Extraction'",Scrapy,'"Data Scraping'"}",France,a,"","",2024-02-23 17:37:55.569587,2024-02-23 17:37:55.569587
https://www.upwork.com/jobs/Looking-for-TikTok-coins-Bulk-quantity_~01d2337cdcd91e62ea/?referrer_url_path=/nx/search/jobs/,Looking for a TikTok coins in Bulk quantity ,2024-01-18 10:35:19,Looking for a TikTok coins in a bulk quantity give me a handsome package only apply if you can do this work. Looking for a long term relationship. Thank you ,"{'"Data Extraction'",'"Data Scraping'",'"Web Scraping'",'"Web Crawling'",Scrapy,'"Ethical Hacking'",TikTok,'"Growth Hacking'"}",Pakistan,a,"","",2024-02-23 17:37:55.578388,2024-02-23 17:37:55.578388
https://www.upwork.com/jobs/Web-Scraping-Expert_~01fd68ef7880ed7a26/?referrer_url_path=/nx/search/jobs/,Web Scraping Expert,2024-01-17 21:08:14,"I need a skilled web scraping expert to collect data from a website. The data will be used to help with various projects and tasks. You will be responsible for using the appropriate tools and techniques to extract the data from the website in an organized and efficient manner. The ideal candidate will have experience with web scraping techniques and be able to handle complex websites. Knowledge of programming languages like Python, Java, or C++ will be beneficial. Attention to detail and the ability to work independently are required. This project requires the following skills:

- Web scraping
- Data extraction
- Attention to detail
- Programming languages","{'"Data Scraping'",Python,'"Data Mining'",Scrapy}",United Kingdom,a,"","",2024-02-23 17:37:55.587755,2024-02-23 17:37:55.587755
https://www.upwork.com/jobs/Looking-for_~0171a0dc7f32c39d57/?referrer_url_path=/nx/search/jobs/,"Looking for 한국분, 웹 스크래핑 알바를 찾습니다.",2024-01-24 17:37:55.594949,"웹스크래핑 알바 구인 공고

직무 개요:
당사는 특정 웹사이트의 데이터를 카테고리 별로 나누어 엑셀 파일로 정리할 데이터입력 or 웹스크래핑 전문가를 찾고 있습니다. 이 작업은 데이터의 정확성과 체계적인 구성을 필요로 합니다.

주요 업무:

-지정된 웹사이트의 특정 카테고리에서 데이터를 수집합니다.
-수집된 데이터를 엑셀 파일로 정리하여 관리합니다.
-데이터의 정확성을 검증하고, 필요한 경우 수정합니다.
-카테고리 별로 데이터를 체계적으로 구분하여 정리합니다.

자격 요건:
- 데이터입력 
-엑셀 및 데이터 관리 능력
-주의 깊고 체계적인 작업 방식
-데이터 정확성에 대한 높은 관심

","{'"Data Scraping'",Scrapy,'"Beautiful Soup'",Selenium,'"Selenium WebDriver'",pandas,Camelot,html2text,'"Data Entry'",Korean}",United States,a,"","",2024-02-23 17:37:55.597141,2024-02-23 17:37:55.597141
https://www.upwork.com/jobs/Cloudflare_~01e4f10f9abb5d73b7/?referrer_url_path=/nx/search/jobs/,Cloudflare,2023-12-06 03:41:41,"Good evening, I need to create several accounts on a website whose security is cloudflare, are you capable of this?","{Selenium,Python,'"Web Crawling'",'"Data Mining'",'"Data Scraping'",Scrapy,'"Data Extraction'",'"LinkedIn Lead Generation'",LinkedIn,'"LinkedIn Sales Navigator'",'"Google Chrome Extension'",'"Web Scraping'",'"Screen Scraping'",'"Web Scraping Software'",'"Scraper Site'"}",Brazil,a,"","",2024-02-23 17:37:55.766371,2024-02-23 17:37:55.766371
https://www.upwork.com/jobs/Web-Scraping-Specialist_~01199492125701f0ff/?referrer_url_path=/nx/search/jobs/,Web Scraping Specialist,2024-01-24 17:37:55.603857,"We are seeking a skilled Web Scraping Specialist to extract specific data from websites. The ideal candidate should have experience in web scraping using Python and be familiar with web scraping libraries and frameworks. The successful candidate will be responsible for developing scraping scripts and optimizing them to efficiently obtain the required data. The ability to troubleshoot and debug scraping scripts is essential. Attention to detail and strong problem-solving skills are also necessary for this role.

You would be setting us up to scrape death notices and obituary information and republishing it as a local directory for death notices. It would also need to be put into a datebase so that the information scraped from all the local funeral homes would be compiled in one area so that our staff know the dates and times of all services in the area to insure we are ready to produce product for the funeral itself. 



Skills required:

- Web scraping
- Python
- Web scraping libraries and frameworks
- Script development
- Troubleshooting and debugging
- Attention to detail
- Problem-solving","{'"Data Scraping'",'"Data Mining'",Python,Scrapy}",United States,$8.00-$25.00,"","",2024-02-23 17:37:55.605397,2024-02-23 17:37:55.605397
https://www.upwork.com/jobs/SCORM-API-Integration-with-LMS_~01ff454817ae7bc9a2/?referrer_url_path=/nx/search/jobs/,SCORM API Integration with LMS,2024-01-17 09:45:07,We are looking for a developer who can integrate SCORM API to our LMS built in React.JS.,"{'"API Integration'",'"Data Extraction'",'"Business Process Automation'",jQuery,Selenium,Scrapy,'"Learning Management System'",'"Shareable Content Object Reference Model'",JavaScript}",India,a,"","",2024-02-23 17:37:55.614953,2024-02-23 17:37:55.614953
https://www.upwork.com/jobs/Website-scraping-for-general-information_~01f84ce0b6f45d61d1/?referrer_url_path=/nx/search/jobs/,Website scraping for general information ,2024-01-17 07:21:20,Need to collect data by scraping some websites. There is a set number of columns that need to be filled in excel with the information ,"{'"Data Scraping'",'"Microsoft Excel'",Scrapy}",India,$10.00-$20.00,"","",2024-02-23 17:37:55.62414,2024-02-23 17:37:55.62414
https://www.upwork.com/jobs/Maintain-and-improve-several-Scrapy-spiders-and-setup-Zyte-Scrapy-Cloud_~01e9ea83c79f288d7d/?referrer_url_path=/nx/search/jobs/,Maintain and improve several Scrapy spiders and setup Zyte Scrapy Cloud,2024-01-24 17:37:55.630506,"We''re looking for an expert to help us maintain and improve, as well as deploy a suite of web scrapers to Scrapy Cloud. The data is exported as CSV and should upload it to an API. It will need to be scheduled weekly. The process will need to be fully automated.","{'"API Integration'",'"Web Crawling'",Python,'"Data Scraping'",Scrapy,'"Data Extraction'"}",United States,a,"","",2024-02-23 17:37:55.632458,2024-02-23 17:37:55.632458
https://www.upwork.com/jobs/Python-Developer-for-Advanced-commerce-Data-Scraping_~0195035e7280b305ea/?referrer_url_path=/nx/search/jobs/,"Python Developer for Advanced E-commerce Data Scraping
",2024-01-24 17:37:55.646343,"We are seeking a skilled Python Developer with a strong background in web scraping and data extraction to join our dynamic team. In this role, you will be responsible for developing and maintaining sophisticated scraping tools to gather valuable data from various e-commerce platforms.

Key Responsibilities:

Design and implement efficient web scraping solutions to extract product data, pricing, reviews, and other relevant information from e-commerce sites.
Ensure the reliability and integrity of data extraction processes.
Collaborate with the data analytics team to refine data for business insights.
Maintain up-to-date knowledge of the e-commerce industry''s trends and changes to adjust scraping strategies accordingly.
Develop solutions to bypass anti-scraping mechanisms while adhering to legal and ethical guidelines.
Optimize existing scraping tools for performance and scalability.
Qualifications:

Proficiency in Python and web scraping libraries (like BeautifulSoup, Scrapy, Selenium).
Experience with data processing and storage frameworks.
Familiarity with SQL databases and NoSQL databases.
Strong understanding of HTML, CSS, and JavaScript.
Knowledge of e-commerce platforms and their data structures.
Ability to work independently and as part of a team.
Good problem-solving skills and attention to detail.","{Python,'"Data Mining'",'"Data Scraping'",Scrapy,'"Data Extraction'"}",United States,fW,"","",2024-02-23 17:37:55.648319,2024-02-23 17:37:55.648319
https://www.upwork.com/jobs/Scrape-Job-Sites-for-New-Job-Posts_~012b11c45d0082603c/?referrer_url_path=/nx/search/jobs/,Scrape Job Sites for New Job Posts,2024-01-24 17:37:55.656992,I need an automated method to extract the latest job postings from LinkedIn Jobs and Google Jobs SERPs (Positions/Titles to be provided) and then capture specific details in a structured spreadsheet (see &quot;Tracker&quot; tab here: https://docs.google.com/spreadsheets/d/1YM5xJEVU2-kzdUHl_ElE0zhEGzkk2nF-TOfEV5IosO0/edit?usp=sharing). Open to using custom scripting or platforms such as Apify / Browse AI.,"{Scrapy,'"Data Scraping'",'"Data Entry'"}",United States,a,"","",2024-02-23 17:37:55.6587,2024-02-23 17:37:55.6587
https://www.upwork.com/jobs/Seeking-Contractor-for-SMS-Email-System-Setup-Twilio-Experience-Preferred_~019cab9343a9665f92/?referrer_url_path=/nx/search/jobs/,Seeking Contractor for SMS-to-Email System Setup (Twilio Experience Preferred),2024-01-14 14:32:03,"We''re on the lookout for a resourceful contractor to set up a basic yet effective SMS-to-Email system. Our aim is to connect with homeowners in the USA to discuss potential property sales. 

This project is perfect for someone who enjoys the challenge of creating cost-efficient solutions and has some experience with platforms like Twilio or Alibaba Cloud.

Project Overview:

Develop an SMS-to-Email system that can handle moderate to high volumes of messages.
The system should effectively send messages to both personal and business email addresses.
Ensure the setup adheres to TCPA and A2P messaging regulations.
Provide insights on economical solutions to achieve our project goals.
Consider future scalability, but focus primarily on immediate needs.

Ideal Candidate:

Some experience in setting up SMS-to-Email systems, with familiarity in platforms like Twilio or Alibaba Cloud.

Understanding of SMS marketing regulations (TCPA, A2P).

Capability to manage a project efficiently with a startup budget.

Problem-solving mindset with a knack for cost-effective strategies.

Good communication skills in English.

If you have examples of past work in a similar vein, please share them.

What We Offer:
An opportunity to contribute to a budding real estate business.
Potential for future collaboration as our company grows.
","{Python,Scripting,Automation,Scrapy}",United States,a,"","",2024-02-23 17:37:55.667418,2024-02-23 17:37:55.667418
https://www.upwork.com/jobs/Need-instagram-handles-scraped_~01018a34bdcdecc93a/?referrer_url_path=/nx/search/jobs/,Need instagram handles scraped,2024-01-14 13:24:11,"I will give you a source of Instagram accounts and I would like you to scrape their valid emails and phone numbers

I have attached file this is list of handles and what information I need

i need it done today ","{'"Screen Scraping'",'"Web Crawling'",'"Web Scraping'",Scrapy,'"Beautiful Soup'",Python-Requests,'"Data Scraping'",Python,Instagram}",Pakistan,a,"","",2024-02-23 17:37:55.677753,2024-02-23 17:37:55.677753
https://www.upwork.com/jobs/Senior-Scraping-Python-Developer_~0122bb358a62266e99/?referrer_url_path=/nx/search/jobs/,Senior Scraping Python Developer,2024-01-11 15:42:21,"We are looking for a Senior Scraping Python developer for remote work in our worldwide team. We need someone who wants to take part in something big and assume responsibility for the success of a new and innovative e-commerce project.

The right candidate will be someone with an open mind who loves to solve problems and who strives to take their projects to the next level.

Responsibilities:
Your day-to-day will be divided between writing good Python and idiomatic code, reviewing pull requests from other team members, debugging complex problems, and also participating in decision-making processes. That is, contributing to your experience in software architecture and design.


Job Type: Remote, full-time
You will be working on the company''s key product:
-Maintain existing Scrapers and create new
-Implement internal and external API integrations
-Promote the best coding practices and standards, design best-in-class solutions

Main hard skills requirements for candidates:
-Strong background with Python 4+ years.
-Experience with the following frameworks: Scrapy, Celery.
-Reverse engineering skills. Such as (any from the list):
--experience with local proxy for intercepting and analyzing HTTPS traffic (mitmproxy, Burp Suite, Charles).
--experience with Android/IOS emulators and intercepting Web traffic on it.
--experience with Frida - patching/analyzing Android/IOS apps.
--experience with bypassing bot-protection systems such as Akamai/PerimeterX/Cloudflare
-Strong background working with Redis, MongoDB, Elasticsearch databases.
-Experience with FastAPI/Flask.
-Experience with Playwright/Selenium will be a plus.
-Experience with Machine Learning with be a huge plus.
-Experience with Kubernetes and Docker is a plus.
-Experience with such python libs like Pydantic, Pillow, etc. will be a plus.

Main soft skills requirements for candidates:
-Strong desire and a proactive attitude to work.
-English - at least Intermediate level.
-Strong problem-solving abilities.
-Flexibility and team player.

About us
AutoDS is an all-in-one dropshipping automation solution that saves dropshippers time on their everyday eCommerce tasks. We help our members automate everything from finding products to sell and monitoring their price, all the way to fulfilling orders.

We are a global company with team members all over the world. We live on collaboration tools like Slack and Zoom, but we love to chat and organize meet-ups as often as possible. ‘Community’ is one of our core values, and it is just as important as our technical values like eCommerce automation.

This is a great opportunity to work with talented teammates from across the globe.

We are proud of our online communities, like our YouTube channel, with over 25k subscribers who are hungry to learn about dropshipping. When you join us, you will play an active part in growing and nurturing these communities.

No matter your role at AutoDS, you will help to grow the company and your voice will be heard.","{Python,Scrapy,Cloudflare,'"API Integration'",Celery,'"Reverse Engineering'",FastAPI,'"Charles Proxy'"}",Israel,a,"","",2024-02-23 17:37:55.685227,2024-02-23 17:37:55.685227
https://www.upwork.com/jobs/Need-tool-for-Facebook-group-private-public-posts-data-scrape_~016d11cc44696a60d0/?referrer_url_path=/nx/search/jobs/,Need tool for Facebook  group (private/public) posts data scrape,2024-01-24 17:37:55.691916,"I need tool for scrape Facebook private groups (that I have joined).  Need to obtain details for all posts,  and get details about each post:

-Number likes post have
-Number of comments post have
-Post URL
-Posted date
-Post type (link, video, photo, text)

I want select the number of the latest posts (or a specific number of last days) to retrieve data accordingly. 

I want  easily filter and sort all the collected data, and sometimes export them in Google Sheets or CSV file.

P.S. I attached screenshot of tool which scraping public group. this is example what  kind of data i want to get and wat kind of filtering/sorting I need. 

P.P.S. in groups sometimes are 100,000''s posts and we need to scrape all of them but if it is very heavy tool must scrape at least 30k post every time.  also tool must work when browser window is minimized (inactive). ","{'"Data Scraping'",Scrapy,'"Data Mining'",Python,'"Data Extraction'",'"Facebook JavaScript'",'"Google Chrome Extension'",'"Browser Extension'"}",Georgia,a,"","",2024-02-23 17:37:55.693838,2024-02-23 17:37:55.693838
https://www.upwork.com/jobs/Scraping-Indian-Labour-and-Employement-Law-data_~0167a5aff2f9803906/?referrer_url_path=/nx/search/jobs/,Scraping Indian Labour and Employement Law data,2024-01-24 17:37:55.700466,You need to write a python script for scraping data for Indian Labour and Employment Law and and that in mongodb.,"{Scrapy,'"Selenium WebDriver'",Python,'"Data Scraping'",'"Microsoft Excel'"}",India,a,"","",2024-02-23 17:37:55.702038,2024-02-23 17:37:55.702038
https://www.upwork.com/jobs/Scrape-data-from-ETSY_~01919b0c4cf0e46869/?referrer_url_path=/nx/search/jobs/,Scrape data from a ETSY,2024-01-08 08:07:32,"I need to scrape data from etsy profiles, i will provide list of profile and i need to scrape data from each profile then write in csv and scrape next profile and so on.","{'"Beautiful Soup'",Selenium,'"Selenium WebDriver'",pandas,Import.io,'"Data Scraping'",'"Data Mining'",Scrapy,Python,'"Data Extraction'"}",Pakistan,fW,"","",2024-02-23 17:37:55.712986,2024-02-23 17:37:55.712986
https://www.upwork.com/jobs/Data-Scraping-TikTok-Shop_~0130bdb68b5608786e/?referrer_url_path=/nx/search/jobs/,Data Scraping TikTok Shop,2024-01-08 05:41:04,"I am looking for a highly skilled data scraper to help me gather information on TikTok Shop. The job involves developing and maintaining scrapers that extract data from this platform and generates structured datasets. A successful candidate should have a demonstrable track record in scraping and data extraction techniques. 

This project will likely be a long term engagement, as the scrapers will require maintenance to continuously pull accurate data. We will be working together towards building a recurring data report that might include information such as: # of live streams, # of viewers, # of orders complete, etc. Once the report building is finalized, the work will transition to maintaining the scrapers and ensuring data quality.

Relevant skills for the role:
- Proficient in Python, JavaScript, or another language typically used for web scraping
- Strong understanding of HTML and CSS
- Familiarity with XPath and CSS Selectors
- Experience with web scraping libraries such as BeautifulSoup and Scrapy
- Ability to choose and implement the right tool for different scraping scenarios
- Expertise in interacting with websites that use dynamic content, AJAX, and JavaScript
- Experience using tools like Selenium for dynamic content scraping
- In-depth knowledge of the HTTP protocol
- Ability to handle authentication, cookies, and headers in web scraping
- Strong skills in cleaning and preprocessing raw data.
- Experience with data transformation and format conversion.
- Proven ability to overcome anti-scraping mechanisms and handle rate limiting
- Knowledge of techniques to avoid IP blocking
- Strong problem-solving abilities, especially in troubleshooting scraping challenges
- Adaptive approach to handle unexpected issues during scraping projects.
- Effective communication of findings and results

Please answer the questions below alongside your application for this role. I look forward to hearing from you!","{'"Web Scraping'",'"Beautiful Soup'",Selenium,Python-Requests,'"Data Scraping'",Python,'"Data Mining'",Scrapy,'"Web Scraping Software'",'"Data Extraction'"}",United States,a,"","",2024-02-23 17:37:55.721614,2024-02-23 17:37:55.721614
https://www.upwork.com/jobs/Python-program-scrape-Instagram-public-data_~01b4f4c51ba96f2113/?referrer_url_path=/nx/search/jobs/,Python program to scrape Instagram public data,2024-01-07 10:43:16,"I need a python program, that will load a csv file containing entries (id; link) and produce publicly available data (id from csv;view count; comment count; likes count; author name)

Example of input CSV:
7849;https://www.instagram.com/reel/C0w1dkGr4fi/?igshid=MzRlODBiNWFlZA==
7850;https://www.instagram.com/reel/C0vRHPCs81w/?igshid=MzRlODBiNWFlZA==
7851;https://www.instagram.com/reel/C0zLs7exfaC/?igshid=MzRlODBiNWFlZA==

I need to run approximately 100 entries every hour.","{Python,'"Data Scraping'",'"Data Mining'",Scrapy,'"Data Extraction'"}",Czech Republic,a,"","",2024-02-23 17:37:55.731041,2024-02-23 17:37:55.731041
https://www.upwork.com/jobs/Data-Mining-and-Scraping-Specialist_~010d6d66c4eaa73237/?referrer_url_path=/nx/search/jobs/,Data Mining and Scraping Specialist,2024-01-05 18:34:59,"We are seeking a highly skilled and experienced Data Mining and Scraping Specialist to join our team. The successful candidate will be responsible for extracting specific data points from a series of web pages that has a username and password. Our project involves gathering information that is consistently presented across 250+ pages, with identical column types such as names, emails, and other relevant fields.

**Key Responsibilities:**

- Develop and implement efficient and reliable data mining and scraping strategies to extract data from multiple web pages.
- Ensure the integrity and accuracy of the data collected.
- Work with similar structured data across various pages, focusing on consistent column types (e.g., name, email).
- Collaborate with the team to understand data needs and report findings in an organized manner.
- Troubleshoot and resolve any issues related to data mining and scraping processes.
- Stay updated with the latest technologies and techniques in data mining and web scraping.

**Qualifications:**

- Proven experience in data mining and web scraping.
- Strong knowledge of programming languages such as Python, particularly libraries and frameworks used for web scraping.
- Ability to handle and process large volumes of data.
- Excellent problem-solving skills and attention to detail.
- Familiarity with data extraction from web pages with consistent structure and format.
- Good communication skills to effectively collaborate with the team.

We look forward to reviewing your application and potentially welcoming you to our team!

PLEASE NOTE THAT WE WILL NOT CONSIDER YOUR APPLICATION IF YOU DO NOT PROVIDE THE APPROPRIATE ANSWERS TO THE SCREENING QUESTIONS.","{'"List Building'",'"Beautiful Soup'",Scrapy,'"Data Scraping'",'"Data Mining'",'"Microsoft Excel'",Python}",United Kingdom,a,"","",2024-02-23 17:37:55.738901,2024-02-23 17:37:55.738901
https://www.upwork.com/jobs/Scrape-information-and-images-from-website_~01c3a00eb006bfa6d9/?referrer_url_path=/nx/search/jobs/,Scrape information and images from website,2023-12-22 20:21:20,"Hi there,

I looking for someone who can help me with scraping information form furniture websites.
I need all the images, names, product information and retailprices of the furniture, lighting and accessories. The information need to be structured ass wel. Images named and put in folders.
All the information in Excel.

I want the information from the following websites:
- Bolia
- Muuto
- 101Copenhagen
- Serax
- Normann Copenhagen
- DCWeditions

Thanks
","{'"Data Extraction'",'"Data Integration'",'"Data Entry'",'"Data Scraping'",Scrapy}",Netherlands,a,"","",2024-02-23 17:37:55.748308,2024-02-23 17:37:55.748308
https://www.upwork.com/jobs/Need-Web-searcher_~01537f22abdb9ab4fd/?referrer_url_path=/nx/search/jobs/,Need a Web searcher,2023-12-02 11:15:34,"Thank you for reviewing my project.
I’m looking for Web research experts to perform occasional researches on different subjects. These following skills will be great for this task:
Knowledge/ Skills:
•	Great web research skills: Google search commands (mention some in your cover), maybe other search engines also.
•	Office tools: knowledge of Google Docs, Microsoft Word, Excel, PowerPoint...
•	Being able to analyze, identify key points, and summarize data
Not required but a big plus:
•	Understanding French. 
•	Knowledge of scrapping, and APIs will be a big plus
Examples of tasks may be: 
Finding specific places in specific cities, finding events, peoples, books...
Some parts also include searching through educational resources, so some background there will be appreciated. 	
Very important: Searches should be very deep, and try to be exhaustive as much as possible. So need to be very detail orientated. 
I look forward to hearing back,","{'"Google Search'",French,Scrapy,Python,'"Data Scraping'"}",Mali,a,"","",2024-02-23 17:37:55.775368,2024-02-23 17:37:55.775368
https://www.upwork.com/jobs/Fetch-data-from-odds-comparison-website-txt-file_~014e7aef42493a86c4/?referrer_url_path=/nx/search/jobs/,Fetch data from odds comparison website to txt file,,"I have a task to fetch data from odds comparison website www.betwatch.com to.  txt file based   on certain filters. they have an  APIs https://guide.betwatch.com/docs/graphql

","{'"Data Scraping'",Scrapy,Python,Selenium,'"API Integration'",'"Data Extraction'",'"Data Analysis'",'"Web Crawling'",Django,JavaScript,'"Google Chrome Extension'",'"RESTful Architecture'",React,Scripting}",Australia,a,"","",2024-02-23 17:37:55.786668,2024-02-23 17:37:55.786668
https://www.upwork.com/jobs/Scraping-reddit-with-Python_~018a16ad95cf7187f6/?referrer_url_path=/nx/search/jobs/,Scraping reddit with Python,2021-02-16 07:43:58,"Hi,
I''m looking for python code to scrap wallstreetbets.
Let me explain what I need:
- the scraping should be on several days (ideally I''d like to set a time range)
- the result should be a graph with the indication of the most popular share or cryptos
- a graph with the sentiment analysis of those share/crypto (buy, neutral, sell, hold, sell short)
I''m a total newbie and I''m not trying to learn python. The only thing I really have to know is how to run the code and edit what I may have to modify.
Please, take a look at this as example:
https://www.youtube.com/watch?v=qCB8MZ-W1Ig&amp;t=19s
We can use teamviewer, zoom, or what you like.
Please send me your quote.
Thank you.","{Scrapy,Python,'"Data Scraping'",'"Data Mining'",'"Data Extraction'",'"Machine Learning'",'"Data Science'"}",Italy,a,"","",2024-02-23 17:37:55.805318,2024-02-23 17:37:55.805318
https://www.upwork.com/jobs/Looking-bypass-Akamai-Bot-with-headless-browsing_~01499b63701140f336/?referrer_url_path=/nx/search/jobs/,Looking to bypass Akamai Bot with headless browsing,2024-02-22 13:32:43,"Hello,

I''m seeking an experienced developer with a strong background in web scraping, particularly using Selenium, and expertise in bypassing sophisticated bot detection systems like Akamai.

Project Overview:

I have a script in Node.js that uses Selenium for web scraping data from specific websites with dynamic interactive data scraping. The script is operational, but I''m encountering challenges with the stability and duration of scrapes, which are hindering the data collection process. My goal is to modify this script to run in headless mode while effectively bypassing bot detection, ensuring consistent and reliable data scraping without being blocked. Should be able to handle a lot of requests without detection. that is key. 

Key Requirements:

Profound knowledge in Selenium WebDriver and Node.js.
Proven experience in implementing headless browsing in a way that mimics human interactions to bypass bot detection (specifically Akamai bot manager).
Ability to work with existing codebase to integrate solutions.
Understanding of web scraping ethics and legalities.
Project Deliverables:

Modify the existing Selenium script to operate in headless mode.
Implement strategies to bypass bot detection without triggering security mechanisms.
Ensure the stability and reliability of the scraping process.
Document the changes made for future reference and adjustments.
I''m looking for someone who can provide a strategic approach to this problem, ensuring that the solution is robust and maintainable. If you have experience with similar challenges and are confident in your ability to deliver effective solutions, I would love to hear from you.","{'"API Integration'",Dashboard,'"Data Extraction'",'"Beautiful Soup'",Scrapy,Node.js,API,'"Data Scraping'",Automation,JavaScript}",,$40.00-$120.00,"","",2024-02-23 23:36:10.44928,2024-02-23 23:36:10.44928
https://www.upwork.com/jobs/Seeking-Founder-Partner-for-Exciting-Startup-Opportunity_~0157b620b1882eec5e/?referrer_url_path=/nx/search/jobs/,Seeking Co-Founder/Partner for Exciting Startup Opportunity,2024-02-22 02:22:39,"Description:

We are seeking a talented AI developer to join our team and create an innovative text-based information retrieval system for our platform, Freight Focus. Our goal is to provide truckers with an intuitive and efficient way to access information on shipping and receiving locations across the United States via text messaging.

Key Responsibilities:

Develop an AI-powered system that can understand and interpret text messages from truckers, retrieve relevant information from our database, and generate accurate responses.
Implement SMS integration to enable truckers to subscribe to our platform using their phone numbers and receive information via text messages.
Design and optimize the system for scalability, reliability, and real-time responsiveness to accommodate a large volume of requests from truckers.
Collaborate with our team to define requirements, prioritize features, and iterate on the system based on user feedback.
Requirements:

Proven experience in AI development, particularly in natural language processing (NLP) and building conversational AI systems.
Strong proficiency in software development, including backend development, database management, and SMS integration.
Familiarity with geolocation services and APIs for retrieving shipping and receiving location data.
Excellent communication skills and ability to collaborate effectively with cross-functional teams.
Passion for innovation and solving complex technical challenges in the transportation industry.","{'"SMS Gateway'",'"Database Management'",'"AI App Development'",Scrapy}",,$20.00-$60.00,"","",2024-02-23 23:36:10.474377,2024-02-23 23:36:10.474377
https://www.upwork.com/jobs/Industrial-Real-Estate-Skip-Tracing_~01471a928d806771c5/?referrer_url_path=/nx/search/jobs/,Industrial Real Estate Skip Tracing,2024-01-31 16:00:36,"We are an industrial real estate company in need of skip tracing. We can provide you with the property address, name, LLC & 2 mailing addresses. In return we need cells, landlines and emails for contacts along with if the owner is deceased.","{'"Data Cleaning'",'"Data Analysis'",'"Data Extraction'",'"Data Scraping'",'"Data Mining'",ScrapeBox,Scrapy}",,c,"","",2024-02-23 23:36:10.482519,2024-02-23 23:36:10.482519
https://www.upwork.com/jobs/Industrial-Real-Estate-Skip-Tracing_~01c508fb8200f3b8fe/?referrer_url_path=/nx/search/jobs/,Industrial Real Estate Skip Tracing,2024-02-02 23:36:10.488121,"We are an industrial real estate company in need of skip tracing. We can provide you with the property address, name, LLC & 2 mailing addresses. In return we need cells, landlines and emails for contacts along with if the owner is deceased.","{'"Data Cleaning'",'"Data Analysis'",'"Data Extraction'",'"Data Scraping'",'"Data Mining'",ScrapeBox,Scrapy}",,c,"","",2024-02-23 23:36:10.490286,2024-02-23 23:36:10.490286
https://www.upwork.com/jobs/Data-Collection-Specialist_~01558d67ff925dc29f/?referrer_url_path=/nx/search/jobs/,Data Collection Specialist,2024-01-31 04:14:40,"I am seeking a highly skilled Data Collection Specialist with expertise in web crawler technology to collect data from a given website. The ideal candidate will have experience with data extraction and web crawling tools and techniques. The primary responsibility will be to collect and process large amounts of data from the website and deliver it in a structured and organized format. The candidate should be proficient in web scraping techniques, able to handle complex web pages, and have a strong understanding of data extraction algorithms. Attention to detail, data entry accuracy, and the ability to meet tight deadlines are essential for this role.

Relevant skills:
- Web crawling
- Data extraction
- Web scraping
- Data entry
- Attention to detail","{'"Data Scraping'",Python,'"Web Crawling'",Scrapy}",,c,"","",2024-02-23 23:36:10.49702,2024-02-23 23:36:10.49702
https://www.upwork.com/jobs/Scrape-Jackson-County-Treasurer-site-build-Spreadsheet_~01b3a217e2762cf3a5/?referrer_url_path=/nx/search/jobs/,Scrape Jackson County Treasurer site build Spreadsheet,2024-01-30 22:58:31,"Ok, this would be the first of many.  I am a real estate investor that focuses on buying properties off market.  There are variables that we search for that are generally easily extracted off the tax roll, and compiled with some other data points, code violations, etc, and linked to a google earth allows us to specifically target market deals.  

All Data is found on the tax roll, the tax roll should be extracted by cells,
All liens, or judgements are found on the recorders office
Owed back taxes, can also be found on tax roll or treasury
This would be extracting all the pertinent data off the tax roll and then cross referencing with taxes, liens, judgements and code violations, then linking it to the Google Earth Link.  ","{'"Data Scraping'",'"Data Mining'",'"Microsoft Excel'",'"Spreadsheet Software'",'"Data Entry'",Scrapy,'"Data Extraction'"}",,$50.00-$75.00,"","",2024-02-23 23:36:10.5035,2024-02-23 23:36:10.5035
https://www.upwork.com/jobs/Social-Media-Scraper-data-extraction_~01c1dcb0f0ee387c1f/?referrer_url_path=/nx/search/jobs/,Social Media Scraper (data extraction) ,2024-01-24 23:36:10.508891,"Dear Data Miners and Extractors: 

I''d like to extract all of the data on our followers and likes on our main facebook page and two of the facebook groups we have. I''d like to get all of their emails, phone numbers and names. 

I need somebody who can utilize a code/tool or similar to run this as many of the options out there have stopped working. 

Are you familiar with Apify or Scrapy etc? ","{'"Data Scraping'",'"Data Extraction'",'"Data Mining'",Scrapy}",,$30.00-$75.00,"","",2024-02-23 23:36:10.510422,2024-02-23 23:36:10.510422
